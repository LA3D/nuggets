---
title: "Building \"Stuff\"?"
author: "Charles F. Vardeman II"
institute: "Center for Research Computing, University of Notre Dame"
date: "2023-09-05"
embed-resources: true
format: 
    revealjs:
        logo: crc-logo-tagline-1-alt.png
        theme: [simple, crc.scss]
        slide-number: true
categories: [Agents,trustedAI,Development]
---

##

::: {style="font-size: 2.5em; text-align: center"}
::: {.fragment .strike}
::: {.fragment .fade-out}
Building Stuff?
:::
:::

::: {.fragment .fade-in}
Building Agents based on Large Language Models! 
:::
:::

## Building "Stuff"...
![](../tai_testing/effective_testing_ml_systems.png){fig-align="center"}

::: footer
Learn More: [Effective testing for machine learning systems](https://www.jeremyjordan.me/testing-ml/)

Youtube Discussion: [MLOps Chat: How Should We Test ML Models? with Data Scientist Jeremy Jordan](https://youtu.be/k0naEYedv5I)
:::

## Building "Stuff"...
:::{.fragment .fade-out}
![](software1-2023-09-01-1139.png){fig-align="center"}
:::

:::{.fragment .fade-in}
![](software2-2023-09-01-1139.png)
:::

::: footer
Learn More: [Effective testing for machine learning systems](https://www.jeremyjordan.me/testing-ml/)
:::

## You are here ⬇️

::: columns
::: {.column width="50%"}
![](php.png)
:::

::: {.column width="50%"}
![](netscape.png)
:::
:::

## What **Kind** of LLM Agents are we trying to build?

::: incremental
- Conversational Agents
- *vs*. Cognitive Autonomous Agents
- *vs*. Agents tuned for a Data Processing Task
:::

##
::: {style="font-size: 2.5em; text-align: center"}
We will focus on Conversational Agents...
:::

## The Best Advice we can Give
:::{.r-stack}
![](../nuggets_review/state_of_gpt.png){.center width="800" height="510"}
:::

::: footer
[Andrej Karpathy, "State of GPT" | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A.](https://youtu.be/bZQun8Y4L2A?si=9w68buJRCPUqAlch)
:::


##
:::{.r-stack}
![](../nuggets_review/state_of_gpt_pipeline.png){.center width="900" height="510"}
:::

::: footer
[Andrej Karpathy, "State of GPT" | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A.](https://youtu.be/bZQun8Y4L2A?si=9w68buJRCPUqAlch)
:::

## Caveat: You are at the **Edge** of Research and Practice! {.center}

## Instruction Prompts

## Reasoning Prompts

## We want Large Language Models to be **Factual**!

::: incremental
- "Fine Tuning"
- Retrieval Augmented Generation (RAG)
:::

## We want Large Language Models to be **Factual**!

- **Fine-Tuning**: augment the **behavior** of the model
- **Retrieval:** introduce new **knowledge** to the model
- **Retreval Aware Training (RAT)** Fine-tune the model to **use** or **ignore retrieved content**


## "Big Models" vs "Small Models"


## Open Source Community

::: columns
::: {.column width="50%"}
![](a16z_header.png){width="600" height="209"}
:::

::: {.column width="50%"}
![](a16z_grants.png){width="502" height="650"}
:::
:::

::: footer
Matt Bronstein and Rajko Radovanovic, “Supporting the Open Source AI Community,” Andreessen Horowitz, Aug. 30, 2023.

[https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/](https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/) (accessed Sep. 03, 2023).

:::
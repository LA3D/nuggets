{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Towards <u>Trusted</u> LLM based Curator Agents\"\n",
        "author: \"Charles F. Vardeman II\"\n",
        "institute: \"Center for Research Computing, University of Notre Dame\"\n",
        "date: \"2023-10-06\"\n",
        "modified: \"2023-10-20\"\n",
        "embed-resources: true\n",
        "format: \n",
        "    revealjs:\n",
        "        width: 1600\n",
        "        height: 900\n",
        "        logo: ../images/crc-logo-tagline-1-alt.png\n",
        "        theme: [simple, ../images/crc.scss]\n",
        "        slide-number: true\n",
        "categories: [LLMs, Agents, Knowledge Graphs]\n",
        "---"
      ],
      "id": "9714f0de"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motivation: TAMMS KG\n",
        "\n",
        "::: {.r-stack}\n",
        "![](../agents_summer23/AI-Curated_KG.png){.center width=\"1135\" height=\"850\"}\n",
        ":::\n",
        "\n",
        "## Starting Architecture... {.center}\n",
        "\n",
        "## AI Curator \"Agents\" {.center}\n",
        "\n",
        "## Activity Specific Agents: Visual Agents\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "* [“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.](https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html)\n",
        "* [Hu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv.](https://doi.org/10.48550/arXiv.2306.08129)\n",
        ":::\n",
        "::: {.column width=\"40%\"} \n",
        "![](../agents_summer23/visualagents.png)\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## Visual Agents Architecture: Different LLMs based on Role\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "* [“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.](https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html)\n",
        "* [Hu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv.](https://doi.org/10.48550/arXiv.2306.08129)\n",
        ":::\n",
        "::: {.column width=\"40%\"} \n",
        "![](../agents_summer23/visualagents_arch.png)\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Activity Specific Agents: Visual Agents Transition Graph\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "* [“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.](https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html)\n",
        "* [Hu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv.](https://doi.org/10.48550/arXiv.2306.08129)\n",
        ":::\n",
        "::: {.column width=\"40%\"} \n",
        "![](../agents_summer23/visualagent_transitiongraph.png)\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "## Different LLM's for Different Tasks\n",
        "- Lesson's from [Kaggle Science Exam Competition](https://www.kaggle.com/competitions/kaggle-llm-science-exam) winning [team solution](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/446422)\n",
        "- Becomes a search - context retrieval problem for the curator LLM\n",
        "\n",
        "\n",
        "## Modeling The World!\n",
        ":::{.r-stack}\n",
        "![](Jano-Data-Stack.png){.center width=\"1102\" height=\"800\"}\n",
        ":::\n",
        "[Ontology Engineering: A View from the Trenches - WOP 2015 Keynote | PPT (slideshare.net)](https://www.slideshare.net/kjanowicz/ontology-engineering-a-view-from-the-trenches-wop-2015-keynote)\n",
        "\n",
        "## Moo Architecture\n",
        ":::{.r-stack}\n",
        "![](../tai-ke/ontology_process.png){.center width=\"1541\" height=\"850\"}\n",
        ":::\n",
        "\n",
        "## We need to think through what **Trusted** Means!\n",
        "\n",
        "::: {.r-stack}\n",
        "![](../tai-tools/4x4-circle-template_TAI_4-2023.png){.center width=\"850\" height=\"850\"}\n",
        ":::\n",
        "\n",
        "## Frameworks to Capture Provenance of Models!\n",
        "- SBoMs and AI BoMs for Agents\n",
        "    - They are KGs Themselves!\n",
        "- Data Cards and Model Cards for Models\n",
        "- Agents will be exposed as Microservices themselves\n",
        "- We should be able to ask the Microservice Layer for \"Trust Information\"\n",
        "- Agent should store \"Metadata\" in the Graph Fragment they are constructing.\n",
        "\n",
        "## Starting with a CSV (Navy Maintenance Data)\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![](column-type-annotation.png)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"} \n",
        "![](column-type-results.png)\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "[Korini, Keti, and Christian Bizer. 2023. “Column Type Annotation Using ChatGPT.” arXiv. http://arxiv.org/abs/2306.00745.](http://arxiv.org/abs/2306.00745)\n",
        "\n",
        "## Context Matters!\n",
        "\n",
        "::: {.r-stack}\n",
        "![](json-ld_pipeline.png){.center width=\"1115\" height=\"800\"}\n",
        ":::\n",
        "\n",
        "[Converting Legacy Enterprise Data into Knowledge Graphs with AI and JSON LD | Eliud Polanco](https://youtu.be/KHNc0WwJ5JA?si=Z9YFCUVRXLyM47bH)\n",
        "\n",
        "## JSON-LD as a Bridge\n",
        "\n",
        ":::{.r-stack}\n",
        "![](fluree.png){.center width=\"1118\" height=\"626\"}\n",
        ":::\n",
        "\n",
        "[Converting Legacy Enterprise Data into Knowledge Graphs with AI and JSON LD | Eliud Polanco](https://youtu.be/KHNc0WwJ5JA?si=Z9YFCUVRXLyM47bH)\n",
        "\n",
        "\n",
        "## Aside: Curator AI's should be multimodal\n",
        "- Dr. Vardeman's Law: Data \"Lives\" in different locations and formats -- not every digital object can or should be in the KG layer. The Curator AI should \"Catalog\" this information.\n",
        "- Multimodal LLM's like AVIS can bridge that Gap!\n",
        "\n",
        "## Semantic AI-based Micro Services {.center}\n",
        "\n",
        "## How can we create \"Semantic Microservices\"\n",
        "\n",
        "::: {.r-stack}\n",
        "![](../nuggets_review/vision_of_agents.png){.center width=\"638\" height=\"800\"}\n",
        ":::\n",
        "[Tim Berners-Lee, James Hendler, and Ora Lassila. \"The Semantic Web.\" Scientific American 284, no. 5 (2001): 34--43. https://lassila.org/publications/2001/SciAm.html](https://lassila.org/publications/2001/SciAm.html)\n",
        "\n",
        "## Semantic Web \"Layer Cake\"\n",
        "::: {.r-stack}\n",
        "![](./lcake-evolution.png){.center width=\"1600\" height=\"483\"}\n",
        ":::\n",
        "[John Sowa, “Semantics.” n.d. Accessed October 17, 2023. https://www.jfsowa.com/ikl/.](https://www.jfsowa.com/ikl/)\n",
        "[Q92665](https://www.wikidata.org/wiki/Q92665)\n",
        "\n",
        "## Aside: Sowa's law of standards\n",
        ":::{.r-stack}\n",
        "\"Whenever a major organization develops a new system as an official standard for X, the primary result is the widespread adoption of some simpler system as a de facto standard for X.\"\n",
        ":::\n",
        "\n",
        "\n",
        "## Jano's Layer Cake\n",
        "\n",
        "::: {.r-stack}\n",
        "![](JANO-archiitecture.png){.center width=\"1110\" height=\"800\"}\n",
        ":::\n",
        "\n",
        "[Ontology Engineering: A View from the Trenches - WOP 2015 Keynote | PPT (slideshare.net)](https://www.slideshare.net/kjanowicz/ontology-engineering-a-view-from-the-trenches-wop-2015-keynote)\n",
        "\n",
        "\n",
        "## Distributed Knowledge Graph Layer Cake\n",
        ":::{.r-stack}\n",
        "![[DKG Basic Concepts](https://docs.origintrail.io/decentralized-knowledge-graph-layer-2/dkg-basic-concepts)](DKG_Knowledge_Asset.png){.center width=\"608\" height=\"800\"}\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## \"Web 2.0 Architecture -- Microservices\"\n",
        "![[RESTful web API design](https://learn.microsoft.com/en-us/azure/architecture/best-practices/api-design)](Azure-Rest.png)\n",
        "\n",
        "## Documenting REST-APIs\n",
        "\n",
        ":::{.r-stack}\n",
        "![[About Swagger Specification | Documentation | Swagger](https://swagger.io/docs/specification/about/)](swagger.png)\n",
        ":::\n",
        "\n",
        "## Example: HuggingFace Embedding Service\n",
        "![[A blazing fast inference solution for text embeddings models](https://github.com/huggingface/text-embeddings-inference)](hf-textembeddings.png)\n",
        "\n",
        "## Example: HuggingFace Embedding Service\n",
        "![[Text Generation Inference API](https://huggingface.github.io/text-embeddings-inference/)](hf-textembeddings-api.png)\n",
        "\n",
        "## OpenAI \"Plugins\"\n",
        "\n",
        "## Bridging Rest to AI using JSON-LD\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![](column-type-annotation.png)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"} \n",
        "![](column-type-results.png)\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "## JSON-LD 1.1\n",
        "\n",
        "## JSON as JSON-LD\n",
        "\n",
        "```{http}\n",
        "GET /ordinary-json-document.json HTTP/1.1\n",
        "Host: example.com\n",
        "Accept: application/ld+json,application/json,*/*;q=0.1\n",
        "\n",
        "====================================\n",
        "\n",
        "HTTP/1.1 200 OK\n",
        "...\n",
        "Content-Type: application/json\n",
        "Link: <https://json-ld.org/contexts/person.jsonld>; rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n",
        "\n",
        "{\n",
        "  \"name\": \"Markus Lanthaler\",\n",
        "  \"homepage\": \"http://www.markus-lanthaler.com/\",\n",
        "  \"image\": \"http://twitter.com/account/profile_image/markuslanthaler\"\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "## The problem with REST\n",
        "\n",
        "\n",
        "\n",
        "## Gorilla API: AI Learning REST Interfaces\n",
        "\n",
        "\n",
        "## \"Semantic APIs for KG's\"\n",
        "\n",
        "## Jano's ODP Bridge\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "## ChatGPT \"Plugin\" Architecture as Example\n",
        "\n",
        "* [ChatGPT plugins (openai.com)](https://openai.com/blog/chatgpt-plugins)\n",
        "* [Introduction - OpenAI API](https://platform.openai.com/docs/plugins/introduction)\n",
        "* [About Get a ChatGPT plugin up and running in under 5 minutes!](https://github.com/openai/plugins-quickstart)\n",
        "* [Use LangChain OpenAPI](https://python.langchain.com/docs/integrations/toolkits/openapi)\n",
        "* [ChatGPT Plugin -- LangChain](https://python.langchain.com/docs/integrations/retrievers/chatgpt-plugin)\n",
        "* [How to build a tool-using agent with LangChain](https://cookbook.openai.com/examples/how_to_build_a_tool-using_agent_with_langchain)\n",
        "\n",
        "\n",
        "## Example Service -- Retrieval Augmented Generation (We're not doing this yet!)\n",
        "\n",
        "::: {.r-stack}\n",
        "![](3M-munging-tool.png)\n",
        ":::\n",
        "\n",
        "* [Experiments in extracting tables from navy 3-M manual for OPNAV 4790/2K data structure Resources](https://github.com/nd-crane/decoder-ring)\n",
        "* [Sample KG construction using OPNAV forms 4790/ 2K as a schema template](https://github.com/nd-crane/2kilos-kg)\n",
        "* [Repository for formatting the Joint Electronics Type Designation System for ML and KG Usage](https://github.com/nd-crane/JETDS)\n",
        "* Likely needed to be stored in a Vector Store\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## SPARQL Interfaces\n",
        "\n",
        "## KG Interpretation in Contexts\n"
      ],
      "id": "d77c2a1f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
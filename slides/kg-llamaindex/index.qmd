---
title: "KG Construction"
author: "Charles F Vardeman II"
date: "2023-08-04"
embed-resources: true
format: 
    revealjs:
        slide-number: true
categories: [Knowledge Engineering,KG Construction, trustedAI]
---

## KG Construction Pipeline
![](graphic_kg-dev-pipeline.png){fig-align="center"}

## Unifying Large Language Models and Knowledge Graphs: A Roadmap
![](unifying_llm_kg.png){fig-align="center"}

::: footer
Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)
:::

## Unifying Large Language Models and Knowledge Graphs: A Roadmap
![](synergized_llm_kg.png){fig-align="center"}

::: footer
Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)
:::

## Unifying Large Language Models and Knowledge Graphs: A Roadmap
![](llm_kg_framework.png){fig-align="center"}

::: footer
Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)
:::

## Unifying Large Language Models and Knowledge Graphs: A Roadmap
![](llm_kg_construction.png){fig-align="center"}

::: footer
Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)
:::

## LLM KG Construction Frameworks Llamaindex {.center}

::: footer
Learn more: [Llamaindex](https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphDemo.html)
:::

## Rebel Large Model

```python
#| echo: true
from transformers import pipeline

triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')
# We need to use the tokenizer manually since we need special tokens.
extracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor("Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic", return_tensors=True, return_text=False)[0]["generated_token_ids"]])
print(extracted_text[0])
# Function to parse the generated text and extract the triplets
def extract_triplets(text):
    triplets = []
    relation, subject, relation, object_ = '', '', '', ''
    text = text.strip()
    current = 'x'
    for token in text.replace("<s>", "").replace("<pad>", "").replace("</s>", "").split():
        if token == "<triplet>":
            current = 't'
            if relation != '':
                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})
                relation = ''
            subject = ''
        elif token == "<subj>":
            current = 's'
            if relation != '':
                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})
            object_ = ''
        elif token == "<obj>":
            current = 'o'
            relation = ''
        else:
            if current == 't':
                subject += ' ' + token
            elif current == 's':
                object_ += ' ' + token
            elif current == 'o':
                relation += ' ' + token
    if subject != '' and relation != '' and object_ != '':
        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})
    return triplets
extracted_triplets = extract_triplets(extracted_text[0])
print(extracted_triplets)
```
::: footer
Learn more: [Rebel Large](https://huggingface.co/Babelscape/rebel-large)
:::



## LlamaIndex with Rebel
![](llamaindex_rebel.png){fig-align="center"}

::: footer
Learn more: [Llamaindex with Rebel Colab Notebook](https://colab.research.google.com/drive/1OO1JYe_uNN1XwW5fI1K_OyR4ohrYoYC3?usp=sharing)
:::

## LlamaIndex with Rebel and Neo4j
![](llamaindex_rebel.png){fig-align="center"}

::: footer
Learn more: [Neo4j Graph Store](https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/Neo4jKGIndexDemo.html)

GitHub: [Tomaz Bratanic](https://github.com/tomasonjo/blogs/blob/master/llm/Llamaindex-rebel-neo4j.ipynb)
:::


## Weaviate With Llama 2 and Llamaindex
![](weaviate_recipes.png){fig-align="center"}

::: footer
Learn more: [Welcome to the quick notebook on using Llama 2 ](https://github.com/weaviate/recipes/blob/main/integrations/llama2-demo/notebook.ipynb)
:::

## Weaviate "Knowledge Graphs"
![](weaviate_embeddings.png){fig-align="center"}

::: footer
Example: [NASA Graph-Enabled Vector Search](https://ntrs.nasa.gov/api/citations/20220018772/downloads/Short-AGU-GES-DISC%20Graph-Enabled%20Vector%20Search%20Updated.pdf)
:::

## Weaviate "Knowledge Graphs"
![](graph_vector_search.png){fig-align="center"}

::: footer
Example: [NASA Graph-Enabled Vector Search](https://ntrs.nasa.gov/api/citations/20220018772/downloads/Short-AGU-GES-DISC%20Graph-Enabled%20Vector%20Search%20Updated.pdf)
:::

## AWS Neptune
![](aws_neptune.png){fig-align="center"}

::: footer
Learn More: [Amazon Neptune](https://aws.amazon.com/neptune/)
:::

## Amazon Science ReFinED
![](refined_amazonscience.png){fig-align="center"}

::: footer
Paper: [ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking](https://arxiv.org/abs/2207.04108)

Paper: [Improving Entity Disambiguation by Reasoning over a Knowledge Base](https://arxiv.org/pdf/2207.04106.pdf)

GitHub: [Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering](https://github.com/amazon-science/ReFinED)
:::

## Amazon Science KGQA
![](kgqa_amazonscience.png){fig-align="center"}

::: footer
Website: [Language models as controlled natural language semantic parsers for knowledge graph question answering](https://www.amazon.science/publications/language-models-as-controlled-natural-language-semantic-parsers-for-knowledge-graph-question-answering)
GitHub: [Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering](https://github.com/NIMI-research/CNL_KGQA)
:::
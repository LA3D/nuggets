{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"KG Construction\"\n",
        "author: \"Charles F Vardeman II\"\n",
        "date: \"2023-08-02\"\n",
        "embed-resources: true\n",
        "format: \n",
        "    revealjs:\n",
        "        slide-number: true\n",
        "categories: [Knowledge Engineering,KG Construction, trustedAI]\n",
        "---"
      ],
      "id": "6d73b5da"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## KG Construction Pipeline\n",
        "![](graphic_kg-dev-pipeline.png){fig-align=\"center\"}\n",
        "\n",
        "## Unifying Large Language Models and Knowledge Graphs: A Roadmap\n",
        "![](unifying_llm_kg.png){fig-align=\"center\"}\n",
        "\n",
        "::: footer\n",
        "Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)\n",
        ":::\n",
        "\n",
        "## Unifying Large Language Models and Knowledge Graphs: A Roadmap\n",
        "![](synergized_llm_kg.png){fig-align=\"center\"}\n",
        "\n",
        "::: footer\n",
        "Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)\n",
        ":::\n",
        "\n",
        "## Unifying Large Language Models and Knowledge Graphs: A Roadmap\n",
        "![](llm_kg_framework.png){fig-align=\"center\"}\n",
        "\n",
        "::: footer\n",
        "Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)\n",
        ":::\n",
        "\n",
        "## Unifying Large Language Models and Knowledge Graphs: A Roadmap\n",
        "![](llm_kg_construction.png){fig-align=\"center\"}\n",
        "\n",
        "::: footer\n",
        "Learn more: [ArXiv Paper](https://arxiv.org/abs/2306.08302)\n",
        ":::\n",
        "\n",
        "## LLM KG Construction Frameworks\n",
        "\n",
        "::: footer\n",
        "Learn more: [Llamaindex](https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/KnowledgeGraphDemo.html)\n",
        ":::\n",
        "\n",
        "## Rebel Large Model\n",
        "![](llamaindex_rebel.png){fig-align=\"center\"}\n"
      ],
      "id": "d0456018"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from transformers import pipeline\n",
        "\n",
        "triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n",
        "# We need to use the tokenizer manually since we need special tokens.\n",
        "extracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\n",
        "print(extracted_text[0])\n",
        "# Function to parse the generated text and extract the triplets\n",
        "def extract_triplets(text):\n",
        "    triplets = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
        "        if token == \"<triplet>\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"<subj>\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "            object_ = ''\n",
        "        elif token == \"<obj>\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "    return triplets\n",
        "extracted_triplets = extract_triplets(extracted_text[0])\n",
        "print(extracted_triplets)"
      ],
      "id": "98efad65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: footer\n",
        "Learn more: [Rebel Large](https://huggingface.co/Babelscape/rebel-large)\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## LlamaIndex with Rebel\n",
        "![](llamaindex_rebel.png){fig-align=\"center\"}\n",
        "\n",
        "::: footer\n",
        "Learn more: [Llamaindex with Rebel Colab Notebook](https://colab.research.google.com/drive/1OO1JYe_uNN1XwW5fI1K_OyR4ohrYoYC3?usp=sharing)\n",
        ":::"
      ],
      "id": "381cfdff"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
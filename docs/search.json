[
  {
    "objectID": "instruction_prompt.html",
    "href": "instruction_prompt.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "ChatGPT, please assist in drafting a blog post for AI Success Factors: Engineering Trust in Deployments. As a generative AI, your input serves as a starting point for discussion and is meticulously reviewed and edited by a team of AI researchers at the Laboratory for Assured AI Applications Development at the University of Notre Dame’s Center for Research Computing.\nThe intended audience includes students, professionals, and enthusiasts interested in the progression of AI, with a focus on the successful deployment of AI technologies. Each post aims to disseminate recent advancements and knowledge in AI, particularly in the fields of AI engineering, trust in AI, and knowledge engineering.\nFor this post, please generate content on the importance of trust in successful AI deployments. Begin with a general introduction to AI deployments, transition into the crucial role of trust, and provide real-world examples where the absence of trust led to issues. Discuss strategies for building trust in AI systems and conclude with insights on future trends in trust within the AI landscape. The tone should be academic yet accessible to our diverse readership."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "href": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing and CI/CD for Trusted AI",
    "text": "Testing and CI/CD for Trusted AI\nTesting and CI/CD are software engineering practices that aim to ensure the quality, reliability, and security of software applications. They are especially important for AI applications, which involve complex and dynamic data, models, and algorithms."
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "href": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What is Software 1.0 and Software 2.0?",
    "text": "What is Software 1.0 and Software 2.0?\nSoftware 1.0 refers to the traditional way of developing software by writing code that specifies the logic and rules of the application. Software 2.0 refers to the emerging way of developing software by using machine learning (ML) models that learn from data and generate code or behavior."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why do we need testing and CI/CD for AI?",
    "text": "Why do we need testing and CI/CD for AI?\nAI applications pose unique challenges and risks for testing and CI/CD, such as:\n\nData quality and availability: AI applications depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: AI models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: AI applications may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "href": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing and CI/CD can help address these challenges and risks by:",
    "text": "Testing and CI/CD can help address these challenges and risks by:\n\nAutomating and streamlining the data, model, and code workflows of AI development\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in AI applications\nEnsuring that AI applications meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of AI applications"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How do we implement testing and CI/CD for AI?",
    "text": "How do we implement testing and CI/CD for AI?\nTesting and CI/CD for AI involve applying software engineering best practices to the data, model, and code components of AI applications. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing AI models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of AI models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates AI models"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Real World Machine Learning “Pipelines”",
    "text": "Real World Machine Learning “Pipelines”\n\n\nTwitter: Andrej Karpathy\nLearn More: Autonomous Vehicle Training & Tesla’s Data Engine Explained, TESLA’S DATA ENGINE AND WHAT WE SHOULD LEARN FROM IT CVPR’20 Workshop on Scalability in Autonomous Driving Keynote - Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Real World Machine Learning “Data Engine”",
    "text": "Real World Machine Learning “Data Engine”\n\n\nTwitter: Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "href": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How Tesla’s Data Engine works",
    "text": "How Tesla’s Data Engine works\n\nThe FSD computer in each Tesla car records and sends any inaccuracies or discrepancies between its actions and the human driver’s actions to Tesla’s servers.\nTesla’s servers use these inaccuracies to create unit tests, which are scenarios that the FSD neural network should be able to handle correctly.\nTesla’s servers also use these inaccuracies to search for similar situations in the vast amount of data collected from all the cars in the fleet and create a well-labeled dataset.\nTesla’s servers use this dataset to re-train the FSD neural network using machine learning algorithms and improve its performance and functionality.\nTesla’s servers deploy the updated FSD neural network to the cars’ FSD computers in “shadow mode” to compare its actions with the human driver’s actions."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "href": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why Tesla’s Data Engine matters",
    "text": "Why Tesla’s Data Engine matters\n\nTesla’s Data Engine allows them to leverage the power of big data analytics and artificial intelligence in their self-driving cars.\nTesla’s Data Engine enables them to address the long tail problem of autonomous driving, which is the challenge of handling rare or complex situations on the road.\nTesla’s Data Engine ensures that the FSD neural network is constantly improving and not regressing or introducing new errors.\n\n\nLearn More: [Tesla’s Data Engine and what we should learn from it]"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "href": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What is “Testing” for AI vs Traditional Software Testing",
    "text": "What is “Testing” for AI vs Traditional Software Testing\n\n\nLearn More: Effective testing for machine learning systems\nYoutube Discussion: MLOps Chat: How Should We Test ML Models? with Data Scientist Jeremy Jordan"
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why do we need testing for ML systems?",
    "text": "Why do we need testing for ML systems?\nML systems pose unique challenges and risks for testing, such as:\n\nData quality and availability: ML systems depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: ML models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: ML systems may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability.\n\nTesting ML systems can help address these challenges and risks by:\n\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in ML systems\nEnsuring that ML systems meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of ML systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "href": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How do we test ML systems?",
    "text": "How do we test ML systems?\nTesting ML systems involves applying software engineering best practices to the data, model, and code components of ML systems. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing ML models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of ML models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates ML models"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "href": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What are some tools and techniques for testing ML systems?",
    "text": "What are some tools and techniques for testing ML systems?\nThere are different tools and techniques that can help us test ML systems effectively and efficiently. Some examples are:\n\nData validation tools: Tools that help us check the schema, statistics, anomalies, drifts, and distributions of our data. For example: TensorFlow Data Validation, Great Expectations, Deequ.\nModel validation tools: Tools that help us measure the performance of our models on various metrics and scenarios. For example: TensorFlow Model Analysis, Scikit-Learn, PyTorch.\nCode validation tools: Tools that help us check the syntax, style, coverage, complexity, and security of our code. For example: PyLint, PyTest, Bandit."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "href": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing “Software 1.0” vs “Software 2.0”",
    "text": "Testing “Software 1.0” vs “Software 2.0”\n\n\nLearn More: Effective testing for machine learning systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "href": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "“Beyond Accuracy: Behavioral Testing of NLP Models with CheckList”",
    "text": "“Beyond Accuracy: Behavioral Testing of NLP Models with CheckList”\n\n\nLearn More: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\nGitHub:Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Examples of “real world” testing",
    "text": "Examples of “real world” testing\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Examples of “real world” testing as a starting point",
    "text": "Examples of “real world” testing as a starting point\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "href": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Test Structure in the Microsoft Recommenders",
    "text": "Test Structure in the Microsoft Recommenders\nThe Microsoft Recommenders repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repository also includes various tests to ensure the quality, reliability, and security of the code and the notebooks."
  },
  {
    "objectID": "slides/tai_testing/index.html#types-of-tests",
    "href": "slides/tai_testing/index.html#types-of-tests",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Types of Tests",
    "text": "Types of Tests\nThere are three types of tests in the Microsoft Recommenders repository:\n\nUnit tests: These are tests that check the functionality and correctness of individual modules, functions, or classes. They are located in the unit folder and use pytest as the testing framework. They are triggered by pull requests to the main or staging branches.\nSmoke tests: These are tests that check if the notebooks can run without errors and produce the expected outputs. They are located in the smoke folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches.\nIntegration tests: These are tests that check if the notebooks can run end-to-end on different environments and platforms, such as CPU, GPU, or Spark. They are located in the integration folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Azure DevOps",
    "text": "Testing Infrastructure: Azure DevOps\nThe Microsoft Recommenders repository uses Azure DevOps as the testing infrastructure. Azure DevOps is a cloud-based platform that provides various services and tools for software development, such as version control, project management, testing, deployment, and monitoring.\nThere are 19 pipelines for Linux tests and 19 pipelines for Windows tests, each corresponding to a different type of test, branch, and environment. For example:\n\nunit_tests: This pipeline runs unit tests on Linux CPU for pull requests to the main branch.\nunit_tests_staging: This pipeline runs unit tests on Linux CPU for pull requests to the staging branch.\ngpu_unit_tests: This pipeline runs unit tests on Linux GPU for pull requests to the main branch.\ngpu_unit_tests_staging: This pipeline runs unit tests on Linux GPU for pull requests to the staging branch.\nnightly_cpu: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the main branch.\nnightly_staging: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the staging branch.\nnightly_gpu: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the main branch.\nnightly_gpu_staging: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the staging branch.\nnightly_spark: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the main branch.\nnightly_spark_staging: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the staging branch.\n\n\nLearn More: [Test Strategy · microsoft/recommenders Wiki · GitHub]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "href": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Conda Environments",
    "text": "Testing Infrastructure: Conda Environments\nThe pipelines use conda environments to manage dependencies and run tests. Conda is an open-source package and environment management system that allows us to create and use different configurations of software packages and libraries.\nA script, generate_conda_file.py, is used to create conda environments for different combinations of CPU, GPU, and Spark. For example:\n\nreco_base: This is the basic CPU environment.\nreco_full: This is the environment that includes CPU, GPU, and Spark.\nreco_gpu: This is the environment that includes CPU and GPU.\nreco_pyspark: This is the environment that includes CPU and Spark.\n\n\nLearn More: [Conda — Conda documentation]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Azure Machine Learning",
    "text": "Testing Infrastructure: Azure Machine Learning\nThe pipelines also use Azure Machine Learning (AML) to run some of the tests on different compute clusters. AML is a cloud-based service that provides various tools and features for ML development, such as data preparation, model training, model deployment, model management, and model monitoring.\nAML provides scalable and flexible compute resources for ML development. For example:\n\nAMLCompute clustername Experiment VM Nodes\nreco-cpu-test2 cpu_unit_tests standard_d3_v2 0..4\nreco-gpu-test gpu_unit_tests standard_nc6_v3 0..4\nreco-spark-test spark_unit_tests standard_d12_v2 0..4\n\n\nLearn More: [What is Azure Machine Learning? - Azure Machine Learning | Microsoft Docs]"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPT’s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPT’s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Tracking LLM “Agent Abilities”",
    "text": "Tracking LLM “Agent Abilities”\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Tracking LLM “Agent Abilities”",
    "text": "Tracking LLM “Agent Abilities”\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing in the context of CI/CD",
    "text": "Testing in the context of CI/CD\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing in the context of SBoMs",
    "text": "Testing in the context of SBoMs\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#other-updates",
    "href": "slides/tai_testing/index.html#other-updates",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Other Updates",
    "text": "Other Updates"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai",
    "href": "slides/tai_testing/index.html#juypter-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter\nGitHub: A generative AI extension for JupyterLab"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai-1",
    "href": "slides/tai_testing/index.html#juypter-ai-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter"
  },
  {
    "objectID": "slides/tai_testing/index.html#kaggle-llm-resource",
    "href": "slides/tai_testing/index.html#kaggle-llm-resource",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Kaggle LLM Resource",
    "text": "Kaggle LLM Resource\n\n\nLearn More: Getting Started With LLMs"
  },
  {
    "objectID": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "href": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Prompt Enginnering Guide",
    "text": "Prompt Enginnering Guide\n\n\nLearn More: Prompt Engineering Guide"
  },
  {
    "objectID": "slides/holiday_2023/index.html#goal-to-help-prepare-you-for-those-difficult-holiday-conversations",
    "href": "slides/holiday_2023/index.html#goal-to-help-prepare-you-for-those-difficult-holiday-conversations",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Goal: To help prepare you for those difficult holiday conversations…",
    "text": "Goal: To help prepare you for those difficult holiday conversations…"
  },
  {
    "objectID": "slides/holiday_2023/index.html#like-how-does-chatgpt-work",
    "href": "slides/holiday_2023/index.html#like-how-does-chatgpt-work",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Like: How does ChatGPT work?",
    "text": "Like: How does ChatGPT work?"
  },
  {
    "objectID": "slides/holiday_2023/index.html#karpathy-the-busy-persons-intro-to-llms",
    "href": "slides/holiday_2023/index.html#karpathy-the-busy-persons-intro-to-llms",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Karpathy: The busy person’s intro to LLMs",
    "text": "Karpathy: The busy person’s intro to LLMs\n\nKarpathy LLM: YouTube LinkReading List For Andrej Karpathy’s “Intro to Large Language Models” Video"
  },
  {
    "objectID": "slides/holiday_2023/index.html#pay-attention-to-the-section-on-llm-security-at-the-end-of-the-talk.",
    "href": "slides/holiday_2023/index.html#pay-attention-to-the-section-on-llm-security-at-the-end-of-the-talk.",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Pay attention to the section on LLM security at the end of the talk.",
    "text": "Pay attention to the section on LLM security at the end of the talk."
  },
  {
    "objectID": "slides/holiday_2023/index.html#making-llms-uncool-language-warning",
    "href": "slides/holiday_2023/index.html#making-llms-uncool-language-warning",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Making LLMs “uncool” (Language Warning)",
    "text": "Making LLMs “uncool” (Language Warning)\n\nMaking Large Language Models Uncool Again: Youtube"
  },
  {
    "objectID": "slides/holiday_2023/index.html#uncool-takeaways",
    "href": "slides/holiday_2023/index.html#uncool-takeaways",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Uncool “takeaways”",
    "text": "Uncool “takeaways”\n\n~30b parameter models a missed opportunity\nWe are “fine-tuning” wrong\nUncertainty future directions for small (fine-tuned) vs large (API) models\nLLM architecture not the path to AG(S)I"
  },
  {
    "objectID": "slides/holiday_2023/index.html#deep-dive-into-understanding-llms",
    "href": "slides/holiday_2023/index.html#deep-dive-into-understanding-llms",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Deep dive into understanding LLMs",
    "text": "Deep dive into understanding LLMs\n\nWhat is ChatGPT doing…and why does it work? Youtube"
  },
  {
    "objectID": "slides/holiday_2023/index.html#ai-engineering",
    "href": "slides/holiday_2023/index.html#ai-engineering",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "AI Engineering",
    "text": "AI Engineering"
  },
  {
    "objectID": "slides/holiday_2023/index.html#openai-dev-day-llm-performance-talk",
    "href": "slides/holiday_2023/index.html#openai-dev-day-llm-performance-talk",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "OpenAI Dev Day LLM Performance Talk",
    "text": "OpenAI Dev Day LLM Performance Talk\n\n\n\n\nA Survey of Techniques for Maximizing LLM Performance"
  },
  {
    "objectID": "slides/holiday_2023/index.html#techniques-for-increasing-llm-performance",
    "href": "slides/holiday_2023/index.html#techniques-for-increasing-llm-performance",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Techniques for increasing LLM Performance",
    "text": "Techniques for increasing LLM Performance"
  },
  {
    "objectID": "slides/holiday_2023/index.html#patterns-for-ai-engineering",
    "href": "slides/holiday_2023/index.html#patterns-for-ai-engineering",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Patterns for AI Engineering",
    "text": "Patterns for AI Engineering\n\nBuilding Blocks for LLM Systems & Products: Eugene YanPatterns for Building LLM-based Systems & Products"
  },
  {
    "objectID": "slides/holiday_2023/index.html#rag-in-production",
    "href": "slides/holiday_2023/index.html#rag-in-production",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "RAG in Production",
    "text": "RAG in Production\n\nBuilding Production-Ready RAG Applications: Jerry Liu"
  },
  {
    "objectID": "slides/holiday_2023/index.html#the-need-for-guardrails",
    "href": "slides/holiday_2023/index.html#the-need-for-guardrails",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "The need for “Guardrails”",
    "text": "The need for “Guardrails”\n\nTrust, but Verify: Shreya Rajpal"
  },
  {
    "objectID": "slides/holiday_2023/index.html#a-firewall-for-your-llm",
    "href": "slides/holiday_2023/index.html#a-firewall-for-your-llm",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "A “firewall” for your LLM",
    "text": "A “firewall” for your LLM\n\nTrust, but Verify: Shreya Rajpal"
  },
  {
    "objectID": "slides/holiday_2023/index.html#nuggets-for-the-week",
    "href": "slides/holiday_2023/index.html#nuggets-for-the-week",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Nuggets for the week…",
    "text": "Nuggets for the week…"
  },
  {
    "objectID": "slides/holiday_2023/index.html#one-year-of-chatgpt",
    "href": "slides/holiday_2023/index.html#one-year-of-chatgpt",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "One Year of ChatGPT!",
    "text": "One Year of ChatGPT!\n\nChen, Hailin, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen Zhao, Caiming Xiong, and Shafiq Joty. 2023. “ChatGPT’s One-Year Anniversary: Are Open-Source Large Language Models Catching Up?” arXiv. http://arxiv.org/abs/2311.16989."
  },
  {
    "objectID": "slides/holiday_2023/index.html#llm-capabilities",
    "href": "slides/holiday_2023/index.html#llm-capabilities",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "LLM Capabilities",
    "text": "LLM Capabilities\n\nChen, Hailin, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen Zhao, Caiming Xiong, and Shafiq Joty. 2023. “ChatGPT’s One-Year Anniversary: Are Open-Source Large Language Models Catching Up?” arXiv. http://arxiv.org/abs/2311.16989."
  },
  {
    "objectID": "slides/holiday_2023/index.html#agent-capabilities",
    "href": "slides/holiday_2023/index.html#agent-capabilities",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Agent Capabilities",
    "text": "Agent Capabilities\n\nChen, Hailin, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen Zhao, Caiming Xiong, and Shafiq Joty. 2023. “ChatGPT’s One-Year Anniversary: Are Open-Source Large Language Models Catching Up?” arXiv. http://arxiv.org/abs/2311.16989."
  },
  {
    "objectID": "slides/holiday_2023/index.html#model-consistency",
    "href": "slides/holiday_2023/index.html#model-consistency",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Model Consistency",
    "text": "Model Consistency\n\nChen, Lingjiao, Matei Zaharia, and James Zou. 2023. “How Is ChatGPT’s Behavior Changing over Time?” arXiv. https://doi.org/10.48550/arXiv.2307.09009."
  },
  {
    "objectID": "slides/holiday_2023/index.html#model-consistency-over-time",
    "href": "slides/holiday_2023/index.html#model-consistency-over-time",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Model Consistency over time",
    "text": "Model Consistency over time\n\nChen, Lingjiao, Matei Zaharia, and James Zou. 2023. “How Is ChatGPT’s Behavior Changing over Time?” arXiv. https://doi.org/10.48550/arXiv.2307.09009."
  },
  {
    "objectID": "slides/holiday_2023/index.html#mixture-of-experts-moe",
    "href": "slides/holiday_2023/index.html#mixture-of-experts-moe",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Mixture of Experts (MoE)",
    "text": "Mixture of Experts (MoE)"
  },
  {
    "objectID": "slides/holiday_2023/index.html#moe",
    "href": "slides/holiday_2023/index.html#moe",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "MoE",
    "text": "MoE"
  },
  {
    "objectID": "slides/holiday_2023/index.html#agent-memory",
    "href": "slides/holiday_2023/index.html#agent-memory",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Agent Memory",
    "text": "Agent Memory\n\nAdding Long Term Memory to OpenGPTs"
  },
  {
    "objectID": "slides/holiday_2023/index.html#long-term-memory",
    "href": "slides/holiday_2023/index.html#long-term-memory",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Long Term Memory",
    "text": "Long Term Memory\n\nAdding Long Term Memory to OpenGPTs"
  },
  {
    "objectID": "slides/holiday_2023/index.html#determinism-vs-stochasticity",
    "href": "slides/holiday_2023/index.html#determinism-vs-stochasticity",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "Determinism vs Stochasticity?",
    "text": "Determinism vs Stochasticity?\n\nDeterminism through RAG and Tool use\nTool code created by LLM based Co-pilots or Agents\nWhat “Programming Language” should we use for the deterministic part?\nWe don’t have an integrated paradigm for what “systems engineering” means in a age of AIs"
  },
  {
    "objectID": "slides/holiday_2023/index.html#for-after-christmas",
    "href": "slides/holiday_2023/index.html#for-after-christmas",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "For after Christmas…",
    "text": "For after Christmas…"
  },
  {
    "objectID": "slides/holiday_2023/index.html#the-end-of-programming",
    "href": "slides/holiday_2023/index.html#the-end-of-programming",
    "title": "Dr V. Holiday 2023 Viewing Guide",
    "section": "The end of Programming?",
    "text": "The end of Programming?\n\n\n\nLarge Language Models and The End of Programming - CS50 Tech Talk with Dr. Matt Welsh"
  },
  {
    "objectID": "slides/fall24_references/index.html#advances-in-agent-based-big-ai-nuggets-from-spring-and-summer",
    "href": "slides/fall24_references/index.html#advances-in-agent-based-big-ai-nuggets-from-spring-and-summer",
    "title": "Advances in Agent-Based Big AI",
    "section": "Advances in Agent-Based Big AI: Nuggets from Spring and Summer",
    "text": "Advances in Agent-Based Big AI: Nuggets from Spring and Summer\n\nWelcome back, everyone!\nOverview of today’s presentation:\n\nLatest advancements in conversational and agentic AI.\nNotable updates from OpenAI and Google DeepMind.\nInsights into agentic patterns and workflows.\nInnovations in Graph-based retrieval models.\nNew frameworks like SciAgents and “HippoRAG”."
  },
  {
    "objectID": "slides/fall24_references/index.html#advances-in-conversational-agentic-ai",
    "href": "slides/fall24_references/index.html#advances-in-conversational-agentic-ai",
    "title": "Advances in Agent-Based Big AI",
    "section": "Advances in Conversational Agentic AI",
    "text": "Advances in Conversational Agentic AI"
  },
  {
    "objectID": "slides/fall24_references/index.html#key-developments",
    "href": "slides/fall24_references/index.html#key-developments",
    "title": "Advances in Agent-Based Big AI",
    "section": "Key Developments",
    "text": "Key Developments\n\nConversational and Agentic AI:\n\nEnhancements in dialogue management and contextual understanding.\nImproved interaction capabilities, especially in handling complex, multi-turn conversations.\n\nOpenAI’s Updates:\n\nIntroduction of advanced multimodal models.\nFocus on integrating visual and text-based inputs for richer interactions.\nExpanded capabilities in workflow automation using AI agents.\nSpecial Purpose Reasoning Model\n\nImpact:\n\nBroader applications in customer service, virtual assistants, and content creation.\nBetter adaptability in real-world scenarios requiring nuanced understanding and interaction."
  },
  {
    "objectID": "slides/fall24_references/index.html#rise-of-conversational-ai-openai",
    "href": "slides/fall24_references/index.html#rise-of-conversational-ai-openai",
    "title": "Advances in Agent-Based Big AI",
    "section": "Rise of ‘Conversational AI’ – OpenAI",
    "text": "Rise of ‘Conversational AI’ – OpenAI\n\n“Hello GPT-4o.” n.d. Accessed September 3, 2024.."
  },
  {
    "objectID": "slides/fall24_references/index.html#project-astra-by-google-deepmind",
    "href": "slides/fall24_references/index.html#project-astra-by-google-deepmind",
    "title": "Advances in Agent-Based Big AI",
    "section": "Project Astra by Google DeepMind",
    "text": "Project Astra by Google DeepMind\n\n“Project Astra.” 2024. Google DeepMind. August 22, 2024.."
  },
  {
    "objectID": "slides/fall24_references/index.html#slide3-id",
    "href": "slides/fall24_references/index.html#slide3-id",
    "title": "Advances in Agent-Based Big AI",
    "section": "",
    "text": "“Gemini Makes Your Mobile Device a Powerful AI Assistant.” 2024. Google. August 13, 2024.."
  },
  {
    "objectID": "slides/fall24_references/index.html#project-astra-by-google-deepmind-1",
    "href": "slides/fall24_references/index.html#project-astra-by-google-deepmind-1",
    "title": "Advances in Agent-Based Big AI",
    "section": "Project Astra by Google DeepMind",
    "text": "Project Astra by Google DeepMind\n\nOverview:\n\nAims to develop proactive, teachable AI assistants.\nFocus on integrating seamlessly across devices and platforms.\n\nKey Features:\n\nMultimodal AI that understands and processes inputs like text, images, and audio.\nAdvanced context-awareness to anticipate user needs and provide relevant assistance.\n\nPotential Applications:\n\nCould revolutionize how users interact with technology, making AI more accessible and useful in everyday tasks."
  },
  {
    "objectID": "slides/fall24_references/index.html#multi-modal-ai-models-in-conversational-agents",
    "href": "slides/fall24_references/index.html#multi-modal-ai-models-in-conversational-agents",
    "title": "Advances in Agent-Based Big AI",
    "section": "Multi-Modal AI Models in Conversational Agents",
    "text": "Multi-Modal AI Models in Conversational Agents"
  },
  {
    "objectID": "slides/fall24_references/index.html#driving-the-development-of-conversational-agents",
    "href": "slides/fall24_references/index.html#driving-the-development-of-conversational-agents",
    "title": "Advances in Agent-Based Big AI",
    "section": "Driving the Development of Conversational Agents",
    "text": "Driving the Development of Conversational Agents\n\nWhat are Multi-Modal AI Models?\n\nAI models that process and integrate multiple types of data, such as text, images, audio, and video.\nExamples include OpenAI’s GPT-4, Google’s Gemini, and DeepMind’s Project Astra.\n\nKey Advantages:\n\nEnhanced Understanding: Ability to comprehend context from multiple data sources simultaneously, improving the accuracy and relevance of responses.\nRicher Interactions: Enables more natural and intuitive interactions by combining visual, auditory, and textual cues.\nBroader Applications: From customer service to personal assistants, these models are making AI interactions more versatile and effective."
  },
  {
    "objectID": "slides/fall24_references/index.html#driving-the-development-of-conversational-agents-1",
    "href": "slides/fall24_references/index.html#driving-the-development-of-conversational-agents-1",
    "title": "Advances in Agent-Based Big AI",
    "section": "Driving the Development of Conversational Agents",
    "text": "Driving the Development of Conversational Agents\n\nImpact on Conversational Agents:\n\nImproved Contextual Awareness: Agents can better understand user needs by interpreting a broader range of input signals.\nGreater Personalization: Tailors interactions to individual users by understanding nuances in visual and audio inputs.\nAdvanced Capabilities: Supports complex tasks such as visual question answering, interactive storytelling, and multimodal search."
  },
  {
    "objectID": "slides/fall24_references/index.html#driving-the-development-of-conversational-agents-2",
    "href": "slides/fall24_references/index.html#driving-the-development-of-conversational-agents-2",
    "title": "Advances in Agent-Based Big AI",
    "section": "Driving the Development of Conversational Agents",
    "text": "Driving the Development of Conversational Agents\n\nExamples and Applications:\n\nVirtual Assistants: Google Assistant and Amazon Alexa integrating voice and image recognition for smart home management.\nCustomer Service: Chatbots that can handle text and visual content, enhancing user experience in e-commerce and tech support.\n\nFuture Directions:\n\nOngoing research aims to further refine these models, making them more efficient and capable of real-time, multimodal interactions.\nPotential for applications in areas like education, healthcare, and entertainment where diverse data types are crucial."
  },
  {
    "objectID": "slides/fall24_references/index.html#mistral-pixtral-12b",
    "href": "slides/fall24_references/index.html#mistral-pixtral-12b",
    "title": "Advances in Agent-Based Big AI",
    "section": "Mistral Pixtral 12B",
    "text": "Mistral Pixtral 12B\n\nMistral releases Pixtral 12B, its first multimodal model"
  },
  {
    "objectID": "slides/fall24_references/index.html#overview-of-pixtral-12b",
    "href": "slides/fall24_references/index.html#overview-of-pixtral-12b",
    "title": "Advances in Agent-Based Big AI",
    "section": "Overview of Pixtral 12B",
    "text": "Overview of Pixtral 12B\n\nIntroduction:\n\nMistral’s first multimodal AI model, capable of processing both text and images.\nBuilt on the Nemo 12B text model with an additional 400 million-parameter vision adapter.\n\nCapabilities:\n\nPerforms tasks such as image captioning, object counting, and answering image-related queries.\nVision encoding allows the model to “see” and process visual data alongside textual inputs."
  },
  {
    "objectID": "slides/fall24_references/index.html#overview-of-pixtral-12b-1",
    "href": "slides/fall24_references/index.html#overview-of-pixtral-12b-1",
    "title": "Advances in Agent-Based Big AI",
    "section": "Overview of Pixtral 12B",
    "text": "Overview of Pixtral 12B\n\nOpen Weights and Accessibility:\n\nModel parameters and code are available on GitHub and Hugging Face.\nMistral is considering making Pixtral 12B available under an open-source license to encourage wider use and development.\n\nImpact:\n\nProvides a competitive alternative to models from OpenAI, Google, and other leading AI developers.\nEncourages the development of applications requiring both visual and textual data processing."
  },
  {
    "objectID": "slides/fall24_references/index.html#google-datagemma",
    "href": "slides/fall24_references/index.html#google-datagemma",
    "title": "Advances in Agent-Based Big AI",
    "section": "Google DataGemma",
    "text": "Google DataGemma\n\nDataGemma: Using real-world data to address AI hallucinations"
  },
  {
    "objectID": "slides/fall24_references/index.html#google-datagemma-schema.org-and-kgs",
    "href": "slides/fall24_references/index.html#google-datagemma-schema.org-and-kgs",
    "title": "Advances in Agent-Based Big AI",
    "section": "Google DataGemma Schema.org and KGs",
    "text": "Google DataGemma Schema.org and KGs\n\nRadhakrishnan, Prashanth, Jennifer Chen, Bo Xu, Prem Ramaswami, Adriana Olmos, James Manyika, and R V Guha. n.d. “Knowing When to Ask - Bridging Large Language Models and Data.”"
  },
  {
    "objectID": "slides/fall24_references/index.html#models-that-can-reason",
    "href": "slides/fall24_references/index.html#models-that-can-reason",
    "title": "Advances in Agent-Based Big AI",
    "section": "Models that Can “Reason”?",
    "text": "Models that Can “Reason”?\n\nIntroducing OpenAI o1-preview: A new series of reasoning models for solving hard problems."
  },
  {
    "objectID": "slides/fall24_references/index.html#gpt-4o1",
    "href": "slides/fall24_references/index.html#gpt-4o1",
    "title": "Advances in Agent-Based Big AI",
    "section": "GPT-4o1",
    "text": "GPT-4o1\n\n“Notes on OpenAI’s New O1 Chain-of-Thought Models.” n.d. Accessed September 13, 2024. https://simonwillison.net/2024/Sep/12/openai-o1/."
  },
  {
    "objectID": "slides/fall24_references/index.html#agentic-patterns-and-workflows",
    "href": "slides/fall24_references/index.html#agentic-patterns-and-workflows",
    "title": "Advances in Agent-Based Big AI",
    "section": "Agentic Patterns and Workflows",
    "text": "Agentic Patterns and Workflows"
  },
  {
    "objectID": "slides/fall24_references/index.html#generative-agents",
    "href": "slides/fall24_references/index.html#generative-agents",
    "title": "Advances in Agent-Based Big AI",
    "section": "Generative Agents",
    "text": "Generative Agents\n\nGenerative Agents: Interactive Simulacra of Human Behavior\nGoogle Illuminate AI Discussion"
  },
  {
    "objectID": "slides/fall24_references/index.html#llms-based-autonomous-agents",
    "href": "slides/fall24_references/index.html#llms-based-autonomous-agents",
    "title": "Advances in Agent-Based Big AI",
    "section": "LLMs Based Autonomous Agents",
    "text": "LLMs Based Autonomous Agents\n\nWang, Lei, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, et al. 2024. “A Survey on Large Language Model Based Autonomous Agents.” Frontiers of Computer Science 18 (6): 186345. https://doi.org/10.1007/s11704-024-40231-1.\nGoogle Illuminate AI Discussion"
  },
  {
    "objectID": "slides/fall24_references/index.html#andrew-ngs-contributions-to-agentic-ai",
    "href": "slides/fall24_references/index.html#andrew-ngs-contributions-to-agentic-ai",
    "title": "Advances in Agent-Based Big AI",
    "section": "Andrew Ng’s Contributions to Agentic AI",
    "text": "Andrew Ng’s Contributions to Agentic AI\n\nWhat’s next for AI agentic workflows ft. Andrew Ng of AI Fund"
  },
  {
    "objectID": "slides/fall24_references/index.html#andrew-ngs-contributions-to-agentic-ai-1",
    "href": "slides/fall24_references/index.html#andrew-ngs-contributions-to-agentic-ai-1",
    "title": "Advances in Agent-Based Big AI",
    "section": "Andrew Ng’s Contributions to Agentic AI",
    "text": "Andrew Ng’s Contributions to Agentic AI\n\nCore Design Patterns:\n\nReflection: Agents improve by critiquing their own outputs and iterating.\nTool Use: Integration of external tools for enhanced task performance.\nPlanning: Agents develop and follow strategic plans to achieve goals.\nMulti-agent Collaboration: Systems of agents working together to solve complex problems.\n\nImpact:\n\nEnhanced robustness and adaptability of AI systems.\nFacilitates more effective problem-solving in dynamic environments."
  },
  {
    "objectID": "slides/fall24_references/index.html#agentic-workflows-in-2024-the-ultimate-guide",
    "href": "slides/fall24_references/index.html#agentic-workflows-in-2024-the-ultimate-guide",
    "title": "Advances in Agent-Based Big AI",
    "section": "Agentic Workflows in 2024: The ultimate guide",
    "text": "Agentic Workflows in 2024: The ultimate guide\n\nAgentic Workflows in 2024: The ultimate guide"
  },
  {
    "objectID": "slides/fall24_references/index.html#enhancing-retrieval-with-graph-based-models",
    "href": "slides/fall24_references/index.html#enhancing-retrieval-with-graph-based-models",
    "title": "Advances in Agent-Based Big AI",
    "section": "Enhancing Retrieval with Graph-Based Models",
    "text": "Enhancing Retrieval with Graph-Based Models\n\nGraphRAG by Microsoft Research:\n\nCombines knowledge graphs with Retrieval-Augmented Generation (RAG).\nUses structured data to improve retrieval accuracy and contextual relevance.\n\nKey Features:\n\nWhole-Data Reasoning: Enables summarization and extraction of key themes from large datasets.\nProvenance Tracking: Provides sources and grounding for AI-generated responses.\n\nBenefits:\n\nImproved trust and verification in AI outputs.\nApplicable in fields like data analysis, content generation, and decision support."
  },
  {
    "objectID": "slides/fall24_references/index.html#advances-in-graphrag",
    "href": "slides/fall24_references/index.html#advances-in-graphrag",
    "title": "Advances in Agent-Based Big AI",
    "section": "Advances in GraphRAG",
    "text": "Advances in GraphRAG\n\nPeng, Boci, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, and Siliang Tang. 2024. “Graph Retrieval-Augmented Generation: A Survey.” arXiv. http://arxiv.org/abs/2408.08921.\nGoogle Illuminate Microsoft GraphRAG Paper"
  },
  {
    "objectID": "slides/fall24_references/index.html#hipporag",
    "href": "slides/fall24_references/index.html#hipporag",
    "title": "Advances in Agent-Based Big AI",
    "section": "HippoRAG",
    "text": "HippoRAG\n\nGutiérrez, Bernal Jiménez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, and Yu Su. 2024. “HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models.” arXiv. https://doi.org/10.48550/arXiv.2405.14831.\nGoogle Illuminate"
  },
  {
    "objectID": "slides/fall24_references/index.html#hipporag-enhanced-memory-integration-for-ai",
    "href": "slides/fall24_references/index.html#hipporag-enhanced-memory-integration-for-ai",
    "title": "Advances in Agent-Based Big AI",
    "section": "HippoRAG: Enhanced Memory Integration for AI",
    "text": "HippoRAG: Enhanced Memory Integration for AI\n\nOverview:\n\nInspired by the hippocampal indexing theory of human memory.\nCombines LLMs with knowledge graphs for enhanced information retrieval.\n\nMethodology:\n\nOffline Indexing: Creates a hippocampal-like index using LLMs.\nOnline Retrieval: Uses Personalized PageRank to link queries to relevant knowledge nodes.\n\nPerformance:\n\nOutperforms traditional retrieval methods in multi-hop question answering.\nMore efficient, faster, and cost-effective than existing iterative retrieval techniques."
  },
  {
    "objectID": "slides/fall24_references/index.html#sciagents-automating-scientific-discovery-the-ograg",
    "href": "slides/fall24_references/index.html#sciagents-automating-scientific-discovery-the-ograg",
    "title": "Advances in Agent-Based Big AI",
    "section": "SciAgents: Automating Scientific Discovery (“The OGRag”)",
    "text": "SciAgents: Automating Scientific Discovery (“The OGRag”)\n\nGhafarollahi, Alireza, and Markus J. Buehler. 2024. “SciAgents: Automating Scientific Discovery through Multi-Agent Intelligent Graph Reasoning.” arXiv. http://arxiv.org/abs/2409.05556.\nGoogle Illuminate"
  },
  {
    "objectID": "slides/fall24_references/index.html#sciagents-multi-agent-intelligent-graph-reasoning",
    "href": "slides/fall24_references/index.html#sciagents-multi-agent-intelligent-graph-reasoning",
    "title": "Advances in Agent-Based Big AI",
    "section": "SciAgents Multi-Agent Intelligent Graph Reasoning",
    "text": "SciAgents Multi-Agent Intelligent Graph Reasoning\n\nIntroduction to SciAgents:\n\nUses ontological knowledge graphs and multi-agent systems.\nDesigned to explore novel domains and discover hidden interdisciplinary connections.\n\nKey Capabilities:\n\nAutonomous generation and refinement of research hypotheses.\nIntegration of up-to-date scientific data and critique of existing theories.\n\nCase Studies:\n\nDemonstrated success in biologically inspired materials research.\nPotential to accelerate scientific discovery across various domains."
  },
  {
    "objectID": "slides/hackers/index.html#topics",
    "href": "slides/hackers/index.html#topics",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Topics",
    "text": "Topics\n\nSetting up your local machine and CRC cluster\nUsing VSCode\nLLM tools"
  },
  {
    "objectID": "slides/hackers/index.html#jupyter-caml-cluster-machine",
    "href": "slides/hackers/index.html#jupyter-caml-cluster-machine",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Jupyter CAML Cluster Machine",
    "text": "Jupyter CAML Cluster Machine\nJupyter CAML Cluster Machine"
  },
  {
    "objectID": "slides/hackers/index.html#link-our-group-space",
    "href": "slides/hackers/index.html#link-our-group-space",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Link our Group Space",
    "text": "Link our Group Space\nln -s /afs/crc/group/TAI ./TAI"
  },
  {
    "objectID": "slides/hackers/index.html#setting-up-environment",
    "href": "slides/hackers/index.html#setting-up-environment",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Setting up Environment",
    "text": "Setting up Environment\n\nFastAI Setup: https://github.com/fastai/fastsetup\nTmux: https://github.com/tmux/tmux/wiki/Getting-Started\ndotfiles: https://github.com/fastai/dotfiles\nFastAI Live Coding: https://forums.fast.ai/t/live-coding-aka-walk-thrus/96617\nFastAI Git, SSH, TMUX: https://forums.fast.ai/t/live-coding-2/96690\nBeginner’s Guide to Mambaforge Installation: https://qbiwan.github.io/fastpages/mamba-installation"
  },
  {
    "objectID": "slides/hackers/index.html#crc-documentation",
    "href": "slides/hackers/index.html#crc-documentation",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "CRC Documentation",
    "text": "CRC Documentation\n\nCRC User Documentation - https://docs.crc.nd.edu/\nCRC QuickStart Guide - https://docs.crc.nd.edu/new_user/quick_start.html#quick-start-guide"
  },
  {
    "objectID": "slides/hackers/index.html#connecting-to-the-crc-machines",
    "href": "slides/hackers/index.html#connecting-to-the-crc-machines",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Connecting to the CRC Machines",
    "text": "Connecting to the CRC Machines\n\nSSH\nCampus VPN"
  },
  {
    "objectID": "slides/hackers/index.html#live-coding-resources",
    "href": "slides/hackers/index.html#live-coding-resources",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Live Coding Resources",
    "text": "Live Coding Resources\n\nFastAI Live Coding: https://forums.fast.ai/t/live-coding-aka-walk-thrus/96617\nFastAI Live Coding 1: https://forums.fast.ai/t/live-coding-1/96649\nFastAI Git, SSH, TMUX: https://forums.fast.ai/t/live-coding-2/96690"
  },
  {
    "objectID": "slides/hackers/index.html#local-first-steps-macos",
    "href": "slides/hackers/index.html#local-first-steps-macos",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Local First Steps (MacOS)",
    "text": "Local First Steps (MacOS)\n\nInstall iTerm2 instead of Mac Terminal\nInstall Homebrew - https://brew.sh/\nInstall Tmux\n\nbrew install tmux"
  },
  {
    "objectID": "slides/hackers/index.html#windows-subsystem-for-linuxwsl-bing",
    "href": "slides/hackers/index.html#windows-subsystem-for-linuxwsl-bing",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Windows Subsystem for Linux(WSL) Bing!",
    "text": "Windows Subsystem for Linux(WSL) Bing!\nWSL stands for Windows Subsystem for Linux, which is a feature of the Windows operating system that enables you to run a Linux file system, along with Linux command-line tools and GUI apps, directly on Windows, alongside your traditional Windows desktop and apps. It is designed to be a seamless experience, essentially providing a full Linux shell that can interact with your Windows filesystem.\nTo start using WSL, you need to install a Linux distribution of your choice from the Microsoft Store, such as Ubuntu. You can launch it as an app or use it as a profile in your terminal. You can also install programs using the Linux package manager and customize it like a regular Linux instance.\nIf you need more help with setting up and using WSL, you can check out the following resources:\n\nSet up a WSL development environment\nWhat is Windows Subsystem For Linux (WSL), and How Do You Use It?.\nWhat is Windows Subsystem for Linux | Microsoft Learn.\n\nI hope this helps you understand what WSL is and how to use it. 😊"
  },
  {
    "objectID": "slides/hackers/index.html#a-note-on-editors-from-bing",
    "href": "slides/hackers/index.html#a-note-on-editors-from-bing",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "A note on Editors from Bing!",
    "text": "A note on Editors from Bing!\nA command line editor is a text editor that can be used to create or modify files in a terminal or console. There are many command line editors available for different operating systems and preferences. Some of the most popular ones are:\n\nVi or Vim: Vi is a classic and powerful editor that was originally created for Unix systems. Vim is an improved version of Vi that adds more features and enhancements. Vi and Vim are widely used by Linux users and system administrators. They have a steep learning curve, but they offer many advanced functions and customization options. To use Vi or Vim, you need to learn different modes of operation and keyboard commands.1 2\nNano: Nano is a simple and user-friendly editor that is inspired by Pico, another editor that was part of the Pine email client. Nano is easy to use and has a built-in help system. It is suitable for beginners and casual users who do not need complex features. Nano is also available on most Linux distributions by default.\nEmacs: Emacs is a versatile and extensible editor that can do much more than editing text files. Emacs can be used as an IDE, a web browser, a mail client, a calculator, and more. Emacs has a rich set of commands and keyboard shortcuts, as well as a scripting language called Emacs Lisp that can be used to customize and extend its functionality. Emacs is popular among programmers and enthusiasts who like to have full control over their editor.\n\n9 Best Text Editors for the Linux Command Line - It’s FOSS.How do I edit text files in the Windows command prompt?."
  },
  {
    "objectID": "slides/hackers/index.html#section",
    "href": "slides/hackers/index.html#section",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "",
    "text": "Note\n\n\nWhen in doubt, use Prof. Sweet’s advice and use Nano!"
  },
  {
    "objectID": "slides/hackers/index.html#dr.-vardemans-dotfiles",
    "href": "slides/hackers/index.html#dr.-vardemans-dotfiles",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Dr. Vardeman’s Dotfiles",
    "text": "Dr. Vardeman’s Dotfiles\n\nVery Simple Set of Dotfiles - https://github.com/charlesvardeman/dotfiles\nBased on FastAI Dotfiles - https://github.com/fastai/dotfiles"
  },
  {
    "objectID": "slides/hackers/index.html#ssh-configuration",
    "href": "slides/hackers/index.html#ssh-configuration",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "SSH Configuration",
    "text": "SSH Configuration\nWe need to set up ssh to facilitate access to GitHub and the CRC Cluster machines. - Live Coding 2: “Setting up SSH Keys” - Dr. Vardeman’s ssh config - Instructions to Setup GitHub SSH Keys"
  },
  {
    "objectID": "slides/hackers/index.html#login-to-crc-machines",
    "href": "slides/hackers/index.html#login-to-crc-machines",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Login to CRC Machines",
    "text": "Login to CRC Machines\nFrom iTerm2 or Terminal\nssh netid@crcfe02.crc.nd.edu"
  },
  {
    "objectID": "slides/hackers/index.html#miniforge-forge-install",
    "href": "slides/hackers/index.html#miniforge-forge-install",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Miniforge Forge Install!",
    "text": "Miniforge Forge Install!\n\n\n\n\n\n\nWarning\n\n\nMambaforge has been integrated with the main Miniforge. Jeremy Howard’s Instructions still work, except use the default Miniforge\n\n\n\nTutorial: Setting up Python enviroments with Mambaforge - Ross Dobson (ross-dobson.github.io)"
  },
  {
    "objectID": "slides/hackers/index.html#zotero",
    "href": "slides/hackers/index.html#zotero",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Zotero",
    "text": "Zotero\n\n\n\nZotero | Your personal research assistant"
  },
  {
    "objectID": "slides/hackers/index.html#zotero-setup",
    "href": "slides/hackers/index.html#zotero-setup",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Zotero Setup",
    "text": "Zotero Setup\n\n\n \n\n\n\nZotero | Downloads"
  },
  {
    "objectID": "slides/hackers/index.html#fastai-fastbook-a-production-mindset",
    "href": "slides/hackers/index.html#fastai-fastbook-a-production-mindset",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "FastAI FastBook – “A Production Mindset”",
    "text": "FastAI FastBook – “A Production Mindset”\n\n\n\nIntroduction to Jupyter\n02_production.ipynb\nNatural Language (NLP)\n\nGetting started with NLP for absolute beginners"
  },
  {
    "objectID": "slides/hackers/index.html#hackers-guide-to-llms",
    "href": "slides/hackers/index.html#hackers-guide-to-llms",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Hackers Guide to LLMs",
    "text": "Hackers Guide to LLMs\n\n\n\nA Hackers’ Guide to Language Models - https://youtu.be/jkrNMKz9pWU?si=f-daO59GuGtD5Spq\nGithub - https://github.com/fastai/lm-hackers\nRepo with requirements.txt: cgreening/lm-hackers: Hackers’ Guide to Language Models (github.com)"
  },
  {
    "objectID": "slides/hackers/index.html#getting-started-with-llms",
    "href": "slides/hackers/index.html#getting-started-with-llms",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Getting Started with LLMs",
    "text": "Getting Started with LLMs\n\nGetting Started With LLMs\nStanford CS224N NLP with Deep Learning | 2023 | Hugging Face Tutorial, Eric Frankel - YouTube\nHugging_Face_Transformers_Tutorial - Colaboratory (google.com)"
  },
  {
    "objectID": "slides/hackers/index.html#quick-nuggets",
    "href": "slides/hackers/index.html#quick-nuggets",
    "title": "H4x0rz GU!dE t0 1lms",
    "section": "Quick Nuggets",
    "text": "Quick Nuggets\nTakeaway: General trend to rapidly integrate Generative AI into traditional software products.\n\nAnnouncing Microsoft Copilot, your everyday AI companion\n\nMicrosoft Aims to Reduce Reliance on OpenAI with SMaller, Cheaper, LLMs\nMicrosoft Looks to Go Nuclear to Support Energy-Hungry AI\n\nAmazon - $4B Anthropic Deal\n\nTrustedAI - Anthropic | Anthropic’s Responsible Scaling Policy\nAnnouncing New Tools to Help Every Business Embrace Generative AI | AWS Machine Learning Blog (amazon.com)\n\nMeta AI Announcements -AI Studio Sandbox\nChatGPT can now see, hear, and speak\n\nOpenAI Red Teaming Network\nBrowse with Bing plugin\nDALL-E3 Stable Diffusion Foundation Model"
  },
  {
    "objectID": "slides/tai-tools/index.html#trusted-ai-frameworks-for-knowledge-engineering",
    "href": "slides/tai-tools/index.html#trusted-ai-frameworks-for-knowledge-engineering",
    "title": "Tools for Trusted AI",
    "section": "Trusted AI Frameworks for Knowledge Engineering",
    "text": "Trusted AI Frameworks for Knowledge Engineering"
  },
  {
    "objectID": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-chatgpt",
    "href": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-chatgpt",
    "title": "Tools for Trusted AI",
    "section": "What is Trusted AI – Let’s ask ChatGPT!",
    "text": "What is Trusted AI – Let’s ask ChatGPT!\nTrusted AI encompasses systems that are not only ethically aligned but also reliable, robust, secure, transparent, and accountable. While ethical considerations form a crucial aspect, Trusted AI extends to include the technical quality and performance of the system. The goal is to create AI technologies that various stakeholders—including users, developers, businesses, and regulators—can trust to behave as intended and to meet specific performance, security, and governance standards.\nThe concept integrates aspects from multiple domains, such as:\n\nEthics: Fairness, transparency, and accountability.\nReliability: Consistent and dependable system performance.\nRobustness: Ability to handle unexpected inputs or conditions without failing.\nSecurity: Measures to protect data and models from unauthorized access and tampering.\nTransparency: Understandability of system decisions and actions.\nAccountability: Mechanisms to trace actions back to the responsible entities for evaluation and auditing.\n\nIn this broader context, “trust” is a multidimensional construct. It’s not just about being ethical but about fulfilling a wide range of expectations and standards that make a system worthy of trust."
  },
  {
    "objectID": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-claude-2",
    "href": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-claude-2",
    "title": "Tools for Trusted AI",
    "section": "What is Trusted AI – Let’s ask Claude 2!",
    "text": "What is Trusted AI – Let’s ask Claude 2!\nTrusted AI refers to artificial intelligence systems that are designed and validated to be reliable, safe and technically robust. Key principles of trusted AI include:\n\nReliability - AI systems consistently produce accurate, reproducible results that can be externally validated. Models are unbiased and decisions explainable.\nSafety and security - AI systems are developed using secure software practices and are resilient against attacks, hacking or misuse. They protect privacy and confidentiality.\nExternal oversight - There are independent audits and ongoing monitoring of AI systems to ensure transparency and identify issues. Public disclosure builds trust.\nHuman control - Humans remain fully in control of AI systems, which augment human intelligence rather than replace it. Autonomous systems have human supervision.\nProportionality - AI capabilities do not exceed what is appropriate for the task. AI is not used when less advanced technology suffices.\nTechnical robustness - AI systems are thoroughly tested for stability, scalability and corner cases. Failsafes prevent glitches or unintended harm.\n\nIn contrast to responsible AI, trusted AI emphasizes technical system properties over organizational processes. It focuses on engineering reliable, safe and externally validated AI, rather than holistic internal governance."
  },
  {
    "objectID": "slides/tai-tools/index.html#our-evolving-vision-of-trusted-ai",
    "href": "slides/tai-tools/index.html#our-evolving-vision-of-trusted-ai",
    "title": "Tools for Trusted AI",
    "section": "Our, evolving vision of Trusted AI",
    "text": "Our, evolving vision of Trusted AI"
  },
  {
    "objectID": "slides/tai-tools/index.html#responsible-ai",
    "href": "slides/tai-tools/index.html#responsible-ai",
    "title": "Tools for Trusted AI",
    "section": "Responsible AI",
    "text": "Responsible AI\n\nResponsible AI: This term is broader and refers to the ethical design, development, and deployment of AI. This includes considerations not just of the AI’s technical behavior (e.g., is it transparent and accountable?), but also of the socio-economic implications, like job displacement, and broader ethical considerations like data privacy and environmental impact."
  },
  {
    "objectID": "slides/tai-tools/index.html#foundational-components-for-trusted-ai",
    "href": "slides/tai-tools/index.html#foundational-components-for-trusted-ai",
    "title": "Tools for Trusted AI",
    "section": "Foundational Components for Trusted AI",
    "text": "Foundational Components for Trusted AI\n\nAutomate the integration and deployment of code, ensuring quality and operational efficiency.\nStandardized Development Environments: Establish consistent, easily replicable environments to accelerate development and experimentation.\nData & Experiment Versioning: Implement robust systems to track changes in data and experiments, allowing for traceability and repeatability.\nModel Lifecycle Management: Streamline the training, deployment, monitoring, and updating of machine learning models.\nFlexibility Across Layers: Design the architecture to allow for different levels of customization, from high-level APIs to low-level controls, facilitating adaptability."
  },
  {
    "objectID": "slides/tai-tools/index.html#why-a-framework",
    "href": "slides/tai-tools/index.html#why-a-framework",
    "title": "Tools for Trusted AI",
    "section": "Why a Framework?",
    "text": "Why a Framework?\n\n\n\n\n“Course22/06-Why-You-Should-Use-a-Framework.Ipynb at Master · Fastai/Course22.”\nAccessed August 29, 2023. https://github.com/fastai/course22/blob/master/06-why-you-should-use-a-framework.ipynb."
  },
  {
    "objectID": "slides/tai-tools/index.html#this-is-a-living-set-of-slides",
    "href": "slides/tai-tools/index.html#this-is-a-living-set-of-slides",
    "title": "Tools for Trusted AI",
    "section": "This is a “living” set of slides!",
    "text": "This is a “living” set of slides!"
  },
  {
    "objectID": "slides/tai-tools/index.html#purpose-to-quickly-bootstrap-you-into-a-research-environment",
    "href": "slides/tai-tools/index.html#purpose-to-quickly-bootstrap-you-into-a-research-environment",
    "title": "Tools for Trusted AI",
    "section": "Purpose: To quickly “Bootstrap” you into a research environment",
    "text": "Purpose: To quickly “Bootstrap” you into a research environment"
  },
  {
    "objectID": "slides/tai-tools/index.html#our-framework-starts-with-github",
    "href": "slides/tai-tools/index.html#our-framework-starts-with-github",
    "title": "Tools for Trusted AI",
    "section": "Our Framework Starts with GitHub",
    "text": "Our Framework Starts with GitHub\n\n\n\n\nGitHub ND-Crane Organization"
  },
  {
    "objectID": "slides/tai-tools/index.html#step-1-create-a-github-account",
    "href": "slides/tai-tools/index.html#step-1-create-a-github-account",
    "title": "Tools for Trusted AI",
    "section": "(Step 1) Create a GitHub Account",
    "text": "(Step 1) Create a GitHub Account\n\n\n\n\nGitHub"
  },
  {
    "objectID": "slides/tai-tools/index.html#step-2-email-github-account-id",
    "href": "slides/tai-tools/index.html#step-2-email-github-account-id",
    "title": "Tools for Trusted AI",
    "section": "(Step 2) Email GitHub Account ID",
    "text": "(Step 2) Email GitHub Account ID\n\nIf you are not part of the nd-crane organization. Email pmoreira@nd.edu your GitHub ID so we can add it to the nd-crane organization"
  },
  {
    "objectID": "slides/tai-tools/index.html#step-3-go-through-github-skills-introduction-to-github",
    "href": "slides/tai-tools/index.html#step-3-go-through-github-skills-introduction-to-github",
    "title": "Tools for Trusted AI",
    "section": "(Step 3) Go through GitHub Skills Introduction to GitHub",
    "text": "(Step 3) Go through GitHub Skills Introduction to GitHub\n\n\n\nGo Through “First Day on GitHub”\n\nIntroduction to GitHub\nCommunicate using Markdown\nGitHub Pages (We will use this with Quarto)\n\nFirst week on GitHub\n\nReview pull requests\nResolve merge conflicts\nRelease-based workflow\nConnect the dots\nCode with Codespaces\n\n\n\n\n\n\nGitHub Skills: https://skills.github.com/"
  },
  {
    "objectID": "slides/tai-tools/index.html#ai-and-machine-learning",
    "href": "slides/tai-tools/index.html#ai-and-machine-learning",
    "title": "Tools for Trusted AI",
    "section": "AI and Machine Learning",
    "text": "AI and Machine Learning\n\n\nPractical Deep Learning: https://course.fast.ai/\nFastAI Book\nFastAI GitHub: https://github.com/fastai"
  },
  {
    "objectID": "slides/tai-tools/index.html#fastai-fastbook-a-production-mindset",
    "href": "slides/tai-tools/index.html#fastai-fastbook-a-production-mindset",
    "title": "Tools for Trusted AI",
    "section": "FastAI FastBook – “A Production Mindset”",
    "text": "FastAI FastBook – “A Production Mindset”\n\n\n\nIntroduction to Jupyter\n02_production.ipynb\nNatural Language (NLP)\n\nGetting started with NLP for absolute beginners"
  },
  {
    "objectID": "slides/tai-tools/index.html#a-preview",
    "href": "slides/tai-tools/index.html#a-preview",
    "title": "Tools for Trusted AI",
    "section": "A Preview…",
    "text": "A Preview…"
  },
  {
    "objectID": "slides/tai-tools/index.html#visual-studio-code",
    "href": "slides/tai-tools/index.html#visual-studio-code",
    "title": "Tools for Trusted AI",
    "section": "Visual Studio Code",
    "text": "Visual Studio Code\n\n\nVisual Studio Code - Code Editing. Redefined: https://code.visualstudio.com/"
  },
  {
    "objectID": "slides/tai-tools/index.html#peter-only-dev-containers-and-fastai",
    "href": "slides/tai-tools/index.html#peter-only-dev-containers-and-fastai",
    "title": "Tools for Trusted AI",
    "section": "(Peter Only!) “Dev Containers” and FastAI",
    "text": "(Peter Only!) “Dev Containers” and FastAI\nUsing Codespaces to work with the “Practical Deep Learning for Coders” course"
  },
  {
    "objectID": "slides/tai-tools/index.html#but-dr.-vardeman-i-know-all-of-this",
    "href": "slides/tai-tools/index.html#but-dr.-vardeman-i-know-all-of-this",
    "title": "Tools for Trusted AI",
    "section": "But Dr. Vardeman, I know all of this!",
    "text": "But Dr. Vardeman, I know all of this!\nGetting Started With LLMs"
  },
  {
    "objectID": "slides/tai-tools/index.html#python",
    "href": "slides/tai-tools/index.html#python",
    "title": "Tools for Trusted AI",
    "section": "Python",
    "text": "Python\n\n\nLearn More: Think Python 2e: https://greenteapress.com/wp/think-python-2e/"
  },
  {
    "objectID": "slides/tai-tools/index.html#python-for-data-analysis",
    "href": "slides/tai-tools/index.html#python-for-data-analysis",
    "title": "Tools for Trusted AI",
    "section": "Python for Data Analysis",
    "text": "Python for Data Analysis\n\n\n\n\n\n\nPractical Deep Learning: https://wesmckinney.com/book/"
  },
  {
    "objectID": "slides/ai-engineering/index.html#this-is-all-peters-fault",
    "href": "slides/ai-engineering/index.html#this-is-all-peters-fault",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "This is all Peter’s fault!",
    "text": "This is all Peter’s fault!"
  },
  {
    "objectID": "slides/ai-engineering/index.html#peter-how-do-we-prompt-better",
    "href": "slides/ai-engineering/index.html#peter-how-do-we-prompt-better",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Peter: How do we prompt better?",
    "text": "Peter: How do we prompt better?"
  },
  {
    "objectID": "slides/ai-engineering/index.html#prompting-in-the-context-of-ai-engineering",
    "href": "slides/ai-engineering/index.html#prompting-in-the-context-of-ai-engineering",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Prompting in the context of AI Engineering",
    "text": "Prompting in the context of AI Engineering"
  },
  {
    "objectID": "slides/ai-engineering/index.html#ai-engineering-as-a-practice",
    "href": "slides/ai-engineering/index.html#ai-engineering-as-a-practice",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "AI Engineering as a Practice?",
    "text": "AI Engineering as a Practice?\n\n\n\n\nThe Rise of the AI Engineer- by swyx - Laintent Space"
  },
  {
    "objectID": "slides/ai-engineering/index.html#ai-engineering-summit",
    "href": "slides/ai-engineering/index.html#ai-engineering-summit",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "AI Engineering Summit",
    "text": "AI Engineering Summit\n\n\n\n\nAI Engineering Summit"
  },
  {
    "objectID": "slides/ai-engineering/index.html#ai-engineering-summit-youtube",
    "href": "slides/ai-engineering/index.html#ai-engineering-summit-youtube",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "AI Engineering Summit – Youtube",
    "text": "AI Engineering Summit – Youtube\n\n\n\n\nAI Engineering Summit"
  },
  {
    "objectID": "slides/ai-engineering/index.html#llmops-engineering",
    "href": "slides/ai-engineering/index.html#llmops-engineering",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "LLMOps Engineering",
    "text": "LLMOps Engineering\n\n\n\n\nA Survey of Techniques for Maximizing LLM Performance"
  },
  {
    "objectID": "slides/ai-engineering/index.html#llmops-engineering-1",
    "href": "slides/ai-engineering/index.html#llmops-engineering-1",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "LLMOps Engineering",
    "text": "LLMOps Engineering\n\n\n\n\nA Survey of Techniques for Maximizing LLM Performance"
  },
  {
    "objectID": "slides/ai-engineering/index.html#llm-engineering-knowledge-engineering-rag-engineering-fine-tuning-engineering.",
    "href": "slides/ai-engineering/index.html#llm-engineering-knowledge-engineering-rag-engineering-fine-tuning-engineering.",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "LLM Engineering – Knowledge Engineering, RAG Engineering, Fine Tuning Engineering.",
    "text": "LLM Engineering – Knowledge Engineering, RAG Engineering, Fine Tuning Engineering."
  },
  {
    "objectID": "slides/ai-engineering/index.html#llmops-cognitive-agents",
    "href": "slides/ai-engineering/index.html#llmops-cognitive-agents",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "LLMOps – Cognitive Agents",
    "text": "LLMOps – Cognitive Agents\n\n\n\nWang, Lei, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, et al. 2023. “A Survey on Large Language Model Based Autonomous Agents.” arXiv. http://arxiv.org/abs/2308.11432."
  },
  {
    "objectID": "slides/ai-engineering/index.html#a-caution-outward-facing-data-fabric-vs-inward-facing",
    "href": "slides/ai-engineering/index.html#a-caution-outward-facing-data-fabric-vs-inward-facing",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "A Caution: Outward facing Data Fabric vs Inward Facing…",
    "text": "A Caution: Outward facing Data Fabric vs Inward Facing…\n\n\n\nWe don’t want to be engineering data silos!\nWith Agents, the “World Wide Web” is a Data Fabric!\nWe want to expose some information as Distributed, Decentralized Knowledge Graphs!"
  },
  {
    "objectID": "slides/ai-engineering/index.html#data-fabrics-are-going-to-be-used-as-data-engines",
    "href": "slides/ai-engineering/index.html#data-fabrics-are-going-to-be-used-as-data-engines",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Data Fabrics are going to be used as Data Engines!",
    "text": "Data Fabrics are going to be used as Data Engines!\n\n\n\n\nTwitter: Andrej Karpathy"
  },
  {
    "objectID": "slides/ai-engineering/index.html#so-its-creepy-looking-ai-turtles-all-the-way-down",
    "href": "slides/ai-engineering/index.html#so-its-creepy-looking-ai-turtles-all-the-way-down",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "So, it’s creepy looking AI turtles all the way down…",
    "text": "So, it’s creepy looking AI turtles all the way down…"
  },
  {
    "objectID": "slides/ai-engineering/index.html#how-to-prompt",
    "href": "slides/ai-engineering/index.html#how-to-prompt",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "How to Prompt?",
    "text": "How to Prompt?"
  },
  {
    "objectID": "slides/ai-engineering/index.html#how-to-prompt-engineer",
    "href": "slides/ai-engineering/index.html#how-to-prompt-engineer",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "How to Prompt Engineer…",
    "text": "How to Prompt Engineer…"
  },
  {
    "objectID": "slides/ai-engineering/index.html#prompting-guide",
    "href": "slides/ai-engineering/index.html#prompting-guide",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Prompting Guide",
    "text": "Prompting Guide\n\n\n\n\nPrompt Engineering Guide"
  },
  {
    "objectID": "slides/ai-engineering/index.html#openai-cookbook",
    "href": "slides/ai-engineering/index.html#openai-cookbook",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "OpenAI Cookbook",
    "text": "OpenAI Cookbook\n\n\n\n\nOpenAI Cookbook\n\n\n\n\nOpenAI Examples"
  },
  {
    "objectID": "slides/ai-engineering/index.html#important-prompt-structure-performance-changes-with-model",
    "href": "slides/ai-engineering/index.html#important-prompt-structure-performance-changes-with-model",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Important: Prompt Structure Performance Changes with Model!",
    "text": "Important: Prompt Structure Performance Changes with Model!"
  },
  {
    "objectID": "slides/ai-engineering/index.html#prompt-testing",
    "href": "slides/ai-engineering/index.html#prompt-testing",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Prompt Testing?",
    "text": "Prompt Testing?\n\n\n\n\nEvaluating LLMs is a minefield"
  },
  {
    "objectID": "slides/ai-engineering/index.html#challenges-in-evaluating-ai-systems",
    "href": "slides/ai-engineering/index.html#challenges-in-evaluating-ai-systems",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Challenges in evaluating AI systems",
    "text": "Challenges in evaluating AI systems\n\n\n\n\nAnthropic Challenges in evaluating AI systems"
  },
  {
    "objectID": "slides/ai-engineering/index.html#challenges-with-prompt-structure-in-evals",
    "href": "slides/ai-engineering/index.html#challenges-with-prompt-structure-in-evals",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Challenges with prompt structure in evals",
    "text": "Challenges with prompt structure in evals\n\n\n\n\nAnthropic Challenges in evaluating AI systems"
  },
  {
    "objectID": "slides/ai-engineering/index.html#retrieval-augmented-generation",
    "href": "slides/ai-engineering/index.html#retrieval-augmented-generation",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Retrieval Augmented Generation",
    "text": "Retrieval Augmented Generation"
  },
  {
    "objectID": "slides/ai-engineering/index.html#unit-testing-of-llms",
    "href": "slides/ai-engineering/index.html#unit-testing-of-llms",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Unit Testing of LLMs",
    "text": "Unit Testing of LLMs\n\n\n\n\nA Survey of Techniques for Maximizing LLM Performance"
  },
  {
    "objectID": "slides/ai-engineering/index.html#prompt-engineering-is-about-adding-context",
    "href": "slides/ai-engineering/index.html#prompt-engineering-is-about-adding-context",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Prompt Engineering is about adding context!",
    "text": "Prompt Engineering is about adding context!"
  },
  {
    "objectID": "slides/ai-engineering/index.html#kgs-for-context",
    "href": "slides/ai-engineering/index.html#kgs-for-context",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "KGs for Context",
    "text": "KGs for Context\n\n\n\n\nSequeda, Juan, Dean Allemang, and Bryon Jacob. 2023. “A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases.” arXiv. http://arxiv.org/abs/2311.07509."
  },
  {
    "objectID": "slides/ai-engineering/index.html#kgs-for-context-1",
    "href": "slides/ai-engineering/index.html#kgs-for-context-1",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "KGs for Context",
    "text": "KGs for Context\n\n\n\n\nSequeda, Juan, Dean Allemang, and Bryon Jacob. 2023. “A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model’s Accuracy for Question Answering on Enterprise SQL Databases.” arXiv. http://arxiv.org/abs/2311.07509."
  },
  {
    "objectID": "slides/ai-engineering/index.html#information-extraction-for-rag-tool-use",
    "href": "slides/ai-engineering/index.html#information-extraction-for-rag-tool-use",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Information Extraction for RAG (Tool Use)",
    "text": "Information Extraction for RAG (Tool Use)\n\n\n\n\nXu, Silei, Shicheng Liu, Theo Culhane, Elizaveta Pertseva, Meng-Hsi Wu, Sina J. Semnani, and Monica S. Lam. 2023. “Fine-Tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata.” arXiv. http://arxiv.org/abs/2305.14202."
  },
  {
    "objectID": "slides/ai-engineering/index.html#prompting-patterns-for-rag-planning-and-action",
    "href": "slides/ai-engineering/index.html#prompting-patterns-for-rag-planning-and-action",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Prompting Patterns for RAG – Planning and Action",
    "text": "Prompting Patterns for RAG – Planning and Action\n\n\n\n\nPrasad, Archiki, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, Mohit Bansal, and Tushar Khot. 2023. “ADaPT: As-Needed Decomposition and Planning with Language Models.” arXiv. https://doi.org/10.48550/arXiv.2311.05772."
  },
  {
    "objectID": "slides/ai-engineering/index.html#training-and-fine-tuning",
    "href": "slides/ai-engineering/index.html#training-and-fine-tuning",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Training and Fine Tuning",
    "text": "Training and Fine Tuning"
  },
  {
    "objectID": "slides/ai-engineering/index.html#textbooks-are-all-you-need-ii-phi-1.5",
    "href": "slides/ai-engineering/index.html#textbooks-are-all-you-need-ii-phi-1.5",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Textbooks are all you need II: phi-1.5",
    "text": "Textbooks are all you need II: phi-1.5\n\n\n\n\nY. Li, S. Bubeck, R. Eldan, A. Del Giorno, S. Gunasekar, and Y. T. Lee, “Textbooks Are All You Need II: phi-1.5 technical report.” arXiv, Sep. 11, 2023. Accessed: Sep. 12, 2023. [Online]. Available: http://arxiv.org/abs/2309.05463"
  },
  {
    "objectID": "slides/ai-engineering/index.html#textbooks-are-all-you-need-iii-phi-2",
    "href": "slides/ai-engineering/index.html#textbooks-are-all-you-need-iii-phi-2",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Textbooks are all you need III: phi-2",
    "text": "Textbooks are all you need III: phi-2\n\n\n\n\nSebastien Bubeck X"
  },
  {
    "objectID": "slides/ai-engineering/index.html#phi-2-metrics",
    "href": "slides/ai-engineering/index.html#phi-2-metrics",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "phi-2 metrics",
    "text": "phi-2 metrics\n\n\n\n\nSebastien Bubeck X"
  },
  {
    "objectID": "slides/ai-engineering/index.html#microsoft-ignite",
    "href": "slides/ai-engineering/index.html#microsoft-ignite",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Microsoft Ignite",
    "text": "Microsoft Ignite\n\n\n\n\nAI+Mixed Reality for the Front Line"
  },
  {
    "objectID": "slides/ai-engineering/index.html#maybe-we-need-more-than-textbooks",
    "href": "slides/ai-engineering/index.html#maybe-we-need-more-than-textbooks",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Maybe we need more than Textbooks?",
    "text": "Maybe we need more than Textbooks?"
  },
  {
    "objectID": "slides/ai-engineering/index.html#a-curriculum-for-logic",
    "href": "slides/ai-engineering/index.html#a-curriculum-for-logic",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "A “Curriculum” for Logic?",
    "text": "A “Curriculum” for Logic?\n\n\n\n\nFeng, Jiazhan, Ruochen Xu, Junheng Hao, Hiteshi Sharma, Yelong Shen, Dongyan Zhao, and Weizhu Chen. 2023. “Language Models Can Be Logical Solvers.” arXiv. http://arxiv.org/abs/2311.06158."
  },
  {
    "objectID": "slides/ai-engineering/index.html#a-curriculum-for-logic-1",
    "href": "slides/ai-engineering/index.html#a-curriculum-for-logic-1",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "A “Curriculum” for Logic?",
    "text": "A “Curriculum” for Logic?\n\n\n\n\nFeng, Jiazhan, Ruochen Xu, Junheng Hao, Hiteshi Sharma, Yelong Shen, Dongyan Zhao, and Weizhu Chen. 2023. “Language Models Can Be Logical Solvers.” arXiv. http://arxiv.org/abs/2311.06158."
  },
  {
    "objectID": "slides/ai-engineering/index.html#fine-tuning-for-truthfulness",
    "href": "slides/ai-engineering/index.html#fine-tuning-for-truthfulness",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Fine Tuning for Truthfulness",
    "text": "Fine Tuning for Truthfulness\n\n\n\n\nTian, Katherine, Eric Mitchell, Huaxiu Yao, Christopher D. Manning, and Chelsea Finn. 2023. “Fine-Tuning Language Models for Factuality.” arXiv. http://arxiv.org/abs/2311.08401."
  },
  {
    "objectID": "slides/ai-engineering/index.html#fine-tuning-for-truthfulness-1",
    "href": "slides/ai-engineering/index.html#fine-tuning-for-truthfulness-1",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "Fine Tuning for Truthfulness",
    "text": "Fine Tuning for Truthfulness\n\n\n\n\nTian, Katherine, Eric Mitchell, Huaxiu Yao, Christopher D. Manning, and Chelsea Finn. 2023. “Fine-Tuning Language Models for Factuality.” arXiv. http://arxiv.org/abs/2311.08401."
  },
  {
    "objectID": "slides/ai-engineering/index.html#dod-need-for-smaller-private-models",
    "href": "slides/ai-engineering/index.html#dod-need-for-smaller-private-models",
    "title": "Return of the Nuggets – AI Engineering",
    "section": "DoD Need for smaller private models",
    "text": "DoD Need for smaller private models\n\n\n\n\nLLMs-at-DoD Chatting with your Data"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tatical-ammunition-management-micro-services-tamms",
    "href": "slides/agents_summer23/index.html#motivation-tatical-ammunition-management-micro-services-tamms",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: Tatical ammunition management Micro Services (TAMMS)",
    "text": "Motivation: Tatical ammunition management Micro Services (TAMMS)"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tamms-cognitive-agents",
    "href": "slides/agents_summer23/index.html#motivation-tamms-cognitive-agents",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: TAMMS cognitive Agents",
    "text": "Motivation: TAMMS cognitive Agents"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tamms-kg",
    "href": "slides/agents_summer23/index.html#motivation-tamms-kg",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: TAMMS KG",
    "text": "Motivation: TAMMS KG"
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs",
    "text": "Cognitive Agents based on LLMs\n\n\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv, August 5, 2023. http://arxiv.org/abs/2304.03442."
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs Architecture",
    "text": "Cognitive Agents based on LLMs Architecture\n\n\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv, August 5, 2023. http://arxiv.org/abs/2304.03442."
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture-framework",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture-framework",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs Architecture Framework",
    "text": "Cognitive Agents based on LLMs Architecture Framework\n\n\nPark, Joon Sung. “Generative Agents: Interactive Simulacra of Human Behavior,” August 22, 2023. https://github.com/joonspk-research/generative_agents."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-web-agents",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-web-agents",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Web Agents",
    "text": "Activity Specific Agents: Web Agents\n\n\nDeng, Xiang, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. “Mind2Web: Towards a Generalist Agent for the Web.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.06070."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-web-agents-architecture",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-web-agents-architecture",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Web Agents Architecture",
    "text": "Activity Specific Agents: Web Agents Architecture\n\n\nDeng, Xiang, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. “Mind2Web: Towards a Generalist Agent for the Web.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.06070."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Visual Agents",
    "text": "Activity Specific Agents: Visual Agents\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#visual-agents-architecture-different-llms-based-on-role",
    "href": "slides/agents_summer23/index.html#visual-agents-architecture-different-llms-based-on-role",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Visual Agents Architecture: Different LLMs based on Role",
    "text": "Visual Agents Architecture: Different LLMs based on Role\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents-transition-graph",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents-transition-graph",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Visual Agents Transition Graph",
    "text": "Activity Specific Agents: Visual Agents Transition Graph\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#aside-transformer-vision-and-segmentation-models",
    "href": "slides/agents_summer23/index.html#aside-transformer-vision-and-segmentation-models",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Aside: Transformer Vision and segmentation models",
    "text": "Aside: Transformer Vision and segmentation models\n\n\n“Alaamaalouf/FollowAnything.” Accessed August 22, 2023. https://github.com/alaamaalouf/FollowAnything.\nMaalouf, Alaa, Ninad Jadhav, Krishna Murthy Jatavallabhula, Makram Chahine, Daniel M. Vogt, Robert J. Wood, Antonio Torralba, and Daniela Rus. “Follow Anything: Open-Set Detection, Tracking, and Following in Real-Time.” arXiv, August 10, 2023. https://doi.org/10.48550/arXiv.2308.05737."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al. “Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-1",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-1",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al. “Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-2",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-2",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al. “Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#aside-prompt-engineering-guide",
    "href": "slides/agents_summer23/index.html#aside-prompt-engineering-guide",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Aside: Prompt Engineering Guide",
    "text": "Aside: Prompt Engineering Guide\n\n\n“Prompt Engineering Guide.” Accessed August 22, 2023. https://www.promptingguide.ai/."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools-gorilla",
    "href": "slides/agents_summer23/index.html#apis-as-tools-gorilla",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools: Gorilla",
    "text": "APIs as Tools: Gorilla\n\n\nPatil, Shishir G., Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. “Gorilla: Large Language Model Connected with Massive APIs.” arXiv, May 24, 2023. http://arxiv.org/abs/2305.15334."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools-architecture",
    "href": "slides/agents_summer23/index.html#apis-as-tools-architecture",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools: Architecture",
    "text": "APIs as Tools: Architecture\n\n\nPatil, Shishir G., Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. “Gorilla: Large Language Model Connected with Massive APIs.” arXiv, May 24, 2023. http://arxiv.org/abs/2305.15334."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools",
    "href": "slides/agents_summer23/index.html#apis-as-tools",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools",
    "text": "APIs as Tools\n\n\nPatil, Shishir. “Gorilla: Large Language Model Connected with Massive APIs [Project Website].” Python, August 22, 2023. https://github.com/ShishirPatil/gorilla."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llm-personality-traits",
    "href": "slides/agents_summer23/index.html#llm-personality-traits",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LLM Personality Traits",
    "text": "LLM Personality Traits\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#using-personality-tests",
    "href": "slides/agents_summer23/index.html#using-personality-tests",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Using Personality Tests",
    "text": "Using Personality Tests\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#behavior-persona-through-prompting",
    "href": "slides/agents_summer23/index.html#behavior-persona-through-prompting",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Behavior Persona Through Prompting",
    "text": "Behavior Persona Through Prompting\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llm-personality-traits-malleability",
    "href": "slides/agents_summer23/index.html#llm-personality-traits-malleability",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LLM Personality Traits Malleability",
    "text": "LLM Personality Traits Malleability\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#grounding-through-hybrid-kgs",
    "href": "slides/agents_summer23/index.html#grounding-through-hybrid-kgs",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Grounding Through Hybrid KGs",
    "text": "Grounding Through Hybrid KGs\n\n\nShirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs",
    "href": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\nLiu, Jerry. “LlamaIndex.” Python, November 2022. https://doi.org/10.5281/zenodo.1234."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs-1",
    "href": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs-1",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\n“Custom Retriever Combining KG Index and VectorStore Index - LlamaIndex 🦙 0.8.5.Post2.” Accessed August 22, 2023. https://gpt-index.readthedocs.io/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#data-agents-in-llamaindex",
    "href": "slides/agents_summer23/index.html#data-agents-in-llamaindex",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Data Agents in LlamaIndex",
    "text": "Data Agents in LlamaIndex\n\n\nFrom: Liu, Jerry. “Data Agents.” LlamaIndex Blog (blog), July 13, 2023. https://medium.com/llamaindex-blog/data-agents-eed797d7972f."
  },
  {
    "objectID": "slides/data-ai/index.html#trusted-ai-frameworks-for-knowledge-engineering",
    "href": "slides/data-ai/index.html#trusted-ai-frameworks-for-knowledge-engineering",
    "title": "Data Centric AI",
    "section": "Trusted AI Frameworks for Knowledge Engineering",
    "text": "Trusted AI Frameworks for Knowledge Engineering"
  },
  {
    "objectID": "slides/data-ai/index.html#foundational-components-for-trusted-ai",
    "href": "slides/data-ai/index.html#foundational-components-for-trusted-ai",
    "title": "Data Centric AI",
    "section": "Foundational Components for Trusted AI",
    "text": "Foundational Components for Trusted AI\n\nAutomate the integration and deployment of code, ensuring quality and operational efficiency.\nStandardized Development Environments: Establish consistent, easily replicable environments to accelerate development and experimentation.\nData & Experiment Versioning: Implement robust systems to track changes in data and experiments, allowing for traceability and repeatability.\nModel Lifecycle Management: Streamline the training, deployment, monitoring, and updating of machine learning models.\nFlexibility Across Layers: Design the architecture to allow for different levels of customization, from high-level APIs to low-level controls, facilitating adaptability."
  },
  {
    "objectID": "slides/data-ai/index.html#data-centric-ai",
    "href": "slides/data-ai/index.html#data-centric-ai",
    "title": "Data Centric AI",
    "section": "Data Centric AI",
    "text": "Data Centric AI\n\n\n\nData-centric AI Resource Hub"
  },
  {
    "objectID": "slides/data-ai/index.html#aside-lessons-from-the-semantic-web",
    "href": "slides/data-ai/index.html#aside-lessons-from-the-semantic-web",
    "title": "Data Centric AI",
    "section": "Aside: Lessons from the Semantic Web?",
    "text": "Aside: Lessons from the Semantic Web?\n\n\n\n\n\n\n“38971912 · Towards a Framework for Data Excellence in Data-Centric AI: Lessons from the Semantic Web,” SlidesLive. (accessed Sep. 14, 2023)."
  },
  {
    "objectID": "slides/data-ai/index.html#dvc-and-data-centric-ai",
    "href": "slides/data-ai/index.html#dvc-and-data-centric-ai",
    "title": "Data Centric AI",
    "section": "DVC and Data Centric AI?",
    "text": "DVC and Data Centric AI?\nData-centric AI is an emerging concept that emphasizes the importance of data quality and data engineering in building AI systems. Data-centric AI aims to improve the performance and robustness of AI models by systematically characterizing, evaluating, and monitoring the underlying data used to train and evaluate them⁴. Data-centric AI also involves using data-driven methods and tools to inform the considerations at each stage of the ML pipeline⁴.\nOne of the tools that can help with data-centric AI is Data Version Control (DVC), which is a system for versioning machine learning models, data sets, and intermediate files. DVC connects them with code, and uses various storage options to store file contents³. DVC allows users to track and reproduce the experiments, share data and models, and collaborate effectively on AI projects³.\nIf you want to learn more about data-centric AI, you can check out some of the web search results I found for you. For example, you can read a survey paper that discusses the necessity, goals, methods, challenges, and benchmarks of data-centric AI¹. You can also watch a video lecture by Andrew Ng, who popularized the term data-centric AI⁶. Or you can explore a website that provides a checklist and resources for applying data-centric AI in practice⁴. I hope this helps you understand what data-centric AI is and how DVC can be useful for it. 😊\nSource: Conversation with Bing, 9/14/2023\n\nWhat is Data-Centric AI? - van der Schaar Lab..\nData Version Control · DVC..\n[2303.10158] Data-centric Artificial Intelligence: A Survey - arXiv.org..\nThe Principles of Data-Centric AI (DCAI) - arXiv.org..\nWhat is Data-Centric Architecture in AI? | Simplilearn.."
  },
  {
    "objectID": "slides/data-ai/index.html#data-version-control-dvc",
    "href": "slides/data-ai/index.html#data-version-control-dvc",
    "title": "Data Centric AI",
    "section": "Data Version Control (DVC)",
    "text": "Data Version Control (DVC)\n\n\n\n\nData Version Control - DVC"
  },
  {
    "objectID": "slides/data-ai/index.html#hugging-face",
    "href": "slides/data-ai/index.html#hugging-face",
    "title": "Data Centric AI",
    "section": "Hugging Face",
    "text": "Hugging Face\n\n\n\n\nThe Hugging Face 🤗 Data Measurements Tool - Data-centric AI Resource Hub (datacentricai.org)\nIntroducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets (huggingface.co)\nDataMeasurementsTool - a Hugging Face Space by huggingface"
  },
  {
    "objectID": "slides/data-ai/index.html#ai-testimony-before-us-senate",
    "href": "slides/data-ai/index.html#ai-testimony-before-us-senate",
    "title": "Data Centric AI",
    "section": "AI Testimony before US Senate",
    "text": "AI Testimony before US Senate\n\n\n\n\n\n\nClement Delangue Senate Statement"
  },
  {
    "objectID": "slides/data-ai/index.html#dvc-and-huggingface-integration-team-frameworks-peter",
    "href": "slides/data-ai/index.html#dvc-and-huggingface-integration-team-frameworks-peter",
    "title": "Data Centric AI",
    "section": "DVC and Huggingface Integration (Team Frameworks – Peter)",
    "text": "DVC and Huggingface Integration (Team Frameworks – Peter)\n\nShare a dataset to the Hub (huggingface.co)\nimport: from external git does not import lfs-tracked file content · Issue #9175 · iterative/dvc (github.com)\nHow to connect Huggingface datasets as a dvc remote · iterative/dvc · Discussion #8267 (github.com)\nAI BoMs from our SBoM Analysis"
  },
  {
    "objectID": "slides/data-ai/index.html#json-ld-model-and-ai-based-microservices",
    "href": "slides/data-ai/index.html#json-ld-model-and-ai-based-microservices",
    "title": "Data Centric AI",
    "section": "JSON-LD Model and “AI Based Microservices”",
    "text": "JSON-LD Model and “AI Based Microservices”\n\n\n\nSPDX V3 is JSON-LD!\nFrequently asked questions - Azure Verifiable Credentials - Microsoft Entra | Microsoft Learn\nWell Known DID Configuration\nUses the same structure as a OpenAI/Microsoft Plugin"
  },
  {
    "objectID": "slides/data-ai/index.html#motivation",
    "href": "slides/data-ai/index.html#motivation",
    "title": "Data Centric AI",
    "section": "Motivation…",
    "text": "Motivation…"
  },
  {
    "objectID": "slides/data-ai/index.html#how-do-we-develop-a-curriculum-for-training-large-language-models",
    "href": "slides/data-ai/index.html#how-do-we-develop-a-curriculum-for-training-large-language-models",
    "title": "Data Centric AI",
    "section": "How do we develop a curriculum for training large language models?",
    "text": "How do we develop a curriculum for training large language models?"
  },
  {
    "objectID": "slides/data-ai/index.html#the-pile",
    "href": "slides/data-ai/index.html#the-pile",
    "title": "Data Centric AI",
    "section": "The “Pile”",
    "text": "The “Pile”"
  },
  {
    "objectID": "slides/data-ai/index.html#llama-open-and-efficient-foundation-language-models",
    "href": "slides/data-ai/index.html#llama-open-and-efficient-foundation-language-models",
    "title": "Data Centric AI",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux,Timothée Lacroix, Baptiste Rozière, et al. “LLaMA: Open and Efficient Foundation Language Models.” arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/data-ai/index.html#gpt-4-sparks-of-agi",
    "href": "slides/data-ai/index.html#gpt-4-sparks-of-agi",
    "title": "Data Centric AI",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\nSparks of AGI: Early Experiments with GPT-4, 2023. https://www.youtube.com/watch?v=qbIk7-JPB2c."
  },
  {
    "objectID": "slides/data-ai/index.html#textbooks-are-all-you-need",
    "href": "slides/data-ai/index.html#textbooks-are-all-you-need",
    "title": "Data Centric AI",
    "section": "Textbooks Are All You Need!",
    "text": "Textbooks Are All You Need!\n\n\n\nTextbooks Are All You Need, 2023. https://www.youtube.com/watch?v=24O1KcIO3FM."
  },
  {
    "objectID": "slides/data-ai/index.html#textbooks-are-all-you-need-1",
    "href": "slides/data-ai/index.html#textbooks-are-all-you-need-1",
    "title": "Data Centric AI",
    "section": "Textbooks Are All You Need!",
    "text": "Textbooks Are All You Need!\n\n\n\nGunasekar, Suriya, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, et al. “Textbooks Are All You Need.” arXiv, June 20, 2023. http://arxiv.org/abs/2306.11644."
  },
  {
    "objectID": "slides/data-ai/index.html#textbooks-are-all-you-need-ii-phi-1.5",
    "href": "slides/data-ai/index.html#textbooks-are-all-you-need-ii-phi-1.5",
    "title": "Data Centric AI",
    "section": "Textbooks are all you need II: phi-1.5",
    "text": "Textbooks are all you need II: phi-1.5\n\n\n\nY. Li, S. Bubeck, R. Eldan, A. Del Giorno, S. Gunasekar, and Y. T. Lee, “Textbooks Are All You Need II: phi-1.5 technical report.” arXiv, Sep. 11, 2023. Accessed: Sep. 12, 2023. [Online]. Available: http://arxiv.org/abs/2309.05463"
  },
  {
    "objectID": "slides/data-ai/index.html#coding-textbooks",
    "href": "slides/data-ai/index.html#coding-textbooks",
    "title": "Data Centric AI",
    "section": "“Coding Textbooks”",
    "text": "“Coding Textbooks”"
  },
  {
    "objectID": "slides/data-ai/index.html#improving-data-quality-by-using-big-brain-llm",
    "href": "slides/data-ai/index.html#improving-data-quality-by-using-big-brain-llm",
    "title": "Data Centric AI",
    "section": "Improving data quality by using “Big Brain LLM”",
    "text": "Improving data quality by using “Big Brain LLM”"
  },
  {
    "objectID": "slides/data-ai/index.html#textbooks-are-all-you-need-ii-phi-1.5-1",
    "href": "slides/data-ai/index.html#textbooks-are-all-you-need-ii-phi-1.5-1",
    "title": "Data Centric AI",
    "section": "Textbooks are all you need II: phi-1.5",
    "text": "Textbooks are all you need II: phi-1.5\n\n\n\nMicrosoft/phi-1_5"
  },
  {
    "objectID": "slides/data-ai/index.html#phi-1.5-doesnt-want-to-kill-us-all",
    "href": "slides/data-ai/index.html#phi-1.5-doesnt-want-to-kill-us-all",
    "title": "Data Centric AI",
    "section": "phi-1.5 Doesn’t want to kill us all…",
    "text": "phi-1.5 Doesn’t want to kill us all…\n\n\n\nSebastien Bubeck on X"
  },
  {
    "objectID": "slideindex.html",
    "href": "slideindex.html",
    "title": "Weekly Nugget Presentations",
    "section": "",
    "text": "Tools for Building Agentic Systems\n\n\n\n\n\n\nAgents\n\n\nAgentic Workflows\n\n\nTrustedAI\n\n\n\n\n\n\n\n\n\nSep 27, 2024\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nAdvances in Agent-Based Big AI\n\n\nNuggets from the Summer\n\n\n\nAgents\n\n\nAgentic Workflows\n\n\nTrustedAI\n\n\n\n\n\n\n\n\n\nSep 13, 2024\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nAgentic Workflow Design Patterns\n\n\n\n\n\n\nAgents\n\n\nLLMs\n\n\nDesign Patterns\n\n\n\n\n\n\n\n\n\nApr 5, 2024\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nRetrieval Augmented Generation – Part 1\n\n\n\n\n\n\nLLMs\n\n\nTrustedAI\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nJoint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information\n\n\n\n\n\n\nLLMs\n\n\nTrustedAI\n\n\n\n\n\n\n\n\n\nFeb 2, 2024\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nDr V. Holiday 2023 Viewing Guide\n\n\n\n\n\n\nLLMs\n\n\nTrustedAI\n\n\n\n\n\n\n\n\n\nDec 1, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nReturn of the Nuggets – AI Engineering\n\n\n\n\n\n\nAI Engineering\n\n\nLLMOps\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nTowards Trusted LLM based Curator Agents\n\n\n\n\n\n\nLLMs\n\n\nAgents\n\n\nKnowledge Graphs\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nH4x0rz GU!dE t0 1lms\n\n\n\n\n\n\nLLMs\n\n\nTools\n\n\n\n\n\n\n\n\n\nOct 5, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nData Centric AI\n\n\n\n\n\n\nTrustedAI\n\n\nData Centric AI\n\n\n\n\n\n\n\n\n\nSep 15, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nTools for Trusted AI\n\n\n\n\n\n\nTools\n\n\nFrameworks\n\n\n\n\n\n\n\n\n\nSep 5, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding “Stuff”?\n\n\n\n\n\n\nAgents\n\n\ntrustedAI\n\n\nDevelopment\n\n\n\n\n\n\n\n\n\nSep 5, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nA Summer of Nuggets\n\n\n\n\n\n\nnuggets\n\n\ntrustedAI\n\n\nLLMs\n\n\n\n\n\n\n\n\n\nAug 28, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Dr. Vardeman is worried about: Trusted cognitive Agents\n\n\n\n\n\n\nAgents\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nThings that concern Dr. Vardeman: Testing\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\nTesting\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nKG Construction\n\n\n\n\n\n\nKnowledge Engineering\n\n\nKG Construction\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n\n\n\n\n\n\nTrust and Causal Reasoning\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "At the University of Notre Dame’s Center for Research Computing (CRC), the Laboratory for Assured AI Applications Development (LA3D) represents a critical step in the field of artificial intelligence (AI). As part of CRC’s commitment to leveraging advanced computation for discovery and innovation, LA3D focuses on ensuring the responsible development and application of AI technologies. This initiative aligns with both the technological evolution of AI and the broader goals of CRC and Notre Dame.\nThe mission of LA3D is robust, layered, and rooted in a commitment to research, develop, and deploy AI models and systems that are not just innovative but trustworthy and ethically aligned. With a focus on AI Engineering, Trusted AI, Knowledge Engineering, FAIR (Findable, Accessible, Interoperable, and Reusable) data, and CyberInfrastructure, LA3D presents a multifaceted approach.\nAI’s Transformative Potential: The transformative potential of AI is no longer a distant aspiration but a present-day reality. Whether in healthcare, finance, transportation, or education, AI’s capacity to innovate is unparalleled. LA3D recognizes this potential and strives to harness it, directing AI’s power towards constructive, ethical, and sustainable ends.\nConnection to the Center for Research Computing: LA3D’s home in the CRC is more than a mere geographical placement. It symbolizes a shared vision of advancing science through computational methods, high-performance computing, and now, AI-driven solutions. By integrating into the CRC’s vibrant ecosystem, LA3D amplifies the pursuit of excellence, pushing the boundaries of what’s achievable with AI.\nMission Overview: LA3D’s mission transcends traditional boundaries, aiming to advance fields like AI Engineering, with its critical role in transitioning prototypes to production; Trusted AI, embodying ethical and reliable systems; Knowledge Engineering, embracing the new frontiers of Large Language Models; FAIR data principles; and the rapidly evolving CyberInfrastructure. Each of these elements comes together to create a synergy that fuels LA3D’s ambition to lead AI into an era marked by integrity, ingenuity, and human-centric focus.\nThe launch of LA3D marks a promising beginning in a journey filled with exploration, challenge, and opportunity. It sets the stage for an intellectual adventure that seeks to navigate the complex landscape of AI, unlocking its potentials while remaining anchored to values and ethical principles. Welcome to the Laboratory for Assured AI Applications Development – a place where AI’s promise transforms into tangible progress."
  },
  {
    "objectID": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "href": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "The Imperative of the Disciplines",
    "text": "The Imperative of the Disciplines\n\nAI Engineering: Bridging the Gap from Prototype to Production\nIn the complex, multifaceted realm of AI, the journey from concept to realization is fraught with challenges and intricacies. AI Engineering, a core discipline at the Laboratory for Assured AI Applications Development (LA3D), stands as a beacon guiding this intricate transition from prototypes to production-grade applications.\n\nTransitioning Prototypes to Production: At LA3D, we recognize that the gap between experimental AI prototypes and fully functional production systems is vast. AI Engineering provides the methodologies, tools, and practices needed to navigate this gap. It’s about ensuring that promising concepts don’t just remain on paper but evolve into tangible applications. The recent Gartner research resonates with our approach, identifying that only 53% of AI projects transition from prototypes to production, underscoring the need for an engineering-driven approach.\nCore Pillars: DataOps, ModelOps, DevOps: DataOps focuses on data management and quality, ModelOps on model lifecycle management, and DevOps for seamless integration. These three core pillars together facilitate performance, scalability, interpretability, and reliability of AI models, maximizing the value of AI investments.\nAssurance in AI Models and Mechanistic Interpretability: Assurance in AI Models and Mechanistic Interpretability: Trust and reliability lie at the core of AI Engineering. At LA3D, the utilization of energy-based modeling, specifically Joint Energy-Based Models (JEMs), offers a transparent and statistically grounded approach to AI. By learning joint distributions over observed and latent variables, and associating lower energies with more likely configurations, JEMs help in aligning AI models with ethical guidelines and intended purposes. This mechanistic interpretability, coupled with the robust design inherent in JEMs, ensures predictability and engenders trust. Such alignment is vital for Assured AI, where understanding the underlying patterns and regularities in data becomes a cornerstone for creating reliable and responsible applications.\nScalability, Efficiency, Lifecycle Management, and Data-Centric AI: Ensuring consistent performance across different scales and complexities is crucial. LA3D’s AI Engineering practices enable models to be deployed in various environments without losing integrity or performance. Managing AI models throughout their lifecycle through continuous monitoring, validation, and maintenance ensures adaptability and alignment with evolving objectives. The emphasis on Data-Centric AI reflects LA3D’s commitment to focusing on the quality of data, recognizing that data is the lifeblood of AI systems.\nInterdisciplinary Collaboration and Alignment with Human Values: AI Engineering fosters collaboration among data scientists, engineers, domain experts, and ethical compliance teams. The result is cohesive AI development, where varying perspectives merge to create solutions resonating with diverse needs and values. At LA3D, AI serves human values and societal needs, ensuring that technology is not only technically sound but also socially responsible.\nEmbracing CyberSecurity: Coupled with a growing interest in CyberSecurity, LA3D extends the scope of AI Engineering to safeguard information and assure security in AI applications.\n\nAI Engineering is not merely a process at LA3D; it’s a philosophy and an imperative discipline. It’s the bedrock that ensures AI models are not just innovative but also responsible, practical, and aligned with the human experience. Bridging the gap from prototype to production, AI Engineering paves the way for a future where AI is not just a tool but a reliable partner for progress. Join us on this journey as we delve deeper into AI Engineering, exploring its challenges, triumphs, and nuances.\n\n\nTrusted AI: A Cornerstone of Ethical and Reliable Systems\nTrusted AI is not just a concept; it’s a commitment to integrity, ethics, and societal alignment that LA3D wholeheartedly embraces. Trust in AI is an essential component in our technological landscape, and it embodies various facets that work in synergy to create ethical and reliable systems.\n\nAssurance in AI Models: At LA3D, assurance goes beyond mere compliance; it’s about creating AI models that can be understood, scrutinized, and validated. Building AI models that can explain their reasoning and provide clarity in their decisions is integral to creating trust.\nTransparency and Accountability: The quest for Trusted AI demands complete transparency in both process and outcomes. LA3D adheres to an open and comprehensible approach that allows all stakeholders to understand how decisions are made and who is accountable for them. Ensuring this level of transparency fosters an environment where AI models can be thoroughly evaluated and critiqued, reinforcing trust in their use.\nResponsible AI: While Trusted AI focuses on reliability and ethics, Responsible AI broadens the spectrum to include considerations such as fairness, inclusivity, privacy, and societal impact. At LA3D, we recognize that AI systems must not only operate within ethical guidelines but also actively contribute to the well-being of society. This commitment to social responsibility aligns with our holistic approach to developing technology that enriches lives.\nCyberSecurity in AI: As AI systems become more intertwined with our daily lives, the need to secure them becomes paramount. LA3D is committed to incorporating CyberSecurity measures within the AI development process, safeguarding data and protecting the integrity of AI systems. We understand that trust in AI also depends on the security of the systems, and we dedicate our resources to ensure that our AI applications are robust against threats.\n\nTrusted AI is a cornerstone at LA3D, reflecting our relentless pursuit of aligning technology with human values and ethical principles. It’s about creating AI that people can rely on, understand, and feel safe using. The interplay between transparency, accountability, Responsible AI, and CyberSecurity forms a unified approach to build AI systems that not only perform exceptionally but also resonate with the broader societal goals.\nJoin us as we explore further the nuances of Trusted AI, a field where technology and ethics merge to pave the way for a future where AI is a dependable ally. Our commitment to this discipline underscores the depth of our understanding of the complexities involved in crafting AI that is truly trusted.\nThis section outlines the key areas of Trusted AI that LA3D focuses on, emphasizing the importance of trust, transparency, responsibility, and security within the AI domain. It underscores the laboratory’s dedication to ethical and reliable AI systems, aligning with societal needs and values.\n\n\nKnowledge Engineering and Prompt Engineering: The New Frontiers\nIn the rapidly evolving landscape of artificial intelligence, Knowledge Engineering and Prompt Engineering emerge as exciting new frontiers that promise to reshape the way we conceptualize, create, and leverage AI systems. At the Laboratory for Assured AI Applications Development (LA3D), we recognize the vital role of these disciplines in shaping the next generation of AI applications.\n\nKnowledge Graphs: Knowledge graphs represent a transformative approach to organizing and connecting information. By modeling relationships between entities in a structured and semantically rich format, knowledge graphs enable more intelligent querying and reasoning. LA3D actively leverages knowledge graphs to power more insightful and context-aware AI solutions.\nOntology Design Patterns: A specialized aspect of Knowledge Engineering, ontology design patterns allow for the formal representation of concepts and their relationships within a specific domain. By utilizing these patterns, LA3D ensures that AI systems have a solid conceptual foundation, enabling more precise interpretation and decision-making.\nLLM Techniques: Large Language Models (LLMs) are revolutionizing natural language processing. By employing techniques like Prompt Engineering, LA3D refines the interaction with LLMs, enhancing their responsiveness and adaptability. This method allows for more effective communication with AI systems, aligning them closer to human-like understanding.\nAI Models as Surrogates: At LA3D, we explore the exciting potential of AI models as surrogates for complex mathematical or physical models. These AI surrogates can provide faster and more accessible simulations, accelerating research and opening new avenues for exploration in science and engineering.\nAI Co-Pilots for Various Tasks: Beyond acting as mere tools, AI models are now being developed as intelligent co-pilots, assisting human experts in a variety of tasks. Whether aiding in data analysis, guiding complex problem-solving, or enhancing creative processes, AI co-pilots represent a new paradigm of collaboration between human and machine intelligence.\n\nKnowledge Engineering and Prompt Engineering are not mere additions to the AI toolkit; they are pivotal advancements that herald a new era in AI application design and interaction. By embracing these new frontiers, LA3D reinforces its commitment to innovation, excellence, and the relentless pursuit of AI that is not just cutting-edge but profoundly attuned to human needs and aspirations. Join us as we explore these new horizons, uncovering the immense potential and profound implications they hold for the future of AI.\n\n\nThe Evolution of CyberInfrastructure and AI-Driven Science AI-Driven Science\nThe seamless integration of CyberInfrastructure with AI-driven science marks a transformative phase in research and innovation. As part of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing (CRC), we are at the forefront of this exciting convergence, pioneering approaches that harness the power of advanced computing technologies to accelerate scientific discovery.\n\nAI-Driven Science: The infusion of AI into scientific research has ushered in a new era of data-driven exploration and insight. At LA3D, we employ AI models to analyze complex data sets, predict outcomes, and even guide experimental design. From enhancing medical diagnostics to predicting climate patterns, AI-driven science is unlocking unprecedented opportunities for understanding and innovation.\nRelevance to CRC: The Center for Research Computing at Notre Dame is committed to providing cutting-edge computational resources and expertise. The collaboration with LA3D amplifies this commitment by aligning AI research with state-of-the-art CyberInfrastructure. Together, we’re pushing the boundaries of what’s possible in computational science.\nAI Surrogates for Mathematical Models: Building on the AI surrogates concept, we utilize AI models to replicate complex mathematical or physical systems within CRC. These surrogates enable faster simulations and insights, thus accelerating research and expanding our ability to tackle previously intractable problems.\nAI Co-Pilots for Scientific Exploration: The development of AI co-pilots has extended into the realm of scientific exploration at CRC. These intelligent systems act as collaborators, assisting researchers in hypothesis formulation, data analysis, and problem-solving. It’s a revolutionary approach that augments human intelligence with AI, fostering a new level of creativity and rigor in scientific inquiry.\nIntegration of CyberInfrastructure: A robust CyberInfrastructure is foundational to AI-driven science at CRC. By weaving together high-performance computing, cloud technologies, and specialized software, we’re creating a dynamic environment where AI and computational science flourish. It’s a synergy that optimizes research processes, enhances collaboration, and catalyzes breakthroughs.\n\nThe evolution of CyberInfrastructure and AI-driven science at CRC represents more than technological advancement; it’s a paradigm shift in how we approach research and discovery. Through strategic collaboration and relentless innovation, we’re crafting a future where technology and human intellect unite to illuminate the unknown. Join us on this path, as we explore the incredible potential and promise of this convergence, continually striving to redefine the boundaries of what is possible in science and beyond."
  },
  {
    "objectID": "posts/welcome/index.html#blogs-objective-and-overview",
    "href": "posts/welcome/index.html#blogs-objective-and-overview",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "Blog’s Objective and Overview",
    "text": "Blog’s Objective and Overview\nIn alignment with the University of Notre Dame’s mission to seek knowledge that addresses humanity’s pressing challenges, and the Center for Research Computing’s (CRC) commitment to driving innovation, the Laboratory for Assured AI Applications Development (LA3D) is pleased to unveil this blog as an essential platform.\n\nWeekly Updates: Engage with regular insights into the ongoing research, technological advancements, and creative pursuits within LA3D. From AI Engineering to Trusted AI, we’ll keep our community abreast of the exciting developments shaping our field.\nInsights into Trusted AI, CI-Compass, and More: Delve into the core projects and collaborations within LA3D, including specialized explorations into the worlds of Trusted AI, CI-Compass, CyberSecurity in AI, and the nuances of Responsible AI.\nAI Workforce Development: Recognizing the need for a skilled and knowledgeable AI workforce, this blog will feature initiatives, programs, and strategies dedicated to cultivating the next generation of AI professionals. Together with CRC, we strive to foster education, mentorship, and career development in AI.\nResearch Publications and Highlights: Discover the rich tapestry of research being woven at LA3D. We’ll highlight key publications, conference achievements, and innovative studies that reflect our commitment to excellence and alignment with Notre Dame’s values.\nCommunity Engagement and Collaboration: Building on Notre Dame’s emphasis on community and service, this blog invites you to participate, share, and learn. Join a lively dialogue that celebrates diversity of thought and collaboration in pursuit of a greater understanding of Assured AI.\nSpotlight on CyberSecurity in AI and Emerging Topics: As part of our comprehensive view of modern AI, we will dedicate specific sections to explore critical areas like CyberSecurity and the delicate balance between Responsible and Trusted AI.\nConnection to Notre Dame’s and CRC’s Mission: This blog embodies the spirit of Notre Dame and CRC’s shared mission to advance knowledge, foster innovation, and contribute to society. We strive to make the pursuit of AI not only a scientific endeavor but also a means to enrich lives and address societal needs.\n\nIn the introduction, we’ve outlined the essential areas of focus at the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. From AI Engineering’s crucial role in transitioning prototypes to production, to the ethical imperatives in Trusted AI, Knowledge Engineering, CyberSecurity in AI, and the blog’s alignment with the missions of CRC and Notre Dame, we’ve set the stage for a comprehensive exploration.\nOur blog serves as a platform to dive into these topics, including AI workforce development and the ways in which AI intersects with societal needs and technological advancements. As we move forward, we’ll examine these subjects in detail, shedding light on the challenges, successes, and ongoing efforts in these fields.\nStay tuned as we delve into the complexities of AI, with insights and updates that reflect LA3D’s commitment to innovation, responsibility, and real-world applicability. Join us in this exploration, as we strive to make AI not just a tool, but a reliable partner for progress."
  },
  {
    "objectID": "posts/frameworks-reflection/index.html",
    "href": "posts/frameworks-reflection/index.html",
    "title": "Reflections on Trusted AI Frameworks after two years",
    "section": "",
    "text": "With artificial intelligence advancing rapidly, ensuring these technologies are trustworthy and ethical is critical, especially in high-stakes domains like defense and national security.\nThe Trusted AI (TAI) Frameworks Project was launched in 2021 through a collaboration between Indiana University, Purdue University, the University of Notre Dame, and the Naval Surface Warfare Center Crane Division (NSWC Crane) located in southwestern Indiana.\nFunded by Purdue’s Scalable Asymmetric Lifecycle Engagement (SCALE) initiative, the project brings together these Indiana-based partners to advance trusted AI research and workforce development tailored to the needs of the U.S. Navy and Marine Corps.\nThe University of Notre Dame contributes vital expertise in areas such as cybersecurity, privacy, and ethical AI to ensure the systems developed not only perform effectively but align with ethical values. Researchers from computing, engineering, psychology, and ethics collaborate to provide a multidisciplinary perspective.\nIndiana’s strong defense, technology, and research presence, including major contractors and NSWC Crane’s AI Development Lab, provide a strategic foundation to jointly create AI solutions that are robust, reliable, and transparent.\nAt the core of the project are six dimensions of trust in AI systems:\nIntegrating these trust principles throughout the AI lifecycle, from data collection to deployment, is critical for successful adoption within the naval domain. The TAI Frameworks Project provides research, methodologies and tools to enable trusted and ethical AI.\nThis collaborative initiative has evolved substantially in its first two years. This post reflects on progress so far and visions for the road ahead in strengthening trust in AI systems, serving both the Navy’s mission and broader societal values.\nReflection on the Framework Project\nAs we reflect on the past years, the TAI Frameworks Project has continuously evolved and adapted in the rapidly changing landscape of AI research and technology.\nThe project originated from a proposal led by initial PI Prof. Ian Taylor. After acceptance but before work commenced, Prof. Jarek Nabrzyski took over as PI with co-PIs Prof. Prof. Chris Sweet and myself. This initial phase focused on integrating dimensions of trust into the methodologies.\nI assumed the PI role in year two to align the project with emerging Navy needs, as we are now entering year three.\nIn the early stages, Prof. Don Brower provided valuable expertise in metadata while Dr. James Sweet reviewed open source AI tools. Prof. Paul Brenner later contributed insights on computing infrastructure and security.\nUndergraduate students including Peter Ainsworth, Nicholas Clark and Daniel Weldon conducted hands-on evaluation of framework components like Quarto, nbdev, and DVC for data versioning. Daniel Weldon along with William Shephard, Samantha Nagel explored containerization of AI models and frameworks like Pytorch using platforms like IronBank to understand deployment complexity with regard to the DoD Cloud Infrastructure.\nThroughout its evolution, the project has adapted based on insights from key partners while maintaining the vision for Trusted AI put forth in the initial proposal by Prof. Taylor. This foundation enables us to confront new challenges and opportunities going forward.\nA core framework diagram, Figure 2, illustrates the end-to-end AI development workflow, spanning problem definition, data collection, model training, deployment, and monitoring. It highlights key tools and technologies including data science, machine learning frameworks, cloud platforms, and DevOps techniques that enable trustworthy AI aligned to specific use cases. The diagram reflects the multifaceted scope of the AI lifecycle, providing a structure for the frameworks, methodologies and collaborations that foster ethical, trustworthy and effective AI development.\nCommunity Engagement and Collaboration\nOur journey has emphasized collaboration, dialogue, and shared learning. By leveraging existing tools and methodologies and engaging in broader community efforts, we have fostered an environment where knowledge is not just consumed but also contributed.\nLooking Ahead and Future Vision\nAs we move forward, our commitment to continuous alignment with trust dimensions and evolving methodologies remains steadfast. Our reflection on achievements and lessons learned will be a guiding light, illuminating the path towards future developments in trusted AI."
  },
  {
    "objectID": "posts/frameworks-reflection/index.html#building-a-foundation-for-trusted-ai",
    "href": "posts/frameworks-reflection/index.html#building-a-foundation-for-trusted-ai",
    "title": "Reflections on Trusted AI Frameworks after two years",
    "section": "1 Building a Foundation for Trusted AI",
    "text": "1 Building a Foundation for Trusted AI\n\n1.1 Software 1.0 vs Software 2.0: Building Trust from the Ground Up\nThe evolution from “Software 1.0” to “Software 2.0,” as popularized by Andrej Karpathy (Karpathy 2017), represents a paradigm shift in how we develop and deploy software systems.\n\nSoftware 1.0 is characterized by deterministic, programmed behavior where engineers write explicit code to define how a system should operate. It’s a method where rules are meticulously crafted, and the outcome is predictable, given a specific set of inputs.\nSoftware 2.0, in contrast, signifies learned behavior where models are trained on data to infer the underlying patterns. Unlike the rigid rules of Software 1.0, Software 2.0 can handle immense complexity, learning from examples to generalize and adapt to new situations. This ability to process and respond to intricate, multi-dimensional inputs sets Software 2.0 apart, opening doors to applications previously thought unfeasible.\n\nThe implications of Software 2.0 are profound for sectors that face highly complex and dynamic environments, such as those present in Navy operations. Where traditional rule-based systems may falter or become unwieldy, Software 2.0 offers the flexibility and adaptability to respond to ever-changing scenarios. Its capacity to absorb and interpret vast amounts of information in real-time provides a powerful tool in navigation, threat assessment, strategy formulation, and more. For the Navy, it enables a more resilient, intelligent, and agile approach to both strategic planning and operational execution.\nHowever, the promise of Software 2.0 doesn’t diminish the importance of Trusted “Software 1.0” as the foundation. Stability, predictability, and reliability remain essential, and the Trusted AI Frameworks Project recognizes the symbiotic relationship between these two paradigms. Trusted “Software 1.0” forms the stable base, while Trusted “Software 2.0” enables more dynamic and complex solutions.\nThe interplay between these two layers presents exciting opportunities and challenges, requiring rigorous validation, ethical considerations, and collaboration to ensure responsible deployment. It’s a multifaceted challenge that intertwines technology, ethics, collaboration, and vision, reflecting the complex reality of modern warfare and strategic planning.\n\n\n1.2 GitOps and AI Engineering: Collaborative Practices for Success\nIn the transition from “Software 1.0” to “Software 2.0,” where complexity and adaptability take center stage, the underlying practices that ensure quality and trust must also evolve. GitOps and collaborative environments like GitHub have emerged as essential tools in this transformation.\n\n1.2.1 What is GitOps?\nGitOps is a methodology that applies Git’s version control principles to the entire infrastructure and development lifecycle. By treating everything as code, including infrastructure and configuration, GitOps enables robust version control, audit trails, and collaboration. Changes are made in the Git repository, and automated systems ensure that the live environment aligns with the defined code state.\n\n\n1.2.2 Importance in Traditional and AI Engineering\n\nTraditional Software Engineering: In the context of “Software 1.0,” GitOps brings consistency, traceability, and collaboration. It provides a unified platform where the entire development team can work together, tracking changes, rolling back when necessary, and maintaining a clear history of modifications. This shared workspace enhances communication, accelerates development, and minimizes the risk of errors.\nAI Engineering: The shift to “Software 2.0” introduces new complexities and dependencies. GitOps adapts to these challenges by offering a flexible and responsive platform that can manage intricate workflows, diverse data sets, and multi-dimensional models. The collaborative nature of platforms like GitHub fosters cross-functional engagement, leveraging collective expertise to scrutinize, enhance, and validate AI models.\n\n\n\n1.2.3 Enhancing Trust and Quality\nBy embracing GitOps, projects can benefit from continuous integration, testing, and deployment. This CI/CD methodology promotes a culture of ongoing evaluation and refinement, where each change undergoes rigorous scrutiny. This process not only ensures quality but also builds trust, as stakeholders have transparent visibility into how decisions are made and how the software evolves.\nFor the Navy, where trust and reliability are paramount, this transparent, collaborative approach aligns with the ethos of responsibility and accountability. By implementing GitOps within the Trusted AI Frameworks Project, the partners foster an environment conducive to innovation, quality, and ethical considerations.\n\n\n\n1.3 CI/CD in Trusted AI: Ensuring Continuous Quality\nContinuous Integration/Continuous Deployment (CI/CD) is not a new concept in software development. Still, its application within the realm of AI and “Software 2.0” introduces unique opportunities and challenges. With AI’s rapid evolution and the growing prominence of foundation models and transfer learning, CI/CD becomes a vital component in maintaining quality, transparency, and trust.\n\n1.3.1 Applying CI/CD to AI “Software 2.0”\n\nFoundation Models: These are large-scale pre-trained models that serve as a base for specialized adaptations. By understanding intricate patterns in extensive data sets, foundation models can be fine-tuned for various tasks, enabling more rapid development and deployment.\nTransfer Learning Methodology: This approach leverages existing pre-trained models (often foundation models) and adapts them to specific tasks or domains. It allows for quicker iterations, conserves resources, and enhances performance on specialized tasks.\n\nIncorporating CI/CD into these AI practices ensures that as models are adapted and evolve, they continue to meet quality standards and align with ethical considerations. It promotes a transparent process, where every modification, every decision, can be traced and validated.\n\n\n1.3.2 Building Trust and Transparency\n\nRapid Integration and Evolution: With AI’s pace, a responsive CI/CD pipeline is essential. Models are constantly refined, adapted, and expanded. Ensuring that these changes are integrated smoothly, without compromising quality, is key to building trust.\nEthical Considerations: Transparency in the AI development process is more than a technical requirement; it’s an ethical obligation. A well-designed CI/CD process provides clear visibility into the workings of AI models, supporting responsible decision-making and accountability.\n\nCertainly! Below is a revised version of your text that incorporates the information we discussed, specifically focusing on the functionality, real-world application, unit and behavior testing, and the continuous iterative process.\n\n\n1.3.3 “Data Engines” in AI CI/CD\nThe innovative concept of “Data Engines” in AI CI/CD refers to an intelligent, integrated system that orchestrates various stages of AI development, from data collection to model deployment, including vital aspects of unit and behavior testing.\n\nComponents and Functionality: A Data Engine incorporates real-time data ingestion, preprocessing, feature engineering, model training, evaluation, acceptance testing, and deployment. Unit testing ensures the individual components’ correctness, while behavior testing verifies the overall system behavior. Together, they serve as the backbone, ensuring that models adapt, learn, and evolve in alignment with real-world complexities and requirements.\nReal-World Example: Tesla’s Data Engine Pipeline: Tesla’s self-driving technology leverages a Data Engine that continually feeds information from vehicles on the road into its AI models. This pipeline manages vast quantities of data, refines features, adapts models, and deploys updates, all in an iterative and seamless manner. Through rigorous unit and behavior testing, it ensures accuracy and responsiveness. This example illustrates how Data Engines can handle the dynamism and complexity inherent in modern AI systems.\nChallenges and Solutions: Integrating a Data Engine within the AI CI/CD process is not without challenges. These may include ensuring data quality, scalability, adherence to ethical guidelines, the complexity of continuous testing, and more. Innovative solutions and best practices, informed by real-world applications like Tesla’s, are instrumental in navigating these challenges successfully.\n\nThe integration of “Data Engines” within the AI CI/CD process marks a critical advancement in how we develop, deploy, and trust AI. By combining continuous data collection, preprocessing, and training with rigorous testing methodologies, Data Engines represent a robust, adaptive approach. For the Navy and the Trusted AI Frameworks Project, it signifies a forward-thinking approach that recognizes the dynamism of modern AI while steadfastly upholding quality and ethical principles.\n\n\n\n1.4 Ethical Considerations in Testing: Beyond Functionality\nAs we endeavor to create AI systems that interact with complex environments and human lives, the ethical implications of their behavior cannot be ignored. While traditional CI/CD GitOps environments are tailored to ensure functionality, quality, and performance, the nature of AI — particularly “Software 2.0” — necessitates a broader and more profound testing approach. This extends into the ethical realm, considering how the AI system behaves in various scenarios and aligns with societal values.\n\n1.4.1 Integrating Ethical Behavior Tests in AI CI/CD GitOps Environments\n\nAdapting Traditional Environments: Conventional CI/CD GitOps practices were not initially designed to handle the ethical complexities of AI systems. Integration of ethical behavior tests within these environments requires thoughtful adaptation and innovation to ensure that AI models align with ethical standards alongside technical requirements.\nEthical “Behavior Tests”: These are specialized tests designed to evaluate AI models in various scenarios, considering ethical principles like fairness, accountability, transparency, and safety. They are critical in building trust and ensuring that AI systems function not only effectively but ethically.\nChallenges with the “Data Engine” Concept: The real-time and continuous nature of Data Engines presents unique ethical challenges. How data is sourced, processed, and utilized within the engine has implications for privacy, bias, quality, and more. Ethical behavior tests must extend into this realm, evaluating the entire pipeline, including the Data Engine’s operations.\n\n\n\n1.4.2 Real-World Implications and the Navy’s Perspective\n\nImportance for the Navy and Marine Corps: For organizations like the Navy and Marine Corps, where AI systems may be deployed in life-critical and high-stakes environments, these ethical considerations are paramount. Ethical behavior tests must be part of the standard AI testing pipeline to ensure that AI deployments are not just functional but morally sound.\nCollaboration with Interdisciplinary Teams: Developing and implementing ethical behavior tests necessitates collaboration with ethicists, social scientists, legal experts, and other stakeholders. It’s a complex task that extends beyond technical engineering, involving a deeper understanding of human values and societal implications.\nBuilding a Comprehensive Ethical Framework: Alongside technical robustness, AI systems must be examined and validated for ethical alignment. This includes developing a comprehensive ethical framework within the CI/CD GitOps environment, guiding the design, development, and deployment of AI, keeping ethical considerations at the forefront.\n\n\n\n1.4.3 Conclusion: Building a Foundation of Trust and Responsibility in AI Development\nThe journey from “Software 1.0” to “Software 2.0” is more than a technological leap; it represents a shift in understanding and responsibility. As AI models grow more complex and intertwined with real-world applications, the demands on software engineering practices also evolve. The traditional foundations of trust and quality assurance in software development have had to adapt to new challenges posed by AI.\nIn this section, we’ve explored how concepts like GitOps and CI/CD practices must be reimagined to align with the unique characteristics of AI engineering. We delved into the creation of Data Engines, recognizing their potential in handling complex environments and real-world data but also acknowledging the ethical considerations they introduce.\nWe recognized that the ethical imperatives in AI go beyond mere functionality, requiring integrated ethical behavior tests, interdisciplinary collaboration, and a comprehensive ethical framework. This is especially pertinent for organizations like the Navy and Marine Corps, where the implications of AI behavior have profound and immediate impacts.\nThe synthesis of these concepts paints a picture of a rapidly changing landscape, one where the lines between traditional software engineering and AI development are blurring. It’s a landscape filled with opportunities, innovations, and new horizons, but also one that demands caution, foresight, and a steadfast commitment to ethical principles.\nThis foundation sets the stage for our subsequent exploration, where we’ll continue to dive into the intricacies of trusted AI, from data-centric methodologies to hardened containers and workforce development. As we journey through this complex terrain, the underlying theme of trust and ethical alignment remains our guiding star, illuminating the path toward responsible and successful AI deployment."
  },
  {
    "objectID": "posts/frameworks-reflection/index.html#managing-and-utilizing-data",
    "href": "posts/frameworks-reflection/index.html#managing-and-utilizing-data",
    "title": "Reflections on Trusted AI Frameworks after two years",
    "section": "2 Managing and Utilizing Data",
    "text": "2 Managing and Utilizing Data\n\n2.1 Data Centric AI for Trusted AI\nIn traditional AI development, much attention is often given to fine-tuning model architectures, experimenting with different layers, activation functions, and optimization algorithms. While this approach has driven many innovations, it may sometimes overlook the central role of data in AI success.\nA paradigm shift is emerging, championed by AI leaders like Andrew Ng through the Data Centric AI movement. This movement emphasizes the need to invest more in the quality and context of the data rather than continually fine-tuning the model architecture. The MIT Introduction to Data-Centric AI course provides a very good introduction to Data Centric AI methodology that the Frameworks aim to enable.\nThe logic behind this shift is profound yet straightforward. Models, irrespective of their complexity, are only as good as the data they learn from. By prioritizing data quality, encompassing aspects such as cleanliness, relevance, diversity, and contextual richness, AI systems can achieve better performance with potentially simpler architectures.\nThis data-centric approach aligns well with the requirements of organizations like the Navy and Marine Corps. In complex environments where variability and uncertainty are common, the depth and quality of data can make a significant difference. A well-annotated dataset that captures the intricacies of real-world scenarios allows AI models to learn more effectively and generalize better to unseen situations.\nFor the Trusted AI (TAI) Frameworks Project, a data-centric philosophy serves as an essential cornerstone, recognizing that robust data management practices can lead to more reliable, interpretable, and trusted AI systems. This perspective does not diminish the value of innovative modeling but places it in the context of a balanced and well-considered AI development strategy, where data and model work in harmony.\nThe data-centric approach is not just a technical reorientation; it’s a recalibration of AI development’s very essence, placing data at the heart of the innovation process. The implications for trusted AI are profound, offering a path to AI systems that are not only highly capable but also aligned with the nuanced requirements and ethical considerations that define the evolving landscape of AI in military and civil applications.\n\n\n\n\n\n\nFigure 4: Trusted AI Needs Trusted Data as pointed out by XKCD: “Flawed Data”\n\n\n\n\n\n2.2 DoD Data Strategy: Aligning with National Defense Goal\nThe Department of Defense’s (DoD) Data Strategy emphasizes the critical role that data plays in achieving the goals of the National Defense Strategy:\n\n\n\n\n\n\n(“DoD Data Strategy: Unleashing Data to Advance the National Defense Strategy” 2020)\n\n\n\n\nMake Data Visible – Consumers can locate the needed data.\nMake Data Accessible – Consumers can retrieve the data.\nMake Data Understandable – Consumers can recognize the content, context, and applicability.\nMake Data Linked – Consumers can exploit data elements through innate relationships.\nMake Data Trustworthy – Consumers can be confident in all aspects of data for decision-making.\nMake Data Interoperable – Consumers have a common representation comprehension of data.\nMake Data Secure – Consumers know that data is protected from unauthorized use/manipulation.\n\n\n\nThe TAI Frameworks Project highlights its commitment to a data-centric approach to trusted AI. Each goal resonates with our overarching mission:\n\nVisible: Ensuring that data is discoverable by those who need it fosters transparency and helps build a foundation of trust in AI systems.\nAccessible: Making data readily available to authorized users enhances the efficiency and effectiveness of AI, providing the right information at the right time.\nUnderstandable: Clear documentation and metadata contribute to the explainability of AI, a core dimension of trust.\nLinked: Connecting related data sets facilitates more coherent AI analysis, ensuring robustness and reliability in decision-making.\nTrustworthy: Maintaining the integrity and quality of data ensures that AI systems are dependable, echoing the Trustworthy dimension in our trust framework.\nInteroperable: Enabling data to be used across different systems and platforms fosters collaboration and integration, key aspects of our community engagement efforts.\nSecure: Implementing strong data security measures safeguards privacy and aligns with the ethical considerations central to trusted AI.\n\nThis alignment with the DoD’s data goals underscores the importance of a data-centric approach in our work. By recognizing data as a strategic asset and prioritizing these seven goals, we are nurturing an environment where trusted AI can flourish, complementing the “Data-Centric AI for Trusted AI” section that follows.\n\n\n2.3 Selection of Data Version Control (DVC) for Tracking Data and Experiments\nManaging and tracking data and experiments is a critical task in the AI development lifecycle. Traditional version control systems are well-suited to handle code, but they often fall short when dealing with the unique requirements of large-scale data. In the context of AI, this limitation can hinder the collaboration and reproducibility that are vital to building trusted systems.\nData Version Control (DVC) emerges as a compelling solution to address these challenges, and its selection in the Trusted AI (TAI) Frameworks Project highlights its inherent advantages. Here’s an exploration of why DVC stands apart from other data management systems:\n\nIntegration with GitOps: DVC extends Git’s functionality to handle large data files without storing them in the Git repository. It uses pointers in the repository, keeping the actual data in a remote location. This approach aligns with GitOps practices, allowing developers to manage data with the same tools and workflows they use for code, promoting a more streamlined and unified process.\nOpen Source Nature: DVC is an open-source project, fostering a community-driven approach that aligns with the values of collaboration, transparency, and accessibility. This aspect encourages active participation from a wide range of contributors, leading to rapid innovations and responsive support.\nCompatibility with CI/CD and GitHub: DVC’s architecture is designed to work seamlessly within CI/CD pipelines, and its compatibility with GitHub Actions enables automated workflows that cover everything from data preprocessing to model training and evaluation. This integration ensures that data handling is not a separate silo but an integral part of the continuous integration, testing, and deployment processes.\nData Tracking and Experiment Versioning: Unlike traditional data management systems, DVC provides robust capabilities to track changes in data and experiments, much like how code is versioned. It enables the ability to revert to previous data states, compare different data versions, and align data changes with specific code revisions. This ensures that every step in the AI development process can be audited and replicated, contributing to greater trust and transparency.\nFacilitating Collaboration: DVC’s decentralized structure and remote storage options enable teams to share and access data without overwhelming the repository. This encourages collaboration, even in distributed environments, ensuring that everyone can work on the same data version and maintain consistency across the development lifecycle.\nFlexible Storage Options: DVC offers flexibility in storing data, supporting various remote storage backends like S3, Azure Blob, Google Cloud Storage, among others. This flexibility aligns with different organizational needs and preferences, ensuring that data management is adaptable to various scenarios.\n\nThe selection of DVC in the TAI Frameworks Project represents a thoughtful alignment with the principles of trusted AI, GitOps, and open-source collaboration. By bridging the gap between traditional software engineering practices and the unique demands of AI data management, DVC supports the creation of AI systems that are not only performant but also transparent, replicable, and ethical.\n\n\n2.4 Ethical Considerations and Trust in Data Management: The Navy’s Mission and Guiding Principles\nIn alignment with the Navy’s strategic goals and the specific executive orders governing the Department of Defense (DoD), ethical considerations and trust in data management hold a central place in the Trusted AI Frameworks Project. By prioritizing metadata, adhering to the FAIR (Findable, Accessible, Interoperable, and Reusable) and CARE (Collective Benefit, Authority to Control, Responsibility, and Ethics) principles, the Navy reinforces its commitment to mission-critical values of transparency, integrity, and accountability. It should be noted that application of FAIR and CARE principles are separate from the notion of “Open Data” and doesn’t invalidate the use of proper access and authorization controls.\n\n2.4.1 Metadata and Its Role in Ethical Data Management\n\nTransparency for Mission Success: Metadata supports the Navy’s operational efficiency by providing clarity on data origins, context, and constraints, thereby enabling informed decision-making.\nCompliance with Executive Orders: Metadata ensures alignment with legal and regulatory requirements, such as the DOD AI Ethical Principles (Department of Defense 2020), which mandates specific data handling protocols within the DoD and specifically:\n\n\n\n\n\n\n\n(Department of Defense 2020)\n\n\n\n\nResponsible. DoD personnel will exercise appropriate levels of judgment and care, while remaining responsible for the development, deployment, and use of AI capabilities.\nEquitable. The Department will take deliberate steps to minimize unintended bias in AI capabilities.\nTraceable. The Department’s AI capabilities will be developed and deployed such that relevant personnel possess an appropriate understanding of the technology, development processes, and operational methods applicable to AI capabilities, including with transparent and auditable methodologies, data sources, and design procedure and documentation.\nReliable. The Department’s AI capabilities will have explicit, well-defined uses, and the safety, security, and effectiveness of such capabilities will be subject to testing and assurance within those defined uses across their entire life-cycles.\nGovernable. The Department will design and engineer AI capabilities to fulfill their intended functions while possessing the ability to detect and avoid unintended consequences, and the ability to disengage or deactivate deployed systems that demonstrate unintended behavior.\n\n\n\n\n\n2.4.2 The FAIR Principles: Ensuring Naval Readiness\n\nFindable & Accessible: Easy discovery and retrieval of data accelerate the Navy’s response time and readiness.\nInteroperable & Reusable: Standards for data compatibility facilitate cross-departmental collaboration and resource optimization, reflecting the Navy’s emphasis on agility and resilience.\n\n\n\n\nTrusted AI Needs to use standards for interoperability as pointed out by XKCD: “Standards”\n\n\n\n\n2.4.3 CARE Principles: Upholding the Navy’s Ethical Values\n\nCollective Benefit: Data practices that align with community interests echo the Navy’s mission to serve and protect the nation.\nAuthority to Control & Responsibility: Respecting the rights of data providers and upholding stewardship responsibilities mirror the Navy’s core values of honor and commitment.\nEthics: Conducting data activities with integrity aligns with the Navy’s ethical framework and compliance with relevant executive orders, such as Executive Order YYYY on Ethical Considerations in the DoD.\n\n\n\n2.4.4 Conclusion: Setting a Standard for Naval Excellence\nThe Trusted AI Frameworks Project’s alignment with metadata, FAIR, and CARE principles reflects the Navy’s dedication to excellence, ethical leadership, and mission success. By embracing these principles, the Navy not only fosters trust and transparency within its ranks but also sets a precedent for responsible data handling that extends to its partnerships with other military branches, academia, and industry.\n\n\n\n2.5 Future Perspectives and Conclusion: The Data-Driven Path to Trusted AI in Year 3 and Beyond\nAs the Trusted AI Frameworks Project enters its third year, the focus on data-centric approaches continues to sharpen, reflecting the broader trend in AI development. In this complex and ever-evolving landscape, the partnership between Indiana University, University of Notre Dame, CRANE Naval Surface Warfare Center, and other collaborators is more crucial than ever. Here, we explore what lies ahead and conclude with insights that underline the strategic importance of data management for the Navy and Marine Corps.\n\n2.5.1 Future Perspectives: Data Management in Year 3 and Beyond\n\nContinued Emphasis on Data Quality: Leveraging the momentum of the data-centric AI movement, the next phase will focus on further refining data quality and context.\nAdoption of Emerging Technologies: Integration with cutting-edge tools and methodologies will enhance agility in data handling.\nStrengthened Collaboration with Open Source Communities: The project’s commitment to using and contributing to open-source tools will continue to foster innovation and collaboration.\n\n\n\n2.5.2 Navigating Ethical Considerations and Regulatory Compliance\n\nAlignment with Executive Orders: Ongoing alignment with legal and regulatory requirements will be paramount.\nEnhanced Ethical Oversight: A robust ethical framework that resonates with FAIR and CARE principles will guide the data management efforts.\n\n\n\n2.5.3 Implications for the Navy and Marine Corps\n\nStrategic Agility: Improved data management facilitates faster and more informed decision-making, crucial for naval readiness.\nEthical Leadership: Upholding the highest standards of integrity aligns with the Navy’s core values and enhances trust.\n\n\n\n2.5.4 Conclusion: A Unified Path Forward\nThe data-driven journey of the Trusted AI Frameworks Project illuminates the vital role of data in enhancing the trustworthiness and success of AI deployment within the Navy and Marine Corps. With a vision rooted in collaboration, ethical excellence, and technological innovation, the path forward promises to be an exciting and transformative adventure. Together, academia, industry, and the military will continue to forge a data-centric future that not only serves the needs of the present but anticipates the challenges and opportunities of tomorrow."
  },
  {
    "objectID": "posts/frameworks-reflection/index.html#deployment-and-provisioning",
    "href": "posts/frameworks-reflection/index.html#deployment-and-provisioning",
    "title": "Reflections on Trusted AI Frameworks after two years",
    "section": "3 Deployment and Provisioning",
    "text": "3 Deployment and Provisioning\n\n3.1 Introduction: The Challenge of Reproducibility and Integration\nTrusted AI involves complex and interdependent components that often originate from disparate academic and open-source projects. This complexity presents unique challenges in ensuring reproducibility and seamless integration of both “software 1.0” and “software 2.0.” The need for a robust framework that addresses these challenges has never been more pertinent. The project’s emphasis on deployment and provisioning aims to build a bridge between the theoretical foundations of AI and the practicalities of its application within a secure and trustworthy framework.\nCertainly! Here’s a revised version of the “DevOps and Computational Environments” section that provides more context and explanations for those who may not be familiar with these technologies:\n\n\n3.2 DevOps and Computational Environments: Bridging Development and Operations\nThe journey of Trusted AI doesn’t end with the creation of intelligent algorithms but extends into the realms of deployment and operational environments. This nexus between development and operations is known as DevOps, a practice that enhances efficiency, reliability, and maintainability. In the context of Trusted AI, several technologies and practices have been leveraged, each serving a specific role:\n\nPython PDM: As Python is one of the most prevalent languages for AI development, tools like Python’s Package Dependency Management (PDM) are essential. PDM helps manage dependencies and package versions, ensuring consistent environments across development, testing, and deployment stages.\nConda/Mamba: These are package managers specifically designed for scientific computing and data science, including AI. They allow for the creation of isolated environments, simplifying the process of managing complex dependencies.\nNix Containers: Nix takes reproducibility to the next level. Unlike conventional package managers, Nix ensures that the exact versions of all dependencies are explicitly defined, creating a consistent and reproducible environment across different stages and machines. This is crucial for both “software 1.0” and “software 2.0,” where inconsistencies in environments can lead to unpredictable behaviors.\nTemplates and Devcontainers: By using templates and development containers (devcontainers), the project has streamlined the setup process, making it easier for developers to replicate environments. This ensures that what works on one developer’s machine will work on another’s, alleviating the infamous “it works on my machine” problem.\n\nThese tools and practices collectively create a seamless and reliable process of moving AI models and applications from development to production. They recognize the complexity of AI development and provide solutions tailored to handle these challenges. The selection of these specific technologies within the Trusted AI project is a strategic alignment with the unique needs of AI, reflecting an understanding of the underlying challenges and opportunities that AI presents.\nBy connecting these dots and creating an ecosystem where development and operations converge, DevOps in the Trusted AI context represents a key pillar in the project’s strategy. It enables not just the creation but also the deployment and maintenance of AI solutions that can be trusted, validated, and reproduced, meeting the stringent standards required by the Navy and other critical stakeholders.\n\n\n\nTrusted AI Python Environment Reproducibility by XKCD: “Python Environment”\n\n\n\n\n3.3 Software Bill of Materials (SBoM): A Comprehensive Inventory for Trust\nIn any sophisticated piece of technology, understanding the components that make up the system is essential for security, quality, and compliance. The Software Bill of Materials (SBoM) serves this very purpose, offering a comprehensive inventory of all software components in a system, akin to a parts list in physical manufacturing.\nThe SBoM is especially critical in the context of Trusted AI for the Navy, aligning with Federal Government requirements and standards for procurement. Here’s a breakdown of the key elements and why they matter:\n\nWhat is an SBoM?: An SBoM details the components, libraries, and modules within a software product. It includes the exact versions, sources, licenses, and dependencies, offering a transparent and verifiable snapshot of the software’s composition.\nSPDX (Software Package Data Exchange): Developed by the Linux Foundation, SPDX provides a standardized format for sharing SBoM data across different tools and systems. It enables consistency and interoperability, supporting transparency and trust in software procurement and deployment.\nJSON-LD Vocabulary: SPDX’s vocabulary released as JSON-LD (JSON Linked Data) provides a machine-readable format that facilitates the automatic processing of SBoM data. It streamlines integration with existing systems and tools, fostering collaboration and automation in AI deployment.\nRelevance to the Navy and Federal Requirements: Compliance with SBoM requirements is essential for the Department of Defense (DoD) and other federal agencies. It aligns with executive orders and guidelines governing software procurement, security, and transparency, making it a crucial component of the Trusted AI project’s success.\n\n\n3.3.1 Extension and Evaluation of SBoM Construction Tools\nIn the Trusted AI Frameworks Project, the integration of outputs from other Trusted AI Projects into a cohesive whole is a key focus. An illustrative example of this integration came during the summer of 2023, when the project extended the foundational work of “Leveraging Labels and SBOMs to Build Trustworthy AI” by Peter J. Caven, Shakthidhar Gopavaram, and PI L. Jean Camp at Indiana University.\nThe team evaluated SBoM construction tools for completeness, specifically focusing on the knowledge graph representation of the SPDX generated by each tool relative to the The Minimum Elements For a Software Bill of Materials (SBOM) (Telecommunications and Administration 2021). A significant highlight of this work was the incorporation of SPDX Version 3.0, which expands its capabilities to include specifications for an AI Profile. This version recognizes the unique attributes of AI and machine learning models, accommodating their complex dependencies and configurations.\nThis extension not only reinforced the commitment to transparent and responsible software development but also exemplified how individual research efforts within the Trusted AI umbrella can be synthesized into the broader Framework. It also underscores the project’s proactive approach in leveraging the latest standards, such as SPDX 3.0, to ensure that the AI models and applications meet the ever-evolving requirements of the field.\n\n\n\n3.4 Hardened Containers, Military CI/CD through IronBank, Cloud One, and Platform One\nThe evolving technological landscape has necessitated a robust infrastructure for deploying software. Within the military context, especially in the Navy, trust, security, and efficiency are paramount. IronBank, Cloud One, and Platform One are initiatives that provide trusted access to cloud services and deployments (e.g., AWS, Azure) and create a streamlined pathway for the adoption of AI and other advanced technologies.\n\n3.4.1 Introduction to IronBank, Cloud One, and Platform One\n\nIronBank: A digital repository that offers containerized software accredited to run in Department of Defense (DoD) environments.\nCloud One: A set of cloud services designed to enable rapid and secure development within the DoD.\nPlatform One: A DoD-wide initiative that provides containerized software solutions, incorporating DevSecOps principles for continuous integration and deployment.\n\nThese platforms reduce the barriers to entry, ensuring a standardized approach to software development and deployment, all while aligning with military guidelines and requirements.\n\n\n3.4.2 AI-Centric Workflows and Challenges:\nIntegrating AI within these platforms presents unique challenges that diverge from traditional software deployments: - Data Management: AI’s unique data needs must be met through robust strategies, accommodating real-time feeds and scalable workflows. - Hardware Needs: AI applications often necessitate specialized hardware such as GPUs and accelerators, requiring containerization techniques that are hardware-agnostic. - Device Driver Complexity: Managing device drivers within Hardened Containers can be particularly intricate, leading to potential security vulnerabilities if misconfigured.\n\n\n3.4.3 Solutions and Alignment with Military Objectives:\nTo tackle these challenges, the combined ecosystem must: - Enhance data management to align with AI’s distinct requirements. - Adopt standardized device driver management and containerization strategies. - Ensure complete compliance with the Linux Foundation’s SPDX standards and federal procurement needs.\nBy integrating AI-centric workflows and aligning with essential hardware and security needs, IronBank, Cloud One, and Platform One offer a strong foundation for the military’s future AI adoption.\nIn the ever-changing technological landscape, the military’s approach to deployment and provisioning must evolve. The alignment of IronBank, Cloud One, and Platform One with AI’s unique workflows, specialized hardware, and secure device driver management sets a robust foundation for future innovation. These platforms not only align with the Navy’s mission but also pave the way for broader AI integration within the military domain, enhancing both trust and functionality.\n\n\n3.4.4 Conclusion: Building Trust through Secure Deployment\nThe deployment and provisioning of AI within the military environment are complex tasks laden with unique challenges. The emergence of hardened containers and specific initiatives like IronBank, Cloud One, and Platform One provides a pathway to integrating AI into the military domain. However, it’s the standardization through tools like Python PDM, Conda/Mamba, and Nix Container that builds a foundation of trust and robustness.\nBy embracing standardized tools, aligning them with military needs, and integrating them with existing trusted platforms, the Navy is poised to leverage the full potential of AI. The overarching strategy must be one of collaboration, security, and forward-thinking innovation, ensuring that the deployment of AI aligns with the broader goals of efficiency, transparency, and trust within the Navy’s mission.\nThe road ahead is promising, with these strategic initiatives paving the way for AI’s broader integration into the military domain. The combination of standardization, compliance, and alignment with military needs ensures a path toward Trusted AI that is both innovative and grounded in secure principles."
  },
  {
    "objectID": "posts/frameworks-reflection/index.html#development-practices-and-methodologies",
    "href": "posts/frameworks-reflection/index.html#development-practices-and-methodologies",
    "title": "Reflections on Trusted AI Frameworks after two years",
    "section": "4 Development Practices and Methodologies",
    "text": "4 Development Practices and Methodologies\n\n4.1 Introduction: The Modern Development Landscape\nThe field of software development has seen a series of paradigm shifts, each reflecting the evolving demands of technology and society. From the traditional waterfall model to the agile development framework, the focus has continuously shifted towards more iterative, responsive, and collaborative practices. Within this changing landscape, the concept of “Literate Programming”  was introduced by Donald Knuth in the 1980s, emphasizing the importance of explaining code in a human-readable narrative. Knuth’s vision foresaw a future where programming is not just a mechanical process but a craft interwoven with storytelling and documentation.\nWith the rise of AI, this vision has been pushed further, enabling a new era of collaboration between human programmers and AI “Co-Pilots.” AI-driven assistance in software development is becoming a reality, allowing for more effective and efficient code writing, debugging, and optimization. Literate programming can play a vital role in this context, as it emphasizes clarity, explanation, and a structured narrative that both human developers and AI models can interpret and build upon.\nIn the realm of AI development, tools like Jupyter Notebooks foster a dynamic environment that bridges the gap between exploration and production, aligning closely with literate programming concepts. AI Co-Pilots can leverage this environment, utilizing the human-friendly documentation to better understand developer intent and provide more relevant assistance.\nThe integration of Language Model based generative models, like large language models, opens up new horizons for collaborative and adaptive software development. These models can navigate the intricate landscape of literate programming, making sense of both code and context, enhancing their ability to assist humans in complex software development tasks.\nAgile principles resonate strongly in this context, mirroring the exploratory nature of AI development. Just as agile methodologies prioritize adaptability and collaboration, modern AI practices encourage experimentation, quick iterations, and a seamless transition from exploration to deployment. The subsequent sections delve into specific practices and tools that exemplify this convergence of agility, literacy, and exploratory programming, demonstrating their relevance and potential within the framework of Trusted AI.\n\n\n\n4.2 Quarto: Bridging the Gap Between Literacy and Code\n\n4.2.1 Introduction to Quarto\nQuarto is a pioneering solution in the field of literate programming that seamlessly integrates human-readable text with executable code. It builds on the vision of “Literate Programming” put forth by Donald Knuth, which emphasizes the importance of making source code as understandable as ordinary written prose.\n\n\n4.2.2 Key Features of Quarto\n\nHuman-Readable Documentation: Quarto allows developers to intertwine code with descriptive narratives, diagrams, and mathematical notation. This approach fosters comprehension, collaboration, and maintainability, making it particularly well-suited for complex AI projects.\nInteroperability with Jupyter Notebooks: By supporting Jupyter Notebook integration, Quarto enables an exploratory programming environment. Researchers and engineers can craft, test, and iterate on code in an interactive and visual manner.\nFlexible Output Formats: Quarto documents can be rendered into various formats such as HTML, PDF, and Word, catering to diverse presentation and distribution needs.\nReproducibility: Code chunks and outputs within Quarto documents are readily reproducible. This aids in verification and validation, essential qualities in Trusted AI.\n\n\n\n4.2.3 Quarto in the Context of AI Development\nIn the rapidly evolving landscape of AI, where complexity can easily spiral out of control, Quarto provides a structured and transparent way to document and develop models. The following aspects make it a particularly fitting choice:\n\nTransparency: Literate programming through Quarto ensures that the code’s logic and decision-making are clearly articulated, fostering trust in the AI system.\nCollaboration: By bridging the gap between code and prose, Quarto facilitates collaboration among multidisciplinary teams, including data scientists, engineers, domain experts, and stakeholders.\nCompliance: In contexts like the Navy, where regulatory compliance and ethical considerations are paramount, Quarto’s approach to documentation can aid in meeting these requirements.\n\n\n\n4.2.4 Conclusion\nQuarto represents a leap forward in aligning software development practices with human cognition and communication. Its ability to bridge literacy and code makes it an indispensable tool in the era of “Software 2.0.” By fostering clear understanding, collaboration, and reproducibility, Quarto contributes to the overarching goal of building Trusted AI systems, aligning perfectly with the needs and values of modern AI development, including military applications.\n\n\n\n4.3 nbdev: Extending Literacy with Quarto Integration\n\n4.3.1 Introduction to nbdev\nnbdev is an open-source development environment that builds upon Jupyter Notebooks and extends the principles of literate programming. It particularly leverages the Quarto framework to create a seamless and productive development experience. By combining code, prose, and visualizations into a single environment, nbdev enables a more transparent and collaborative approach to software development.\n\n\n4.3.2 Key Features of nbdev\n\nQuarto Integration: By incorporating Quarto, nbdev fosters a rich literate programming environment where code is documented and explained in human-readable form.\nInteractive Development: Developers can write code, run experiments, and analyze results all within the same Jupyter Notebook, promoting a more exploratory and iterative process.\nAutomated Code Export: Code written in nbdev’s notebooks can be automatically converted to traditional script files, facilitating integration with existing codebases and deployment pipelines.\nTesting Integration: nbdev supports continuous integration and testing within the notebook environment, aligning with modern software quality assurance practices.\nCollaboration Tools: With built-in support for Git and GitHub, nbdev streamlines collaboration and version control, bridging the gap between data scientists, developers, and other stakeholders.\n\n\n\n4.3.3 nbdev in the Context of AI Development\nThe flexibility and transparency offered by nbdev are especially significant in AI development. Here’s how:\n\nComplex Model Documentation: AI models are inherently complex and require detailed explanation. Nbdev allows for the clear documentation of both algorithms and the reasoning behind design choices.\nRapid Prototyping: The interactive nature of nbdev enables quicker experimentation and refinement of models, a crucial aspect of AI development.\nReproducibility: By enforcing a structured approach, nbdev ensures that models are more reproducible, enhancing trust and reliability.\nAlignment with Software 2.0 Principles: The nbdev framework aligns well with the “Software 2.0” paradigm, where learned behaviors and model training are central. It supports the rapid evolution and integration needed in the AI landscape.\n\nnbdev, with its integration of Quarto, provides a cohesive and advanced environment for literate programming. Its synergy with the principles of modern AI development makes it an essential tool for achieving transparency, collaboration, and efficiency. In contexts like the military, where understanding, trust, and compliance are key, nbdev offers a pathway to create more accessible and trustworthy AI systems.\n\n\n\n4.4 Fast.ai: A Layered Approach to AI Development\n\n4.4.1 Introduction to Fast.ai\nFast.ai is an open-source deep learning library that simplifies the process of building and training deep learning models. Its core philosophy is to offer a layered approach, providing APIs at different levels of abstraction. This flexibility empowers developers, data scientists, and researchers to engage with AI across various complexities, from high-level applications to low-level customization.\n\n\n4.4.2 Fast.ai’s Layered Approach\n\nApplications Layer: This layer offers pre-built solutions for common tasks like image classification, natural language processing, tabular data analysis, and collaborative filtering. It is designed for ease of use, allowing non-specialists to build and deploy models with minimal code.\nHigh-Level API: For those who need more control and customization, the high-level API provides an intuitive interface to design and experiment with more complex models. It strikes a balance between simplicity and power, suitable for intermediate-level developers.\nMid-Level API: The mid-level API introduces more granular control and allows for the creation of custom models and data pipelines. It’s designed for advanced users who wish to dive deeper into the underlying mechanics of their models.\nLow-Level API: At the lowest layer, developers have direct access to underlying PyTorch constructs, facilitating experimentation and the development of entirely novel architectures. This layer is aimed at research scientists and cutting-edge practitioners.\n\n\n\n4.4.3 Literate Programming and nbdev Integration\nFast.ai not only encourages a more accessible approach to AI but also promotes literate programming principles. The library itself was developed using nbdev, thereby enhancing its transparency, documentation, and collaboration.\n\nTransparent Development: Literate programming within nbdev enables Fast.ai’s code, design rationale, and experiments to be clearly documented and shared.\nInteroperability: Fast.ai’s integration with nbdev ensures smooth collaboration between different stakeholders in the AI development process, including data scientists, engineers, and domain experts.\nRapid Prototyping and Experimentation: Leveraging the exploratory nature of nbdev, Fast.ai facilitates iterative experimentation and refinement, vital for AI research and development.\n\n\n\n4.4.4 Relevance to the Navy and Broader Defense Community\nFast.ai’s layered approach is particularly relevant to the Navy and other defense institutions. Here’s why:\n\nScalability: Fast.ai’s structure allows for quick prototyping and scaling, accommodating both straightforward applications and sophisticated custom solutions.\nEducation and Workforce Development: The approachability of Fast.ai makes it an excellent tool for education and training, aligning with initiatives like Scalable Asymmetric Lifecycle Engagement (SCALE) managed by Purdue University.\nTrust and Compliance: The transparency and reproducibility afforded by Fast.ai, especially in combination with nbdev, align well with the principles of Trusted AI, a critical consideration for military applications.\n\nFast.ai represents a significant advancement in making AI accessible, understandable, and manageable. Its layered approach, combined with literate programming principles, contributes to a more transparent and collaborative development process. In the context of defense and national security, Fast.ai offers a pathway to harness the power of AI effectively, ethically, and responsively.\n\n\n\n4.5 Conclusion: The Evolution of Development Practices in Trusted AI\nThe landscape of software development, particularly in the realm of AI, is undergoing a radical transformation. As we have explored in this section, the integration of literate programming, layered APIs, and open-source tools like Quarto, nbdev, and Fast.ai represent a shift towards more transparent, collaborative, and efficient development practices. These shifts are not just technological but cultural, redefining how developers, data scientists, engineers, and domain experts collaborate to create intelligent systems.\n\n4.5.1 The Role of AI Co-Pilots\nA promising frontier in this evolution is the integration of AI itself into the development and deployment process. AI Co-Pilots, or intelligent assistants, are emerging as key players in this new paradigm.\n\nSecurity Oversight: AI Co-Pilots can continuously monitor code for potential security vulnerabilities, offering real-time insights and even automated fixes, aligning with Trusted AI principles.\nCI/CD Integration: By embedding intelligence into the Continuous Integration/Continuous Deployment pipeline, AI Co-Pilots can optimize testing, deployment, and scaling, adapting to the unique demands of AI “Software 2.0.”\nCode Quality Control: AI-driven code review can ensure adherence to coding standards, improve code quality, and reduce human error, fostering more robust and maintainable systems.\nAdaptive Learning and Enhancement: Leveraging real-world data, AI Co-Pilots can learn and evolve, offering personalized assistance and driving continuous improvement in development practices.\n\n\n\n4.5.2 Relevance to the Navy and Defense Community\nThe Navy, and the defense community at large, stand to benefit profoundly from these advancements. The integration of AI Co-Pilots can enhance the security, efficiency, and agility of development processes, key attributes in an ever-changing and complex environment.\n\nMission Readiness: Faster, more robust development practices mean quicker deployment of critical AI systems, enhancing responsiveness and strategic capabilities.\nEthical Compliance: Automated oversight aligned with ethical guidelines ensures that AI systems adhere to the necessary standards, fostering trust and accountability.\nWorkforce Development: AI-driven tools offer opportunities for training and upskilling, aligning with initiatives like the Scalable Asymmetric Lifecycle Engagement (SCALE) managed by Purdue University, enhancing both semiconductor and AI workforce development.\n\n\n\n4.5.3 Looking Ahead\nThe integration of AI into development practices represents a significant step towards a future where intelligent systems are not just the products but active participants in the development lifecycle. This shift promises to enhance not only the efficiency and quality of development but also the ethical alignment and trustworthiness of AI systems.\nIn an era where complexity is the norm, and the stakes are high, these advancements offer a path towards a more resilient, responsive, and responsible approach to AI. The convergence of AI and human expertise is not just a technical evolution but a philosophical one, reflecting a deeper understanding of the interconnectedness of technology, ethics, and humanity.\n\n\n\n4.6 Broader Challenges and Opportunities\nThe quest for Trusted AI is not merely a technical challenge; it’s a complex endeavor that intersects with various domains, including ethics, community involvement, workforce development, interdisciplinary collaboration, and more. This section highlights some of these broader considerations, emphasizing the multifaceted nature of Trusted AI.\n\n4.6.1 Workforce Development\n\nSkills Gap: With the rapid advancement of AI technologies, there is a growing need for professionals with specialized skills. Addressing this gap requires tailored training and educational programs.\nInitiatives like SCALE: Managed by Purdue University and focused on semiconductor and AI workforce development, SCALE represents a model for public-private collaboration in nurturing talent.\nInclusion and Diversity: Building a workforce that reflects diverse perspectives is essential for developing AI systems that are equitable and unbiased.\n\n\n\n4.6.2 Ethical Considerations\n\nTransparency and Accountability: Ensuring that AI systems are transparent and accountable is fundamental to building trust.\nEthical Testing: Integrating ethical “behavior tests” within AI testing pipelines, as highlighted in CI/CD and GitOps environments, is vital to align AI with societal values.\nRegulatory Compliance: Adherence to executive orders, regulations, and guidelines governing DoD and Navy’s use of AI is crucial for legal and ethical operation.\n\n\n\n4.6.3 Community and Open Source Involvement\n\nCollaboration with Open Source Tools: Leveraging and contributing to open-source tools fosters a collaborative and innovative ecosystem.\nEngagement with the Broader Community: Collaborating with academia, industry, and other stakeholders can accelerate progress and ensure alignment with broader societal goals.\nPromoting Open Standards: Encouraging the use of open standards like Linux Foundation SPDX helps in creating a universal language and facilitating collaboration across different entities.\n\n\n\n4.6.4 Interdisciplinary Collaboration\n\nBridging Silos: Trusted AI requires the fusion of expertise from computer science, ethics, law, social sciences, and more. Encouraging interdisciplinary collaboration breaks down barriers and fosters holistic solutions.\nInnovation through Diversity of Thought: By integrating diverse perspectives, new pathways to innovation are uncovered, driving creativity and resilience in the development of AI systems.\n\n\n\n4.6.5 User Experience and Human-AI Interaction\n\nHuman-Centered Design: Emphasizing the end-user’s needs and expectations ensures that AI systems are user-friendly, accessible, and effective.\nEvolving Interaction Models: As Trusted AI projects mature, new paradigms of Human-AI Interaction (HAI) will emerge, necessitating ongoing research and adaptation.\n\n\n\n\n4.7 Conclusion: A Holistic Approach to Trusted AI\nTrusted AI is not a monolithic entity but a complex, dynamic field that intersects with various disciplines and societal considerations. By embracing these broader challenges and opportunities, we pave the way for AI systems that are not just intelligent but responsible, ethical, and aligned with human values and needs.\nThe integration of these various facets into the Trusted AI framework contributes to a comprehensive and sustainable approach, one that recognizes the interconnectedness of technology with the broader fabric of society. The journey towards Trusted AI is a collective endeavor, one that requires collaboration, empathy, foresight, and a deep commitment to ethical principles.\n\n\n\n\n\n\nUse of Generative AI in Writing and Editing\n\n\n\nChatGPT GPT-4 version Aug 3, 2023 was used in the structuring, writing and editing of this blog post."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "Reflections on Trusted AI Frameworks after two years\n\n\n\n\n\n\nTrusted AI\n\n\nAI Frameworks\n\n\nAI Engineering\n\n\n\n\n\n\n\n\n\nSep 15, 2023\n\n\nCharles Vardeman\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To AI Success Factors: Engineering Trust in Deployments\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nAug 15, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/agents_april24/index.html#agentic-workflow-architectural-patterns",
    "href": "slides/agents_april24/index.html#agentic-workflow-architectural-patterns",
    "title": "Agentic Workflow Design Patterns",
    "section": "“Agentic” Workflow Architectural Patterns",
    "text": "“Agentic” Workflow Architectural Patterns\n\nWhat’s next for AI agentic workflows ft. Andrew Ng of AI Fund"
  },
  {
    "objectID": "slides/agents_april24/index.html#agentic-patterns-multiagent-collaboration",
    "href": "slides/agents_april24/index.html#agentic-patterns-multiagent-collaboration",
    "title": "Agentic Workflow Design Patterns",
    "section": "Agentic Patterns – Multiagent Collaboration",
    "text": "Agentic Patterns – Multiagent Collaboration"
  },
  {
    "objectID": "slides/agents_april24/index.html#agentic-reasoning-design-patterns",
    "href": "slides/agents_april24/index.html#agentic-reasoning-design-patterns",
    "title": "Agentic Workflow Design Patterns",
    "section": "Agentic Reasoning Design Patterns",
    "text": "Agentic Reasoning Design Patterns"
  },
  {
    "objectID": "slides/agents_april24/index.html#agents-for-curation",
    "href": "slides/agents_april24/index.html#agents-for-curation",
    "title": "Agentic Workflow Design Patterns",
    "section": "Agents for “Curation”?",
    "text": "Agents for “Curation”?\n\nGoing Meta - Ep 27: Building a Reflection Agent with LangGraph"
  },
  {
    "objectID": "slides/agents_april24/index.html#agentically-built-semantic-models",
    "href": "slides/agents_april24/index.html#agentically-built-semantic-models",
    "title": "Agentic Workflow Design Patterns",
    "section": "Agentically Built Semantic Models",
    "text": "Agentically Built Semantic Models\n\n\n\nGoing Meta Episode 27 Repository"
  },
  {
    "objectID": "slides/spring24/index.html#when-last-we-spoke",
    "href": "slides/spring24/index.html#when-last-we-spoke",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "When last we spoke…",
    "text": "When last we spoke…\n\nMotivating Use Case"
  },
  {
    "objectID": "slides/spring24/index.html#ai-based-curation",
    "href": "slides/spring24/index.html#ai-based-curation",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "AI Based Curation",
    "text": "AI Based Curation\n\nKG Driven Architecture"
  },
  {
    "objectID": "slides/spring24/index.html#inspiration-from-tamms-agent-cognitive-architecture",
    "href": "slides/spring24/index.html#inspiration-from-tamms-agent-cognitive-architecture",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Inspiration from TAMMS Agent Cognitive Architecture",
    "text": "Inspiration from TAMMS Agent Cognitive Architecture\n\nTAMMS Agent Architecture"
  },
  {
    "objectID": "slides/spring24/index.html#society-of-sme-agents",
    "href": "slides/spring24/index.html#society-of-sme-agents",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "“Society of SME Agents”",
    "text": "“Society of SME Agents”\n\nSME Agent “Ecosystem”"
  },
  {
    "objectID": "slides/spring24/index.html#the-bad-news-the-world-has-cought-up-to-us",
    "href": "slides/spring24/index.html#the-bad-news-the-world-has-cought-up-to-us",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "The Bad News: The world has cought up to us…",
    "text": "The Bad News: The world has cought up to us…"
  },
  {
    "objectID": "slides/spring24/index.html#visual-agents-architecture-multi-agent-architecture-based-on-role",
    "href": "slides/spring24/index.html#visual-agents-architecture-multi-agent-architecture-based-on-role",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Visual Agents Architecture: Multi-Agent Architecture based on Role",
    "text": "Visual Agents Architecture: Multi-Agent Architecture based on Role\n\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.\nHu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv."
  },
  {
    "objectID": "slides/spring24/index.html#activity-specific-agents-visual-agents-transition-graph",
    "href": "slides/spring24/index.html#activity-specific-agents-visual-agents-transition-graph",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Activity Specific Agents: Visual Agents Transition Graph",
    "text": "Activity Specific Agents: Visual Agents Transition Graph\n\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.\nHu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv."
  },
  {
    "objectID": "slides/spring24/index.html#langchain-multi-agent-workflows",
    "href": "slides/spring24/index.html#langchain-multi-agent-workflows",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "LangChain Multi-Agent Workflows",
    "text": "LangChain Multi-Agent Workflows\n\nLangGraph: Multi-Agent Workflows"
  },
  {
    "objectID": "slides/spring24/index.html#multi-agent-example",
    "href": "slides/spring24/index.html#multi-agent-example",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Multi-Agent Example",
    "text": "Multi-Agent Example\n\nMulti-agent collaboration example"
  },
  {
    "objectID": "slides/spring24/index.html#curator-agents",
    "href": "slides/spring24/index.html#curator-agents",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Curator Agents",
    "text": "Curator Agents"
  },
  {
    "objectID": "slides/spring24/index.html#retrieval-augmented-generation-for-large-language-models-a-survey",
    "href": "slides/spring24/index.html#retrieval-augmented-generation-for-large-language-models-a-survey",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Retrieval-Augmented Generation for Large Language Models: A Survey",
    "text": "Retrieval-Augmented Generation for Large Language Models: A Survey\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2024. “Retrieval-Augmented Generation for Large Language Models: A Survey.” arXiv. https://doi.org/10.48550/arXiv.2312.10997."
  },
  {
    "objectID": "slides/spring24/index.html#retrieval-augmented-generation-the-idea",
    "href": "slides/spring24/index.html#retrieval-augmented-generation-the-idea",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Retrieval Augmented Generation – The Idea",
    "text": "Retrieval Augmented Generation – The Idea\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2024. “Retrieval-Augmented Generation for Large Language Models: A Survey.” arXiv. https://doi.org/10.48550/arXiv.2312.10997."
  },
  {
    "objectID": "slides/spring24/index.html#knowledge-engineering-dynamic-qa-systems",
    "href": "slides/spring24/index.html#knowledge-engineering-dynamic-qa-systems",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Knowledge Engineering Dynamic QA Systems",
    "text": "Knowledge Engineering Dynamic QA Systems\n\nJerry Liu, “Beyond Naive RAG: Adding Agentic Layers, AI User Conference, 2024"
  },
  {
    "objectID": "slides/spring24/index.html#naive-rag",
    "href": "slides/spring24/index.html#naive-rag",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Naive RAG",
    "text": "Naive RAG\n\nJerry Liu, “Beyond Naive RAG: Adding Agentic Layers, AI User Conference, 2024"
  },
  {
    "objectID": "slides/spring24/index.html#what-does-this-concept-look-like-in-llm-driven-architecture-for-qa-systems",
    "href": "slides/spring24/index.html#what-does-this-concept-look-like-in-llm-driven-architecture-for-qa-systems",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "What does this concept “look like” in LLM driven architecture for QA systems",
    "text": "What does this concept “look like” in LLM driven architecture for QA systems\n\nAgents based on LLM Cognitive Architecture\n\nCurator Agents – Curation Workflow\nSubject Matter Expert Agents\n\nKnowledge Graphs\nTools to Query KG\nSome form of Knowledge Engineering and Ontology"
  },
  {
    "objectID": "slides/spring24/index.html#how-does-this-fit-into-the-enterprise-data-architecture",
    "href": "slides/spring24/index.html#how-does-this-fit-into-the-enterprise-data-architecture",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "How does this “fit” into the Enterprise Data Architecture?",
    "text": "How does this “fit” into the Enterprise Data Architecture?\n\nGartner Data Architecture"
  },
  {
    "objectID": "slides/spring24/index.html#the-curator-agent-should-interact-with-the-data-catalog-kg",
    "href": "slides/spring24/index.html#the-curator-agent-should-interact-with-the-data-catalog-kg",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "The Curator Agent Should Interact with the Data Catalog KG",
    "text": "The Curator Agent Should Interact with the Data Catalog KG\n\nJuan Sequeda, “What Does It Mean for a Data Catalog to Be Powered by a Knowledge Graph?”,https://www.datanami.com/2022/09/30/what-does-it-mean-for-a-data-catalog-to-be-powered-by-a-knowledge-graph/"
  },
  {
    "objectID": "slides/spring24/index.html#data-catalogs-should-have-an-ontology",
    "href": "slides/spring24/index.html#data-catalogs-should-have-an-ontology",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Data Catalogs Should have an Ontology",
    "text": "Data Catalogs Should have an Ontology\n\nJuan Sequeda, “What Does It Mean for a Data Catalog to Be Powered by a Knowledge Graph?”,https://www.datanami.com/2022/09/30/what-does-it-mean-for-a-data-catalog-to-be-powered-by-a-knowledge-graph/"
  },
  {
    "objectID": "slides/spring24/index.html#example-ontology",
    "href": "slides/spring24/index.html#example-ontology",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Example Ontology",
    "text": "Example Ontology\n\nJuan Sequeda, “What Does It Mean for a Data Catalog to Be Powered by a Knowledge Graph?”,https://www.datanami.com/2022/09/30/what-does-it-mean-for-a-data-catalog-to-be-powered-by-a-knowledge-graph/"
  },
  {
    "objectID": "slides/spring24/index.html#the-curator-agent-should-follow-best-practices-for-constructing-ontologies",
    "href": "slides/spring24/index.html#the-curator-agent-should-follow-best-practices-for-constructing-ontologies",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "The Curator Agent should follow best practices for constructing ontologies",
    "text": "The Curator Agent should follow best practices for constructing ontologies\n\nShimizu, Cogan, Karl Hammar, and Pascal Hitzler. 2023. “Modular Ontology Modeling.” Edited by Sabrina Kirrane, Axel-Cyrille Ngonga Ngomo, Sabrina Kirrane, and Axel-Cyrille Ngonga Ngomo. Semantic Web 14 (3): 459–89. https://www.semantic-web-journal.net/system/files/swj2886.pdf."
  },
  {
    "objectID": "slides/spring24/index.html#extreme-design-methodology",
    "href": "slides/spring24/index.html#extreme-design-methodology",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Extreme Design Methodology",
    "text": "Extreme Design Methodology\n\nDe Berardinis, Jacopo, Valentina Anita Carriero, Nitisha Jain, Nicolas Lazzari, Albert Meroño-Peñuela, Andrea Poltronieri, and Valentina Presutti. 2023. “The Polifonia Ontology Network: Building a Semantic Backbone for Musical Heritage.” In The Semantic Web – ISWC 2023, edited by Terry R. Payne, Valentina Presutti, Guilin Qi, María Poveda-Villalón, Giorgos Stoilos, Laura Hollink, Zoi Kaoudi, Gong Cheng, and Juanzi Li, 14266:302–22. Lecture Notes in Computer Science. Cham: Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-47243-5_17."
  },
  {
    "objectID": "slides/spring24/index.html#llm-assisted-competency-question-design",
    "href": "slides/spring24/index.html#llm-assisted-competency-question-design",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "LLM Assisted Competency Question Design",
    "text": "LLM Assisted Competency Question Design\n\nIDEA: Infer, DEsign, creAte:https://github.com/polifonia-project/idea"
  },
  {
    "objectID": "slides/spring24/index.html#a-curator-agent-is-a-knowledge-engineer",
    "href": "slides/spring24/index.html#a-curator-agent-is-a-knowledge-engineer",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "A Curator Agent is a Knowledge Engineer…",
    "text": "A Curator Agent is a Knowledge Engineer…"
  },
  {
    "objectID": "slides/spring24/index.html#knowledge-engineering-using-large-language-models",
    "href": "slides/spring24/index.html#knowledge-engineering-using-large-language-models",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Knowledge Engineering Using Large Language Models",
    "text": "Knowledge Engineering Using Large Language Models\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/spring24/index.html#prompt-engineering-as-knowledge-engineering",
    "href": "slides/spring24/index.html#prompt-engineering-as-knowledge-engineering",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Prompt Engineering as Knowledge Engineering",
    "text": "Prompt Engineering as Knowledge Engineering\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/spring24/index.html#systematic-approaches-to-prompt-engineering",
    "href": "slides/spring24/index.html#systematic-approaches-to-prompt-engineering",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Systematic Approaches to Prompt Engineering",
    "text": "Systematic Approaches to Prompt Engineering\n LangChain Integration: https://python.langchain.com/docs/integrations/providers/dspy"
  },
  {
    "objectID": "slides/spring24/index.html#knowledge-engineering-practice",
    "href": "slides/spring24/index.html#knowledge-engineering-practice",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Knowledge Engineering Practice",
    "text": "Knowledge Engineering Practice\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/spring24/index.html#trusted-ai-llms-and-ke",
    "href": "slides/spring24/index.html#trusted-ai-llms-and-ke",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Trusted AI, LLMs and KE",
    "text": "Trusted AI, LLMs and KE\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/spring24/index.html#building-detailed-kgs-as-part-of-the-curator-agent-workflow",
    "href": "slides/spring24/index.html#building-detailed-kgs-as-part-of-the-curator-agent-workflow",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Building Detailed KGs as part of the Curator Agent Workflow",
    "text": "Building Detailed KGs as part of the Curator Agent Workflow\n\nPaco Nathan, “Language, Graphs, and AI in Industry”, https://youtu.be/ScIHpAhPccM?si=fzVTe4KKDCgybmAQ"
  },
  {
    "objectID": "slides/spring24/index.html#knowledge-graph-construction-and-the-curator-agent",
    "href": "slides/spring24/index.html#knowledge-graph-construction-and-the-curator-agent",
    "title": "Joint Human-LLM Curation: Crafting Understandable and Relevant AI-Powered Information",
    "section": "Knowledge Graph Construction and the Curator Agent",
    "text": "Knowledge Graph Construction and the Curator Agent\n\n\n\nPaco Nathan, “Language, Graphs, and AI in Industry”, https://derwen.ai/s/mqqm"
  },
  {
    "objectID": "slides/ai-curators/index.html#github-repo",
    "href": "slides/ai-curators/index.html#github-repo",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "GitHub Repo",
    "text": "GitHub Repo\n\nTrusted AI - Towards a Curator (TAITaC)"
  },
  {
    "objectID": "slides/ai-curators/index.html#dod-data-vision",
    "href": "slides/ai-curators/index.html#dod-data-vision",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "DoD Data Vision",
    "text": "DoD Data Vision\n\n\n\n\n\n\n\nNorquist, David L. n.d. “DOD Data Strategy.” https://media.defense.gov/2020/Oct/08/2002514180/-1/-1/0/DOD-DATA-STRATEGY.PDF."
  },
  {
    "objectID": "slides/ai-curators/index.html#ontology-design-patterns-as-a-semantic-bridge",
    "href": "slides/ai-curators/index.html#ontology-design-patterns-as-a-semantic-bridge",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Ontology Design Patterns as a Semantic Bridge",
    "text": "Ontology Design Patterns as a Semantic Bridge\n\n\n\n\nOntology Engineering: A View from the Trenches - WOP 2015 Keynote | PPT (slideshare.net)"
  },
  {
    "objectID": "slides/ai-curators/index.html#ai-agents-for-interoperability",
    "href": "slides/ai-curators/index.html#ai-agents-for-interoperability",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "AI Agents for Interoperability",
    "text": "AI Agents for Interoperability\n\n\n\n\n\n\n\nTangi, Luca, Marco Combetto, BOSCH Jaume Martin, and MÜLLER Paula Rodriguez. 2023. “Artificial Intelligence for Interoperability in the European Public Sector.” JRC Publications Repository. October 4, 2023. https://doi.org/10.2760/633646."
  },
  {
    "objectID": "slides/ai-curators/index.html#problem-can-we-use-llm-based-cognitive-agents-to-accelerate-and-create-active-metadata",
    "href": "slides/ai-curators/index.html#problem-can-we-use-llm-based-cognitive-agents-to-accelerate-and-create-active-metadata",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Problem – Can we use LLM Based Cognitive Agents to accelerate and create “Active Metadata”?",
    "text": "Problem – Can we use LLM Based Cognitive Agents to accelerate and create “Active Metadata”?"
  },
  {
    "objectID": "slides/ai-curators/index.html#problem-how-can-llm-based-cognitive-agents-use-data-centric-ai-to-be-more-factual-through-retrieval-augmented-generation-rag-and-tool-use",
    "href": "slides/ai-curators/index.html#problem-how-can-llm-based-cognitive-agents-use-data-centric-ai-to-be-more-factual-through-retrieval-augmented-generation-rag-and-tool-use",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Problem – How can LLM Based Cognitive Agents use Data Centric AI to be more FACTUAL through Retrieval Augmented Generation (RAG) and Tool Use?",
    "text": "Problem – How can LLM Based Cognitive Agents use Data Centric AI to be more FACTUAL through Retrieval Augmented Generation (RAG) and Tool Use?"
  },
  {
    "objectID": "slides/ai-curators/index.html#problem-data-centric-ai-is-hard-but-necessary-for-trusted-ai-can-we-use-llm-based-cognitive-agents-to-lower-the-barrier-to-data-centric-ai",
    "href": "slides/ai-curators/index.html#problem-data-centric-ai-is-hard-but-necessary-for-trusted-ai-can-we-use-llm-based-cognitive-agents-to-lower-the-barrier-to-data-centric-ai",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Problem – Data Centric AI is Hard but necessary for Trusted AI – Can we use LLM Based Cognitive Agents to lower the barrier to Data Centric AI?",
    "text": "Problem – Data Centric AI is Hard but necessary for Trusted AI – Can we use LLM Based Cognitive Agents to lower the barrier to Data Centric AI?"
  },
  {
    "objectID": "slides/ai-curators/index.html#problem-how-can-we-trust-validate-and-integrate-human-in-the-loop-for-llm-based-agents-used-for-data-curation",
    "href": "slides/ai-curators/index.html#problem-how-can-we-trust-validate-and-integrate-human-in-the-loop-for-llm-based-agents-used-for-data-curation",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Problem – How can we Trust, Validate, and integrate Human in the loop for LLM Based Agents used for Data Curation?",
    "text": "Problem – How can we Trust, Validate, and integrate Human in the loop for LLM Based Agents used for Data Curation?"
  },
  {
    "objectID": "slides/ai-curators/index.html#motivation-tamms-kg",
    "href": "slides/ai-curators/index.html#motivation-tamms-kg",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Motivation: TAMMS KG",
    "text": "Motivation: TAMMS KG"
  },
  {
    "objectID": "slides/ai-curators/index.html#starting-architecture",
    "href": "slides/ai-curators/index.html#starting-architecture",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Starting Architecture…",
    "text": "Starting Architecture…"
  },
  {
    "objectID": "slides/ai-curators/index.html#ai-curator-agents-team-lemon",
    "href": "slides/ai-curators/index.html#ai-curator-agents-team-lemon",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "AI Curator “Agents”: Team “LEMON”",
    "text": "AI Curator “Agents”: Team “LEMON”"
  },
  {
    "objectID": "slides/ai-curators/index.html#framework-for-architecture-design-of-llm-based-agents",
    "href": "slides/ai-curators/index.html#framework-for-architecture-design-of-llm-based-agents",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Framework for architecture design of LLM Based Agents",
    "text": "Framework for architecture design of LLM Based Agents\n\n\n\nWang, Lei, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, et al. 2023. “A Survey on Large Language Model Based Autonomous Agents.” arXiv. http://arxiv.org/abs/2308.11432."
  },
  {
    "objectID": "slides/ai-curators/index.html#cognitive-architectures-for-language-agents",
    "href": "slides/ai-curators/index.html#cognitive-architectures-for-language-agents",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Cognitive Architectures for Language Agents",
    "text": "Cognitive Architectures for Language Agents\n\n\n\n\nSumers, Theodore R., Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths. 2023. “Cognitive Architectures for Language Agents.” arXiv. http://arxiv.org/abs/2309.02427."
  },
  {
    "objectID": "slides/ai-curators/index.html#llm-powered-agents",
    "href": "slides/ai-curators/index.html#llm-powered-agents",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "LLM Powered Agents",
    "text": "LLM Powered Agents\n\n\n\n\nLLM Powered Agents"
  },
  {
    "objectID": "slides/ai-curators/index.html#example",
    "href": "slides/ai-curators/index.html#example",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "slides/ai-curators/index.html#activity-specific-agents-visual-agents",
    "href": "slides/ai-curators/index.html#activity-specific-agents-visual-agents",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Activity Specific Agents: Visual Agents",
    "text": "Activity Specific Agents: Visual Agents\n\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.\nHu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv."
  },
  {
    "objectID": "slides/ai-curators/index.html#visual-agents-architecture-different-llms-based-on-role",
    "href": "slides/ai-curators/index.html#visual-agents-architecture-different-llms-based-on-role",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Visual Agents Architecture: Different LLMs based on Role",
    "text": "Visual Agents Architecture: Different LLMs based on Role\n\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.\nHu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv."
  },
  {
    "objectID": "slides/ai-curators/index.html#activity-specific-agents-visual-agents-transition-graph",
    "href": "slides/ai-curators/index.html#activity-specific-agents-visual-agents-transition-graph",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Activity Specific Agents: Visual Agents Transition Graph",
    "text": "Activity Specific Agents: Visual Agents Transition Graph\n\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html.\nHu, Ziniu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David A. Ross, Cordelia Schmid, and Alireza Fathi. 2023. “AVIS: Autonomous Visual Information Seeking with Large Language Model Agent.” arXiv."
  },
  {
    "objectID": "slides/ai-curators/index.html#different-llms-for-different-tasks",
    "href": "slides/ai-curators/index.html#different-llms-for-different-tasks",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Different LLM’s for Different Tasks",
    "text": "Different LLM’s for Different Tasks\n\nLesson’s from Kaggle Science Exam Competition winning team solution\nBecomes a search - context retrieval problem for the curator LLM"
  },
  {
    "objectID": "slides/ai-curators/index.html#local-llms-vs-api-based-llms",
    "href": "slides/ai-curators/index.html#local-llms-vs-api-based-llms",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Local LLMs vs API based LLMs",
    "text": "Local LLMs vs API based LLMs\n\nLM Compatibility Tracking"
  },
  {
    "objectID": "slides/ai-curators/index.html#llms-fine-tuned-to-be-agents",
    "href": "slides/ai-curators/index.html#llms-fine-tuned-to-be-agents",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "LLMs fine tuned to be Agents",
    "text": "LLMs fine tuned to be Agents\n\n\n\n\nZeng, Aohan, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, and Jie Tang. 2023. “AgentTuning: Enabling Generalized Agent Abilities for LLMs.” arXiv. http://arxiv.org/abs/2310.12823.\n\n\n\nGPTQ model files for Knowledge Engineering GroupAgentLM 70B."
  },
  {
    "objectID": "slides/ai-curators/index.html#llms-fine-tuned-to-be-agents-1",
    "href": "slides/ai-curators/index.html#llms-fine-tuned-to-be-agents-1",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "LLMs fine tuned to be Agents",
    "text": "LLMs fine tuned to be Agents\n\n\n\n\nZeng, Aohan, Mingdao Liu, Rui Lu, Bowen Wang, Xiao Liu, Yuxiao Dong, and Jie Tang. 2023. “AgentTuning: Enabling Generalized Agent Abilities for LLMs.” arXiv. http://arxiv.org/abs/2310.12823.\n\n\n\nGPTQ model files for Knowledge Engineering GroupAgentLM 70B."
  },
  {
    "objectID": "slides/ai-curators/index.html#tool-use-calling-python-functions",
    "href": "slides/ai-curators/index.html#tool-use-calling-python-functions",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Tool Use (Calling Python Functions)",
    "text": "Tool Use (Calling Python Functions)\n\nCreate our own Code Interpreter | A hacker’s guide to Language Models\nGPT - OpenAI API\nFunction-calling with an OpenAPI specification | OpenAI Cookbook"
  },
  {
    "objectID": "slides/ai-curators/index.html#structured-responses-and-llms",
    "href": "slides/ai-curators/index.html#structured-responses-and-llms",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Structured Responses and LLMs",
    "text": "Structured Responses and LLMs\n\nlamma.cpp Grammers\nIntroducing Code Llama, a state-of-the-art large language model for coding\nlamma.cpp Python\nImplementation of Functions using Lamma.cpp grammar\nopenai-functions"
  },
  {
    "objectID": "slides/ai-curators/index.html#aws-agents-for-amazon-bedrock",
    "href": "slides/ai-curators/index.html#aws-agents-for-amazon-bedrock",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "AWS Agents for Amazon Bedrock",
    "text": "AWS Agents for Amazon Bedrock\n\nFully Managed Agents – Amazon Bedrock – AWS"
  },
  {
    "objectID": "slides/ai-curators/index.html#curation-state-graphs",
    "href": "slides/ai-curators/index.html#curation-state-graphs",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Curation State Graphs?",
    "text": "Curation State Graphs?"
  },
  {
    "objectID": "slides/ai-curators/index.html#modeling-the-world",
    "href": "slides/ai-curators/index.html#modeling-the-world",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Modeling The World!",
    "text": "Modeling The World!\n\n\n\nOntology Engineering: A View from the Trenches - WOP 2015 Keynote | PPT (slideshare.net)"
  },
  {
    "objectID": "slides/ai-curators/index.html#moo-architecture",
    "href": "slides/ai-curators/index.html#moo-architecture",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Moo Architecture",
    "text": "Moo Architecture"
  },
  {
    "objectID": "slides/ai-curators/index.html#we-need-to-think-through-what-trusted-means",
    "href": "slides/ai-curators/index.html#we-need-to-think-through-what-trusted-means",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "We need to think through what Trusted Means!",
    "text": "We need to think through what Trusted Means!"
  },
  {
    "objectID": "slides/ai-curators/index.html#frameworks-data-engine",
    "href": "slides/ai-curators/index.html#frameworks-data-engine",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Frameworks – Data Engine",
    "text": "Frameworks – Data Engine\n\nCopying Tesla’s Data Engine"
  },
  {
    "objectID": "slides/ai-curators/index.html#frameworks-to-capture-provenance-of-models",
    "href": "slides/ai-curators/index.html#frameworks-to-capture-provenance-of-models",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Frameworks to Capture Provenance of Models!",
    "text": "Frameworks to Capture Provenance of Models!\n\nSBoMs and AI BoMs for Agents\n\nThey are KGs Themselves!\n\nData Cards and Model Cards for Models\nAgents will be exposed as Microservices themselves\nWe should be able to ask the Microservice Layer for “Trust Information”\nAgent should store “Metadata” in the Graph Fragment they are constructing."
  },
  {
    "objectID": "slides/ai-curators/index.html#starting-with-a-csv-navy-maintenance-data",
    "href": "slides/ai-curators/index.html#starting-with-a-csv-navy-maintenance-data",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Starting with a CSV (Navy Maintenance Data)",
    "text": "Starting with a CSV (Navy Maintenance Data)\n\n\n\n\n\n\nKorini, Keti, and Christian Bizer. 2023. “Column Type Annotation Using ChatGPT.” arXiv. http://arxiv.org/abs/2306.00745."
  },
  {
    "objectID": "slides/ai-curators/index.html#context-matters",
    "href": "slides/ai-curators/index.html#context-matters",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Context Matters!",
    "text": "Context Matters!\n\n\n\nConverting Legacy Enterprise Data into Knowledge Graphs with AI and JSON LD | Eliud Polanco"
  },
  {
    "objectID": "slides/ai-curators/index.html#json-ld-as-a-bridge",
    "href": "slides/ai-curators/index.html#json-ld-as-a-bridge",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "JSON-LD as a Bridge",
    "text": "JSON-LD as a Bridge\n\n\n\nConverting Legacy Enterprise Data into Knowledge Graphs with AI and JSON LD | Eliud Polanco"
  },
  {
    "objectID": "slides/ai-curators/index.html#aside-curator-ais-should-be-multimodal",
    "href": "slides/ai-curators/index.html#aside-curator-ais-should-be-multimodal",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Aside: Curator AI’s should be multimodal",
    "text": "Aside: Curator AI’s should be multimodal\n\nDr. Vardeman’s Law: Data “Lives” in different locations and formats – not every digital object can or should be in the KG layer. The Curator AI should “Catalog” this information.\nMultimodal LLM’s like AVIS can bridge that Gap!"
  },
  {
    "objectID": "slides/ai-curators/index.html#semantic-ai-based-micro-services",
    "href": "slides/ai-curators/index.html#semantic-ai-based-micro-services",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Semantic AI-based Micro Services",
    "text": "Semantic AI-based Micro Services"
  },
  {
    "objectID": "slides/ai-curators/index.html#how-can-we-create-semantic-microservices",
    "href": "slides/ai-curators/index.html#how-can-we-create-semantic-microservices",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "How can we create “Semantic Microservices”",
    "text": "How can we create “Semantic Microservices”\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. “The Semantic Web.” Scientific American 284, no. 5 (2001): 34–43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/ai-curators/index.html#semantic-web-layer-cake",
    "href": "slides/ai-curators/index.html#semantic-web-layer-cake",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Semantic Web “Layer Cake”",
    "text": "Semantic Web “Layer Cake”\n\n\n\nJohn Sowa, “Semantics.” n.d. Accessed October 17, 2023. https://www.jfsowa.com/ikl/. Q92665"
  },
  {
    "objectID": "slides/ai-curators/index.html#aside-sowas-law-of-standards",
    "href": "slides/ai-curators/index.html#aside-sowas-law-of-standards",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Aside: Sowa’s law of standards",
    "text": "Aside: Sowa’s law of standards\n\n“Whenever a major organization develops a new system as an official standard for X, the primary result is the widespread adoption of some simpler system as a de facto standard for X.”"
  },
  {
    "objectID": "slides/ai-curators/index.html#janos-layer-cake",
    "href": "slides/ai-curators/index.html#janos-layer-cake",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Jano’s Layer Cake",
    "text": "Jano’s Layer Cake\n\n\n\nOntology Engineering: A View from the Trenches - WOP 2015 Keynote | PPT (slideshare.net)"
  },
  {
    "objectID": "slides/ai-curators/index.html#distributed-knowledge-graph-layer-cake",
    "href": "slides/ai-curators/index.html#distributed-knowledge-graph-layer-cake",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Distributed Knowledge Graph Layer Cake",
    "text": "Distributed Knowledge Graph Layer Cake\n\n\n\n\nDKG Basic Concepts"
  },
  {
    "objectID": "slides/ai-curators/index.html#dkg-example",
    "href": "slides/ai-curators/index.html#dkg-example",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "DKG Example",
    "text": "DKG Example\n\n\n\n\n\n\n\nOriginTrail powering consumer interaction with the new GS1 Digital Link"
  },
  {
    "objectID": "slides/ai-curators/index.html#web-2.0-architecture-microservices",
    "href": "slides/ai-curators/index.html#web-2.0-architecture-microservices",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "“Web 2.0 Architecture – Microservices”",
    "text": "“Web 2.0 Architecture – Microservices”\n\nRESTful web API design"
  },
  {
    "objectID": "slides/ai-curators/index.html#documenting-rest-apis",
    "href": "slides/ai-curators/index.html#documenting-rest-apis",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Documenting REST-APIs",
    "text": "Documenting REST-APIs\n\n\n\n\nAbout Swagger Specification | Documentation | Swagger"
  },
  {
    "objectID": "slides/ai-curators/index.html#example-huggingface-embedding-service",
    "href": "slides/ai-curators/index.html#example-huggingface-embedding-service",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Example: HuggingFace Embedding Service",
    "text": "Example: HuggingFace Embedding Service\n\nA blazing fast inference solution for text embeddings models"
  },
  {
    "objectID": "slides/ai-curators/index.html#example-huggingface-embedding-service-1",
    "href": "slides/ai-curators/index.html#example-huggingface-embedding-service-1",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Example: HuggingFace Embedding Service",
    "text": "Example: HuggingFace Embedding Service\n\nText Generation Inference API"
  },
  {
    "objectID": "slides/ai-curators/index.html#openai-plugins",
    "href": "slides/ai-curators/index.html#openai-plugins",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "OpenAI “Plugins”",
    "text": "OpenAI “Plugins”\n\n\n\n\nGetting started - OpenAI API"
  },
  {
    "objectID": "slides/ai-curators/index.html#microsoft-and-openai-plugins",
    "href": "slides/ai-curators/index.html#microsoft-and-openai-plugins",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Microsoft and “OpenAI Plugins”",
    "text": "Microsoft and “OpenAI Plugins”\n\nCreate and run a ChatGPT plugin with Semantic Kernel | Microsoft Learn"
  },
  {
    "objectID": "slides/ai-curators/index.html#bridging-rest-to-ai-using-json-ld",
    "href": "slides/ai-curators/index.html#bridging-rest-to-ai-using-json-ld",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Bridging Rest to AI using JSON-LD",
    "text": "Bridging Rest to AI using JSON-LD\n\n\n\n\n\nJSON-LD 1.1 – A JSON-based Serialization for Linked Data"
  },
  {
    "objectID": "slides/ai-curators/index.html#json-ld-best-practices",
    "href": "slides/ai-curators/index.html#json-ld-best-practices",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "JSON-LD Best Practices",
    "text": "JSON-LD Best Practices\n\n\n\n\n\nJSON-LD Best Practices"
  },
  {
    "objectID": "slides/ai-curators/index.html#json-as-json-ld",
    "href": "slides/ai-curators/index.html#json-as-json-ld",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "JSON as JSON-LD",
    "text": "JSON as JSON-LD\nGET /ordinary-json-document.json HTTP/1.1\nHost: example.com\nAccept: application/ld+json,application/json,*/*;q=0.1\n\n====================================\n\nHTTP/1.1 200 OK\n...\nContent-Type: application/json\nLink: &lt;https://json-ld.org/contexts/person.jsonld&gt;; rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n\n{\n  \"name\": \"Markus Lanthaler\",\n  \"homepage\": \"http://www.markus-lanthaler.com/\",\n  \"image\": \"http://twitter.com/account/profile_image/markuslanthaler\"\n}"
  },
  {
    "objectID": "slides/ai-curators/index.html#gorilla-retrieval-aware-training-for-apis",
    "href": "slides/ai-curators/index.html#gorilla-retrieval-aware-training-for-apis",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Gorilla: Retrieval Aware Training for APIs",
    "text": "Gorilla: Retrieval Aware Training for APIs\n\n\n\n\n\n\n\n\nS. Patil, “Gorilla: Large Language Model Connected with Massive APIs [Project Website].” Sep. 04, 2023.\nAccessed: Sep. 04, 2023. [Online]. Available: https://github.com/ShishirPatil/gorilla"
  },
  {
    "objectID": "slides/ai-curators/index.html#gorilla-retrieval-aware-training-for-apis-1",
    "href": "slides/ai-curators/index.html#gorilla-retrieval-aware-training-for-apis-1",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Gorilla: Retrieval Aware Training for APIs",
    "text": "Gorilla: Retrieval Aware Training for APIs\n\n\n\n\n\n\n\n\nS. Patil, “Gorilla: Large Language Model Connected with Massive APIs [Project Website].” Sep. 04, 2023.\nAccessed: Sep. 04, 2023. [Online]. Available: https://github.com/ShishirPatil/gorilla"
  },
  {
    "objectID": "slides/ai-curators/index.html#problem-with-rest-interoperability-scale-and-queriability",
    "href": "slides/ai-curators/index.html#problem-with-rest-interoperability-scale-and-queriability",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Problem with REST – Interoperability, Scale and Queriability",
    "text": "Problem with REST – Interoperability, Scale and Queriability"
  },
  {
    "objectID": "slides/ai-curators/index.html#semantic-apis-for-kgs",
    "href": "slides/ai-curators/index.html#semantic-apis-for-kgs",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "“Semantic APIs for KG’s”",
    "text": "“Semantic APIs for KG’s”"
  },
  {
    "objectID": "slides/ai-curators/index.html#sparql-1.1-federated-queries",
    "href": "slides/ai-curators/index.html#sparql-1.1-federated-queries",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "SPARQL 1.1 Federated Queries",
    "text": "SPARQL 1.1 Federated Queries\n\n\n\n\n\nBenefitting from SPARQL 1.1 Federated Queries with Amazon Neptune\n\n\n\n\n\n\nSPARQL 1.1 Federated Query"
  },
  {
    "objectID": "slides/ai-curators/index.html#how-do-we-provide-context-to-llms-to-query-a-kg",
    "href": "slides/ai-curators/index.html#how-do-we-provide-context-to-llms-to-query-a-kg",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "How do we provide “Context” to LLMs to QUERY a KG?",
    "text": "How do we provide “Context” to LLMs to QUERY a KG?"
  },
  {
    "objectID": "slides/ai-curators/index.html#sparql-1.1-service-description-to-provide-context",
    "href": "slides/ai-curators/index.html#sparql-1.1-service-description-to-provide-context",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "SPARQL 1.1 Service Description to provide Context!",
    "text": "SPARQL 1.1 Service Description to provide Context!\n\n\n\n\n\n\n\nDataset and API Discovery in Linked Data"
  },
  {
    "objectID": "slides/ai-curators/index.html#example-in-the-wild",
    "href": "slides/ai-curators/index.html#example-in-the-wild",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Example in the Wild",
    "text": "Example in the Wild\n\n\n\n\n\nSwiss Linked Data: https://geo.ld.admin.ch/.well-known/void\n\n\n\n\n\n\nUniProt: https://sparql.uniprot.org/.well-known/void"
  },
  {
    "objectID": "slides/ai-curators/index.html#chatgpt-plugin-architecture-as-example",
    "href": "slides/ai-curators/index.html#chatgpt-plugin-architecture-as-example",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "ChatGPT “Plugin” Architecture as Example",
    "text": "ChatGPT “Plugin” Architecture as Example\n\nChatGPT plugins (openai.com)\nIntroduction - OpenAI API\nAbout Get a ChatGPT plugin up and running in under 5 minutes!\nUse LangChain OpenAPI\nChatGPT Plugin – LangChain\nHow to build a tool-using agent with LangChain"
  },
  {
    "objectID": "slides/ai-curators/index.html#example-service-retrieval-augmented-generation-were-not-doing-this-yet",
    "href": "slides/ai-curators/index.html#example-service-retrieval-augmented-generation-were-not-doing-this-yet",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "Example Service – Retrieval Augmented Generation (We’re not doing this yet!)",
    "text": "Example Service – Retrieval Augmented Generation (We’re not doing this yet!)\n\n\n\n\nExperiments in extracting tables from navy 3-M manual for OPNAV 4790/2K data structure Resources\nSample KG construction using OPNAV forms 4790/ 2K as a schema template\nRepository for formatting the Joint Electronics Type Designation System for ML and KG Usage\nLikely needed to be stored in a Vector Store"
  },
  {
    "objectID": "slides/ai-curators/index.html#sparql-interfaces",
    "href": "slides/ai-curators/index.html#sparql-interfaces",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "SPARQL Interfaces",
    "text": "SPARQL Interfaces"
  },
  {
    "objectID": "slides/ai-curators/index.html#kg-interpretation-in-contexts",
    "href": "slides/ai-curators/index.html#kg-interpretation-in-contexts",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "KG Interpretation in Contexts",
    "text": "KG Interpretation in Contexts"
  },
  {
    "objectID": "slides/ai-curators/index.html#fair-vocabularies-and-ontologies",
    "href": "slides/ai-curators/index.html#fair-vocabularies-and-ontologies",
    "title": "Towards Trusted LLM based Curator Agents",
    "section": "FAIR Vocabularies and Ontologies",
    "text": "FAIR Vocabularies and Ontologies"
  },
  {
    "objectID": "slides/building_stuff/index.html#slides-link-httpsla3d.github.ionuggetsslideindex.html",
    "href": "slides/building_stuff/index.html#slides-link-httpsla3d.github.ionuggetsslideindex.html",
    "title": "Building “Stuff”?",
    "section": "Slides Link: https://la3d.github.io/nuggets/slideindex.html",
    "text": "Slides Link: https://la3d.github.io/nuggets/slideindex.html"
  },
  {
    "objectID": "slides/building_stuff/index.html#building-stuff",
    "href": "slides/building_stuff/index.html#building-stuff",
    "title": "Building “Stuff”?",
    "section": "Building “Stuff”…",
    "text": "Building “Stuff”…\n\n\nJeremy Jordan. “Effective Testing for Machine Learning Systems.,”\nAugust 19, 2020. https://www.jeremyjordan.me/testing-ml/."
  },
  {
    "objectID": "slides/building_stuff/index.html#building-stuff-1",
    "href": "slides/building_stuff/index.html#building-stuff-1",
    "title": "Building “Stuff”?",
    "section": "Building “Stuff”…",
    "text": "Building “Stuff”…"
  },
  {
    "objectID": "slides/building_stuff/index.html#section",
    "href": "slides/building_stuff/index.html#section",
    "title": "Building “Stuff”?",
    "section": "",
    "text": "Building Stuff?\n\n\n\nBuilding Agents based on Large Language Models!"
  },
  {
    "objectID": "slides/building_stuff/index.html#you-are-almost-here",
    "href": "slides/building_stuff/index.html#you-are-almost-here",
    "title": "Building “Stuff”?",
    "section": "You are “almost” here ⬇️",
    "text": "You are “almost” here ⬇️"
  },
  {
    "objectID": "slides/building_stuff/index.html#building-agents-involves-pre-trained-foundation-models",
    "href": "slides/building_stuff/index.html#building-agents-involves-pre-trained-foundation-models",
    "title": "Building “Stuff”?",
    "section": "Building “Agents” Involves Pre-trained Foundation Models…",
    "text": "Building “Agents” Involves Pre-trained Foundation Models…\n\n\n\n\nZhou, Ce, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, et al. \n“A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.”\narXiv, May 1, 2023.https://doi.org/10.48550/arXiv.2302.09419."
  },
  {
    "objectID": "slides/building_stuff/index.html#how-do-we-program-a-large-language-model",
    "href": "slides/building_stuff/index.html#how-do-we-program-a-large-language-model",
    "title": "Building “Stuff”?",
    "section": "How do we “program” a Large Language Model?",
    "text": "How do we “program” a Large Language Model?"
  },
  {
    "objectID": "slides/building_stuff/index.html#autoregressive-large-language-model",
    "href": "slides/building_stuff/index.html#autoregressive-large-language-model",
    "title": "Building “Stuff”?",
    "section": "Autoregressive Large Language Model",
    "text": "Autoregressive Large Language Model\n“An autoregressive large language model (AR-LLM) is a type of neural network model that can generate natural language text. It has a very large number of parameters (billions or trillions) that are trained on a huge amount of text data from various sources. The main goal of an AR-LLM is to predict the next word or token based on the previous words or tokens in the input text. For example, if the input text is”The sky is”, the AR-LLM might predict “blue” as the next word. AR-LLMs can also generate text from scratch by sampling words from a probability distribution. For example, if the input text is empty, the AR-LLM might generate “Once upon a time, there was a princess who lived in a castle.” as the output text.”1\nBing Chat, Accessed: 09-05-23 https://sl.bing.net/vDC45Llquq"
  },
  {
    "objectID": "slides/building_stuff/index.html#ar-llms-can-simulate-turing-machines",
    "href": "slides/building_stuff/index.html#ar-llms-can-simulate-turing-machines",
    "title": "Building “Stuff”?",
    "section": "AR-LLMs can simulate “Turing Machines”",
    "text": "AR-LLMs can simulate “Turing Machines”\n\n\n\n\nAbstract: We show that transformer-based large language models are computationally universal when augmented with an external memory. Any deterministic language model that conditions on strings of bounded length is equivalent to a finite automaton, hence computationally limited. However, augmenting such models with a read-write memory creates the possibility of processing arbitrarily large inputs and, potentially, simulating any algorithm. We establish that an existing large language model, Flan-U-PaLM 540B, can be combined with an associative read-write memory to exactly simulate the execution of a universal Turing machine, \\(U_{15,2}\\). A key aspect of the finding is that it does not require any modification of the language model weights. Instead, the construction relies solely on designing a form of stored instruction computer that can subsequently be programmed with a specific set of prompts.\n\n\nSchuurmans, Dale. “Memory Augmented Large Language Models Are Computationally Universal.”\narXiv, January 9, 2023. https://doi.org/10.48550/arXiv.2301.04589."
  },
  {
    "objectID": "slides/building_stuff/index.html#what-kind-of-llm-agents-are-we-trying-to-build",
    "href": "slides/building_stuff/index.html#what-kind-of-llm-agents-are-we-trying-to-build",
    "title": "Building “Stuff”?",
    "section": "What Kind of LLM Agents are we trying to build?",
    "text": "What Kind of LLM Agents are we trying to build?\n\n\nConversational Agents\nvs. Cognitive Autonomous Agents\nvs. Agents tuned for a Data Processing Task"
  },
  {
    "objectID": "slides/building_stuff/index.html#section-1",
    "href": "slides/building_stuff/index.html#section-1",
    "title": "Building “Stuff”?",
    "section": "",
    "text": "We will focus on Conversational Agents…"
  },
  {
    "objectID": "slides/building_stuff/index.html#the-best-advice-we-can-give",
    "href": "slides/building_stuff/index.html#the-best-advice-we-can-give",
    "title": "Building “Stuff”?",
    "section": "The Best Advice we can Give…",
    "text": "The Best Advice we can Give…\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023.\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#section-2",
    "href": "slides/building_stuff/index.html#section-2",
    "title": "Building “Stuff”?",
    "section": "",
    "text": "Andrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023.\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#caveat-you-are-at-the-edge-of-research-and-practice",
    "href": "slides/building_stuff/index.html#caveat-you-are-at-the-edge-of-research-and-practice",
    "title": "Building “Stuff”?",
    "section": "Caveat: You are at the Edge of Research and Practice!",
    "text": "Caveat: You are at the Edge of Research and Practice!"
  },
  {
    "objectID": "slides/building_stuff/index.html#prompt-engineering",
    "href": "slides/building_stuff/index.html#prompt-engineering",
    "title": "Building “Stuff”?",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n“Prompt engineering is the process of designing and refining the prompts or input stimuli for a language model to generate specific types of output. Prompt engineering involves selecting appropriate keywords, providing context, and shaping the input in a way that encourages the model to produce the desired response and is a vital technique to actively shape the behavior and output of foundation models.”1\n“Prompt Engineering for Foundation Models - Amazon SageMaker.” Accessed September 4, 2023. http://tiny.cc/p3mavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "href": "slides/building_stuff/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "title": "Building “Stuff”?",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al.\n“Training Language Models to Follow Instructions with Human Feedback.”\narXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/building_stuff/index.html#instruction-tuning-facilitate-conversational-agents-to-converse-in-a-set-style",
    "href": "slides/building_stuff/index.html#instruction-tuning-facilitate-conversational-agents-to-converse-in-a-set-style",
    "title": "Building “Stuff”?",
    "section": "Instruction Tuning Facilitate Conversational Agents to “Converse” in a Set Style!",
    "text": "Instruction Tuning Facilitate Conversational Agents to “Converse” in a Set Style!"
  },
  {
    "objectID": "slides/building_stuff/index.html#tools-for-prompt-engineering",
    "href": "slides/building_stuff/index.html#tools-for-prompt-engineering",
    "title": "Building “Stuff”?",
    "section": "Tools for “Prompt Engineering”",
    "text": "Tools for “Prompt Engineering”\n\n\n\n\nHenry Zeng, Lauryn Gayhardt, Jill Grant “What is Azure Machine Learning prompt flow\n(preview) - Azure Machine Learning,” Jul. 02, 2023.\nhttp://tiny.cc/kelavz (accessed Sep. 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#tools-for-prompt-engineering-1",
    "href": "slides/building_stuff/index.html#tools-for-prompt-engineering-1",
    "title": "Building “Stuff”?",
    "section": "Tools for “Prompt Engineering”",
    "text": "Tools for “Prompt Engineering”\n\n\n\n\nHenry Zeng, Lauryn Gayhardt, Jill Grant “What is Azure Machine Learning prompt flow\n(preview) - Azure Machine Learning,” Jul. 02, 2023.\nhttp://tiny.cc/kelavz (accessed Sep. 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents",
    "href": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents",
    "title": "Building “Stuff”?",
    "section": "Trusted “Prompt Engineering” for Conversational Agents",
    "text": "Trusted “Prompt Engineering” for Conversational Agents\n“NeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems. Guardrails (or”rails” for short) are specific ways of controlling the output of a large language model, such as not talking about politics, responding in a particular way to specific user requests, following a predefined dialog path, using a particular language style, extracting structured data, and more.”1\n“NeMo Guardrails.” NVIDIA Corporation, Sep. 05, 2023. Accessed: Sep. 05, 2023. [Online]. Available: https://github.com/NVIDIA/NeMo-Guardrails"
  },
  {
    "objectID": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents-1",
    "href": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents-1",
    "title": "Building “Stuff”?",
    "section": "Trusted “Prompt Engineering” for Conversational Agents",
    "text": "Trusted “Prompt Engineering” for Conversational Agents\n\nBuilding Trustworthy, Safe, and Secure LLM Conversational Systems: The core value of using NeMo Guardrails is the ability to write rails to guide conversations. You can choose to define the behavior of your LLM-powered application on specific topics and prevent it from engaging in discussions on unwanted topics.\nConnect models, chains, services, and more via actions: NeMo Guardrails provides the ability to connect an LLM to other services (a.k.a. tools) seamlessly and securely.\n\n\n“NeMo Guardrails.” NVIDIA Corporation, Sep. 05, 2023. Accessed: Sep. 05, 2023. [Online].\nAvailable: https://github.com/NVIDIA/NeMo-Guardrails"
  },
  {
    "objectID": "slides/building_stuff/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "href": "slides/building_stuff/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "title": "Building “Stuff”?",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.\n“Large Language Models Are Zero-Shot Reasoners.” arXiv, January 29, 2023.\nhttps://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/building_stuff/index.html#llms-as-reasoners-using-prompts",
    "href": "slides/building_stuff/index.html#llms-as-reasoners-using-prompts",
    "title": "Building “Stuff”?",
    "section": "LLMs as Reasoners using Prompts!",
    "text": "LLMs as Reasoners using Prompts!\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al\n“Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023.\nhttp://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/building_stuff/index.html#prompt-engineering-guide",
    "href": "slides/building_stuff/index.html#prompt-engineering-guide",
    "title": "Building “Stuff”?",
    "section": "Prompt Engineering Guide",
    "text": "Prompt Engineering Guide\n\n\n\n\n\n\n\n\n“Prompt Engineering Guide – Nextra.”\nhttps://www.promptingguide.ai/ (accessed Sep. 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual",
    "href": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual",
    "title": "Building “Stuff”?",
    "section": "We want Large Language Models to be Factual!",
    "text": "We want Large Language Models to be Factual!\n\nFine-Tuning: augment the behavior of the model\nRetrieval: introduce new knowledge to the model\nRetreval Aware Training (RAT) Fine-tune the model to use or ignore retrieved content"
  },
  {
    "objectID": "slides/building_stuff/index.html#fine-tuning-foundation-models",
    "href": "slides/building_stuff/index.html#fine-tuning-foundation-models",
    "title": "Building “Stuff”?",
    "section": "Fine-Tuning Foundation Models",
    "text": "Fine-Tuning Foundation Models\n“Foundation models are computationally expensive and trained on a large, unlabeled corpus. Fine-tuning a pre-trained foundation model is an affordable way to take advantage of their broad capabilities while customizing a model on your own small, corpus. Fine-tuning is a customization method that involved further training and does change the weights of your model…”\n“…There are two main approaches that you can take for fine-tuning depending on your use case and chosen foundation model. If you’re interested in fine-tuning your model on domain-specific data, see Domain adaptation fine-tuning. If you’re interested in instruction-based fine-tuning using prompt and response examples, see Instruction-based fine-tuning.”1\n“Fine-tune a foundation model - Amazon SageMaker”, http://tiny.cc/grmavz (accessed Sep. 05, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#retrieval-augmented-generation-rag",
    "href": "slides/building_stuff/index.html#retrieval-augmented-generation-rag",
    "title": "Building “Stuff”?",
    "section": "Retrieval Augmented Generation (RAG)",
    "text": "Retrieval Augmented Generation (RAG)\n“Foundation models are usually trained offline, making the model agnostic to any data that is created after the model was trained. Additionally, foundation models are trained on very general domain corpora, making them less effective for domain-specific tasks. You can use Retrieval Augmented Generation (RAG) to retrieve data from outside a foundation model and augment your prompts by adding the relevant retrieved data in context. For more information about RAG model architectures”1\n“Retrieval Augmented Generation (RAG) - Amazon SageMaker.” Accessed September 4, 2023. http://tiny.cc/f3mavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#retrieval-augmented-generation-rag-1",
    "href": "slides/building_stuff/index.html#retrieval-augmented-generation-rag-1",
    "title": "Building “Stuff”?",
    "section": "Retrieval Augmented Generation (RAG)",
    "text": "Retrieval Augmented Generation (RAG)\n\n\n\n\n\n\n\n\n“Retrieval Augmented Generation (RAG) - Amazon SageMaker.” Accessed September 4, 2023.\nhttp://tiny.cc/f3mavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#llamaindex-to-build-hybrid-kgs",
    "href": "slides/building_stuff/index.html#llamaindex-to-build-hybrid-kgs",
    "title": "Building “Stuff”?",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\n\n\n\n\n\n\n“Custom Retriever Combining KG Index and VectorStore Index\n\nLlamaIndex 🦙 0.8.5.Post2.” Accessed August 22, 2023.\n\nhttp://tiny.cc/oflavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis",
    "href": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis",
    "title": "Building “Stuff”?",
    "section": "Gorilla: Retrieval Aware Training for APIs",
    "text": "Gorilla: Retrieval Aware Training for APIs\n\n\n\n\n\n\n\n\nS. Patil, “Gorilla: Large Language Model Connected with Massive APIs [Project Website].” Sep. 04, 2023.\nAccessed: Sep. 04, 2023. [Online]. Available: https://github.com/ShishirPatil/gorilla"
  },
  {
    "objectID": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis-1",
    "href": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis-1",
    "title": "Building “Stuff”?",
    "section": "Gorilla: Retrieval Aware Training for APIs",
    "text": "Gorilla: Retrieval Aware Training for APIs\n\n\n\n\n\n\n\n\nS. Patil, “Gorilla: Large Language Model Connected with Massive APIs [Project Website].” Sep. 04, 2023.\nAccessed: Sep. 04, 2023. [Online]. Available: https://github.com/ShishirPatil/gorilla"
  },
  {
    "objectID": "slides/building_stuff/index.html#big-models-vs-small-models",
    "href": "slides/building_stuff/index.html#big-models-vs-small-models",
    "title": "Building “Stuff”?",
    "section": "“Big Models” vs “Small Models”",
    "text": "“Big Models” vs “Small Models”\n\n\nModels as a service (Bedrock, OpenAI API, Anthropic Claude)\n\nGenerally more difficult to “Fine-Tune” (GPT-3.5 turbo)1\nModels are generally more capable (Factuality, Instructions, Reasoning)]\n“Coin-operated” pay per/token\n\n“Open License” 7B-70B Parameter Models\n\nMostly based on Meta AI LLama or LLama 2 models\nRequire more effort to work consistently\nModels can run on reduced hardware requirements\nCan be fine-tuned for task specific workflows\n\n\n\n“GPT-3.5 Turbo fine-tuning and API updates.” https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates (accessed Sep. 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#small-models-with-custom-grammar-llama.cpp",
    "href": "slides/building_stuff/index.html#small-models-with-custom-grammar-llama.cpp",
    "title": "Building “Stuff”?",
    "section": "Small Models with custom grammar (llama.cpp)",
    "text": "Small Models with custom grammar (llama.cpp)\nJSON-Grammar\nroot   ::= object\nvalue  ::= object | array | string | number | (\"true\" | \"false\" | \"null\") ws\n\nobject ::=\n  \"{\" ws (\n            string \":\" ws value\n    (\",\" ws string \":\" ws value)*\n  )? \"}\" ws\n\narray  ::=\n  \"[\" ws (\n            value\n    (\",\" ws value)*\n  )? \"]\" ws\n\nstring ::=\n  \"\\\"\" (\n    [^\"\\\\] |\n    \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]) # escapes\n  )* \"\\\"\" ws\n\nnumber ::= (\"-\"? ([0-9] | [1-9] [0-9]*)) (\".\" [0-9]+)? ([eE] [-+]? [0-9]+)? ws\n\n# Optional space: by convention, applied in this grammar after literal chars when allowed\nws ::= ([ \\t\\n] ws)?\n\n“speculative : add grammar support by ggerganov · Pull Request #2991 · ggerganov/llama.cpp,”\nGitHub. https://github.com/ggerganov/llama.cpp/pull/2991 (accessed Sep. 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#the-state-of-gpt-recommendations",
    "href": "slides/building_stuff/index.html#the-state-of-gpt-recommendations",
    "title": "Building “Stuff”?",
    "section": "“The state of GPT” Recommendations",
    "text": "“The state of GPT” Recommendations\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023.\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#open-source-community",
    "href": "slides/building_stuff/index.html#open-source-community",
    "title": "Building “Stuff”?",
    "section": "Open Source Community",
    "text": "Open Source Community\n\n\n\n\n\n\n\nMatt Bronstein and Rajko Radovanovic, “Supporting the Open Source AI Community,”\nAndreessen Horowitz, Aug. 30, 2023.\nhttp://tiny.cc/uflavz (accessed Sep. 03, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#on-to-the-first-steps-to-building-llm-based-applications",
    "href": "slides/building_stuff/index.html#on-to-the-first-steps-to-building-llm-based-applications",
    "title": "Building “Stuff”?",
    "section": "On to the First Steps to Building LLM Based Applications…",
    "text": "On to the First Steps to Building LLM Based Applications…"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "href": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "title": "KG Construction",
    "section": "KG Construction Pipeline",
    "text": "KG Construction Pipeline"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "href": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "title": "KG Construction",
    "section": "LLM KG Construction Frameworks Llamaindex",
    "text": "LLM KG Construction Frameworks Llamaindex\n\nLearn more: Llamaindex"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#rebel-large-model",
    "href": "slides/kg-llamaindex/index.html#rebel-large-model",
    "title": "KG Construction",
    "section": "Rebel Large Model",
    "text": "Rebel Large Model\n#| echo: true\nfrom transformers import pipeline\n\ntriplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets(text):\n    triplets = []\n    relation, subject, relation, object_ = '', '', '', ''\n    text = text.strip()\n    current = 'x'\n    for token in text.replace(\"&lt;s&gt;\", \"\").replace(\"&lt;pad&gt;\", \"\").replace(\"&lt;/s&gt;\", \"\").split():\n        if token == \"&lt;triplet&gt;\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n                relation = ''\n            subject = ''\n        elif token == \"&lt;subj&gt;\":\n            current = 's'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n            object_ = ''\n        elif token == \"&lt;obj&gt;\":\n            current = 'o'\n            relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '':\n        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n    return triplets\nextracted_triplets = extract_triplets(extracted_text[0])\nprint(extracted_triplets)\n\nLearn more: Rebel Large"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel",
    "text": "LlamaIndex with Rebel\n\n\nLearn more: Llamaindex with Rebel Colab Notebook"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel and Neo4j",
    "text": "LlamaIndex with Rebel and Neo4j\n\n\nLearn more: Neo4j Graph Store\nGitHub: Tomaz Bratanic"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "href": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "title": "KG Construction",
    "section": "Weaviate With Llama 2 and Llamaindex",
    "text": "Weaviate With Llama 2 and Llamaindex\n\n\nLearn more: Welcome to the quick notebook on using Llama 2"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "title": "KG Construction",
    "section": "Weaviate “Knowledge Graphs”",
    "text": "Weaviate “Knowledge Graphs”\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "title": "KG Construction",
    "section": "Weaviate “Knowledge Graphs”",
    "text": "Weaviate “Knowledge Graphs”\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#aws-neptune",
    "href": "slides/kg-llamaindex/index.html#aws-neptune",
    "title": "KG Construction",
    "section": "AWS Neptune",
    "text": "AWS Neptune\n\n\nLearn More: Amazon Neptune"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "href": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "title": "KG Construction",
    "section": "Amazon Science ReFinED",
    "text": "Amazon Science ReFinED\n\n\nPaper: ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking\nPaper: Improving Entity Disambiguation by Reasoning over a Knowledge Base\nGitHub: ReFinED is an efficient and accurate entity linking (EL) system."
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "href": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "title": "KG Construction",
    "section": "Amazon Science KGQA",
    "text": "Amazon Science KGQA\n\n\nWebsite: Language models as controlled natural language semantic parsers for knowledge graph question answering GitHub: Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering"
  },
  {
    "objectID": "slides/rag-part1/index.html#hypothesis-retrieval-augmented-generation-requires-curation",
    "href": "slides/rag-part1/index.html#hypothesis-retrieval-augmented-generation-requires-curation",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Hypothesis: Retrieval Augmented Generation Requires Curation",
    "text": "Hypothesis: Retrieval Augmented Generation Requires Curation"
  },
  {
    "objectID": "slides/rag-part1/index.html#knowledge-engineering-using-large-language-models",
    "href": "slides/rag-part1/index.html#knowledge-engineering-using-large-language-models",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Knowledge Engineering Using Large Language Models",
    "text": "Knowledge Engineering Using Large Language Models\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/rag-part1/index.html#prompt-engineering-as-knowledge-engineering",
    "href": "slides/rag-part1/index.html#prompt-engineering-as-knowledge-engineering",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Prompt Engineering as Knowledge Engineering",
    "text": "Prompt Engineering as Knowledge Engineering\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/rag-part1/index.html#knowledge-engineering-practice",
    "href": "slides/rag-part1/index.html#knowledge-engineering-practice",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Knowledge Engineering Practice",
    "text": "Knowledge Engineering Practice\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/rag-part1/index.html#trusted-ai-llms-and-ke",
    "href": "slides/rag-part1/index.html#trusted-ai-llms-and-ke",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Trusted AI, LLMs and KE",
    "text": "Trusted AI, LLMs and KE\n\nAllen, Bradley P, Lise Stork, and Paul Groth. 2023. “Knowledge Engineering Using Large Language Models.” arXiv.Org. October 1, 2023. https://arxiv.org/abs/2310.00637"
  },
  {
    "objectID": "slides/rag-part1/index.html#retrieval-augmented-generation-for-large-language-models-a-survey",
    "href": "slides/rag-part1/index.html#retrieval-augmented-generation-for-large-language-models-a-survey",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Retrieval-Augmented Generation for Large Language Models: A Survey",
    "text": "Retrieval-Augmented Generation for Large Language Models: A Survey\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2024. “Retrieval-Augmented Generation for Large Language Models: A Survey.” arXiv. https://doi.org/10.48550/arXiv.2312.10997."
  },
  {
    "objectID": "slides/rag-part1/index.html#sparse-and-dense-representations",
    "href": "slides/rag-part1/index.html#sparse-and-dense-representations",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Sparse and Dense Representations",
    "text": "Sparse and Dense Representations\n\nPaco Nathan, 2021, “Thinking Sparse and Dense”"
  },
  {
    "objectID": "slides/rag-part1/index.html#retrieval-augmented-generation-the-idea",
    "href": "slides/rag-part1/index.html#retrieval-augmented-generation-the-idea",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Retrieval Augmented Generation – The Idea",
    "text": "Retrieval Augmented Generation – The Idea\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2024. “Retrieval-Augmented Generation for Large Language Models: A Survey.” arXiv. https://doi.org/10.48550/arXiv.2312.10997."
  },
  {
    "objectID": "slides/rag-part1/index.html#naive-rag",
    "href": "slides/rag-part1/index.html#naive-rag",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Naive RAG",
    "text": "Naive RAG\n\nIndexing\n\nData Indexing: Cleaning and extracting data from PDF, HTML, Word, Markdown, Images\nChunking: Dividing text into smaller chunks for LLM limited context window\nEmbedding and Creating Index: Encoding text/images into vectors through a language model\n\nRetrieve: Given a user input, retrieve relevant information\nGeneration: The user query to the LLM and related documents from retrieval are combined into a new prompt. The LLM generates a response based on this new context window."
  },
  {
    "objectID": "slides/rag-part1/index.html#naive-rag-architecture",
    "href": "slides/rag-part1/index.html#naive-rag-architecture",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Naive RAG Architecture",
    "text": "Naive RAG Architecture\n\nLangchain Q&A with RAG"
  },
  {
    "objectID": "slides/rag-part1/index.html#some-text",
    "href": "slides/rag-part1/index.html#some-text",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Some text",
    "text": "Some text\n\n\nDoD must accelerate its progress towards becoming a data-centric organization. DoD has lacked the enterprise data management to ensure that trusted, critical data is widely available to or accessible by mission commanders, warfighters, decision-makers, and mission partners in a real- time, useable, secure, and linked manner. This limits data-driven decisions and insights, which hinders the execution of swift and appropriate action.\n\nAdditionally, DoD software and hardware systems must be designed, procured, tested, upgraded, operated, and sustained with data interoperability as a key requirement. All too often these gaps are bridged with unnecessary human-machine interfaces that introduce complexity, delay, and increased risk of error. This constrains the Department’s ability to operate against threats at\nmachine speed across all domains.\n\nDoD also must improve skills in data fields necessary for effective data management. The Department must broaden efforts to assess our current talent, recruit new data experts, and retain our developing force while establishing policies to ensure that data talent is cultivated. We must also spend the time to increase the data acumen resident across the workforce and find optimal ways to promote a culture of data awareness."
  },
  {
    "objectID": "slides/rag-part1/index.html#chunking",
    "href": "slides/rag-part1/index.html#chunking",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "“Chunking”",
    "text": "“Chunking”\n\n“Chunkviz”"
  },
  {
    "objectID": "slides/rag-part1/index.html#chunking-with-overlap",
    "href": "slides/rag-part1/index.html#chunking-with-overlap",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "“Chunking” with Overlap",
    "text": "“Chunking” with Overlap\n\n“Chunkviz”"
  },
  {
    "objectID": "slides/rag-part1/index.html#smarter-chunking",
    "href": "slides/rag-part1/index.html#smarter-chunking",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Smarter “Chunking”",
    "text": "Smarter “Chunking”\n\nLangChain - Recursively Split by Character"
  },
  {
    "objectID": "slides/rag-part1/index.html#chunking-recursive-character-splitter",
    "href": "slides/rag-part1/index.html#chunking-recursive-character-splitter",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "“Chunking” recursive character splitter",
    "text": "“Chunking” recursive character splitter\n\n“Chunkviz”"
  },
  {
    "objectID": "slides/rag-part1/index.html#chunking-with-larger-segment-size",
    "href": "slides/rag-part1/index.html#chunking-with-larger-segment-size",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "“Chunking” with larger segment size",
    "text": "“Chunking” with larger segment size\n\n“Chunkviz”"
  },
  {
    "objectID": "slides/rag-part1/index.html#vector-indexing-of-the-chunks",
    "href": "slides/rag-part1/index.html#vector-indexing-of-the-chunks",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Vector Indexing of the “Chunks”",
    "text": "Vector Indexing of the “Chunks”\n\nfrom langchain_community.embeddings import FakeEmbeddings\nembeddings = FakeEmbeddings(size=1352)\nquery_result = embeddings.embed_query(dod_text)\nprint(dod_text[:5])\nquery_result[:5]\n\nDoD m\n\n\n\n\n[0.28925496400357076,\n 0.42954295410387294,\n -0.75042013219397,\n -0.21105104953004536,\n -0.655199848252018]\n\n\nFigure 1: Vector representation of the text"
  },
  {
    "objectID": "slides/rag-part1/index.html#failure-points-for-rag",
    "href": "slides/rag-part1/index.html#failure-points-for-rag",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Failure points for RAG",
    "text": "Failure points for RAG\n\nBarnett, Scott, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Abdelrazek. 2024. “Seven Failure Points When Engineering a Retrieval Augmented Generation System.”"
  },
  {
    "objectID": "slides/rag-part1/index.html#problem-a-global-constant-for-chunk-size-doesnt-take-into-account-the-semantic-structure-of-a-document.",
    "href": "slides/rag-part1/index.html#problem-a-global-constant-for-chunk-size-doesnt-take-into-account-the-semantic-structure-of-a-document.",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Problem: A global constant for Chunk Size doesn’t take into account the semantic structure of a document.",
    "text": "Problem: A global constant for Chunk Size doesn’t take into account the semantic structure of a document."
  },
  {
    "objectID": "slides/rag-part1/index.html#agentic-chunking",
    "href": "slides/rag-part1/index.html#agentic-chunking",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "“Agentic” Chunking",
    "text": "“Agentic” Chunking\n\nLangChain on X: Proposition-Based Retrieval"
  },
  {
    "objectID": "slides/rag-part1/index.html#agentic-example-proposition-based-dense-retrieval",
    "href": "slides/rag-part1/index.html#agentic-example-proposition-based-dense-retrieval",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Agentic Example: Proposition Based Dense Retrieval",
    "text": "Agentic Example: Proposition Based Dense Retrieval\n\nChen, Tong, Hongwei Wang, Sihao Chen, Wenhao Yu, Kaixin Ma, Xinran Zhao, Hongming Zhang, and Dong Yu. 2023. “Dense X Retrieval: What Retrieval Granularity Should We Use?” arXiv.Org. December 11, 2023. https://arxiv.org/abs/2312.06648v2."
  },
  {
    "objectID": "slides/rag-part1/index.html#rag-complexity-overview",
    "href": "slides/rag-part1/index.html#rag-complexity-overview",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "RAG Complexity Overview",
    "text": "RAG Complexity Overview\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2024. “Retrieval-Augmented Generation for Large Language Models: A Survey.” arXiv. https://doi.org/10.48550/arXiv.2312.10997."
  },
  {
    "objectID": "slides/rag-part1/index.html#comparison-with-other-optimization-methods",
    "href": "slides/rag-part1/index.html#comparison-with-other-optimization-methods",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Comparison with other optimization methods",
    "text": "Comparison with other optimization methods\n\nGao, Yunfan, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, et al. 2024. “Retrieval-Augmented Generation for Large Language Models: A Survey.” arXiv. https://doi.org/10.48550/arXiv.2312.10997."
  },
  {
    "objectID": "slides/rag-part1/index.html#llms-and-trusted-ai",
    "href": "slides/rag-part1/index.html#llms-and-trusted-ai",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "LLMs and Trusted AI",
    "text": "LLMs and Trusted AI\n\nSun, Lichao, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, et al. 2024. “TrustLLM: Trustworthiness in Large Language Models.” arXiv. http://arxiv.org/abs/2401.05561."
  },
  {
    "objectID": "slides/rag-part1/index.html#graph-based-vector-retrieval",
    "href": "slides/rag-part1/index.html#graph-based-vector-retrieval",
    "title": "Retrieval Augmented Generation – Part 1",
    "section": "Graph Based Vector Retrieval",
    "text": "Graph Based Vector Retrieval\n\nNeo4j Ontology Vectors"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned ML Website",
    "text": "Towards Trustworthy and Aligned ML Website\n\n\nTowards Trustworthy and Aligned ML"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#causal-reasoning",
    "href": "slides/trust-causal/index.html#causal-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Causal Reasoning",
    "text": "Causal Reasoning\n\n\nLearn more: Amazon Book of Why"
  },
  {
    "objectID": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "href": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "title": "Trust and Causal Reasoning",
    "section": "Trustworthy ML Initiative (TrustML)",
    "text": "Trustworthy ML Initiative (TrustML)\n\n\nLearn more: Trustworthy ML Org"
  },
  {
    "objectID": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "href": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "title": "Trust and Causal Reasoning",
    "section": "Gorilla API to Ground “Tool Use”",
    "text": "Gorilla API to Ground “Tool Use”\n\n\nLearn more: Gorilla: Large Language Model Connected with Massive APIs"
  },
  {
    "objectID": "slides/trust-causal/index.html#llama2-accessory",
    "href": "slides/trust-causal/index.html#llama2-accessory",
    "title": "Trust and Causal Reasoning",
    "section": "LLaMA2-Accessory",
    "text": "LLaMA2-Accessory\n\n\nLearn more: LLaMA2-Accessory"
  },
  {
    "objectID": "slides/trust-causal/index.html#multilingual-token-analysis",
    "href": "slides/trust-causal/index.html#multilingual-token-analysis",
    "title": "Trust and Causal Reasoning",
    "section": "MultiLingual Token Analysis",
    "text": "MultiLingual Token Analysis\n\n\nLearn more: Video: LLaMA2 Multilingual Models and Fine Tuning\nGoogle Collab Notebook:"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2",
    "href": "slides/trust-causal/index.html#metaai-dinov2",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2",
    "text": "MetaAI DINOv2\n\n\nLearn more: DINOv2 by Meta AI"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "href": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2 Huggingface Release",
    "text": "MetaAI DINOv2 Huggingface Release\n\n\nLearn more: DINOv2 by Meta AI Huggingface"
  },
  {
    "objectID": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "href": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "title": "Trust and Causal Reasoning",
    "section": "Example notebook for DINOv2 Semantic Segmentation",
    "text": "Example notebook for DINOv2 Semantic Segmentation\n\n\nLearn more: Linear probing of DINOv2 for semantic segmentation"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/nuggets_review/index.html#where-we-started",
    "href": "slides/nuggets_review/index.html#where-we-started",
    "title": "A Summer of Nuggets",
    "section": "Where we started…",
    "text": "Where we started…"
  },
  {
    "objectID": "slides/nuggets_review/index.html#where-were-going",
    "href": "slides/nuggets_review/index.html#where-were-going",
    "title": "A Summer of Nuggets",
    "section": "Where we’re going…",
    "text": "Where we’re going…\n\n\n\n\nAI Success Factors: Engineering Trust in Deployments"
  },
  {
    "objectID": "slides/nuggets_review/index.html#this-is-meant-to-provide-something-of-a-roadmap",
    "href": "slides/nuggets_review/index.html#this-is-meant-to-provide-something-of-a-roadmap",
    "title": "A Summer of Nuggets",
    "section": "This is meant to provide something of a “Roadmap”!",
    "text": "This is meant to provide something of a “Roadmap”!"
  },
  {
    "objectID": "slides/nuggets_review/index.html#video-link",
    "href": "slides/nuggets_review/index.html#video-link",
    "title": "A Summer of Nuggets",
    "section": "Video Link",
    "text": "Video Link"
  },
  {
    "objectID": "slides/nuggets_review/index.html#old-school-ai-and-the-web",
    "href": "slides/nuggets_review/index.html#old-school-ai-and-the-web",
    "title": "A Summer of Nuggets",
    "section": "“Old School AI” and the Web…",
    "text": "“Old School AI” and the Web…\n\n\nA vision of “Ontologies”, “Linked Data”, and “Software Agents”…\n\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. “The Semantic Web.” Scientific American 284, no. 5 (2001): 34–43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/nuggets_review/index.html#old-school-cool-ai-and-the-web-2001",
    "href": "slides/nuggets_review/index.html#old-school-cool-ai-and-the-web-2001",
    "title": "A Summer of Nuggets",
    "section": "Old School “Cool” AI and the Web (2001)…",
    "text": "Old School “Cool” AI and the Web (2001)…\n\n\nThe semantic web had a vision of Agents with Shared Understanding through Ontologies, the ability to Use Tools Like the Web and Consume a Web of Linked Data as Distibuted Knowledge Graphs.\n\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. “The Semantic Web.” Scientific American 284, no. 5 (2001): 34–43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/nuggets_review/index.html#whats-an-ontology",
    "href": "slides/nuggets_review/index.html#whats-an-ontology",
    "title": "A Summer of Nuggets",
    "section": "What’s an Ontology?",
    "text": "What’s an Ontology?\n\n\nTom Gruber. “Ontology.” In Encyclopedia of Database Systems, edited by Ling Liu and M. Tamer Özsu, 1–3. New York, NY: Springer, 2016. https://doi.org/10.1007/978-1-4899-7993-3_1318-2."
  },
  {
    "objectID": "slides/nuggets_review/index.html#ontology-design-patterns",
    "href": "slides/nuggets_review/index.html#ontology-design-patterns",
    "title": "A Summer of Nuggets",
    "section": "Ontology Design Patterns",
    "text": "Ontology Design Patterns\n\n\n\n\n\n\n\nEva Blomqvist, Pascal Hitzler, Krzysztof Janowicz, Adila Krisnadhi, Tom Narock, and Monika Solanki. “Considerations Regarding Ontology Design Patterns.” Semantic Web 7, no. 1 (November 10, 2015): 1–7. https://doi.org/10.3233/SW-150202."
  },
  {
    "objectID": "slides/nuggets_review/index.html#google-search-and-the-semantic-web",
    "href": "slides/nuggets_review/index.html#google-search-and-the-semantic-web",
    "title": "A Summer of Nuggets",
    "section": "Google Search and the “Semantic Web”",
    "text": "Google Search and the “Semantic Web”\n\n\n\n\n\n\n\nGoogle. “Introducing the Knowledge Graph: Things, Not Strings,” May 16, 2012. https://blog.google/products/search/introducing-knowledge-graph-things-not/.\nGoogle. “A Reintroduction to Our Knowledge Graph and Knowledge Panels,” May 20, 2020. https://blog.google/products/search/about-knowledge-graph-and-knowledge-panels/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs",
    "href": "slides/nuggets_review/index.html#knowledge-graphs",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs\n\n\n\n\n\n\n\nHogan, Aidan, Eva Blomqvist, Michael Cochez, Claudia d’Amato, Gerard de Melo, Claudio Gutiérrez, Sabrina Kirrane, et al. Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge 22. Springer, 2021. https://doi.org/10.2200/S01125ED1V01Y202109DSK022."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-1",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-1",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs\n\n\nWhat’s a Knowledge Graph?\n\n\n\n\nHogan, Aidan, Eva Blomqvist, Michael Cochez, Claudia d’Amato, Gerard de Melo, Claudio Gutiérrez, Sabrina Kirrane, et al. Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge 22. Springer, 2021. https://doi.org/10.2200/S01125ED1V01Y202109DSK022."
  },
  {
    "objectID": "slides/nuggets_review/index.html#ai-in-2023..",
    "href": "slides/nuggets_review/index.html#ai-in-2023..",
    "title": "A Summer of Nuggets",
    "section": "AI in 2023..",
    "text": "AI in 2023.."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-ai-social-disruption",
    "href": "slides/nuggets_review/index.html#the-ai-social-disruption",
    "title": "A Summer of Nuggets",
    "section": "The “AI Social Disruption”",
    "text": "The “AI Social Disruption”\n\n\n\n\nJames Gary, “AI – The Social Disruption”, AI Magazine 42, no. 1 (April 12, 2021), Cover."
  },
  {
    "objectID": "slides/nuggets_review/index.html#pretrained-foundation-models",
    "href": "slides/nuggets_review/index.html#pretrained-foundation-models",
    "title": "A Summer of Nuggets",
    "section": "Pretrained Foundation Models…",
    "text": "Pretrained Foundation Models…\n\n\n\n\nZhou, Ce, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, et al. “A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.” arXiv, May 1, 2023. https://doi.org/10.48550/arXiv.2302.09419."
  },
  {
    "objectID": "slides/nuggets_review/index.html#evolution-of-large-language-models",
    "href": "slides/nuggets_review/index.html#evolution-of-large-language-models",
    "title": "A Summer of Nuggets",
    "section": "Evolution of Large Language Models",
    "text": "Evolution of Large Language Models\n\n\n\n\nYang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. “Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.” arXiv, April 27, 2023. https://doi.org/10.48550/arXiv.2304.13712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformerattention-is-all-you-need",
    "href": "slides/nuggets_review/index.html#transformerattention-is-all-you-need",
    "title": "A Summer of Nuggets",
    "section": "Transformer:“Attention is all you need”",
    "text": "Transformer:“Attention is all you need”\n\n\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” arXiv, August 1, 2023. https://doi.org/10.48550/arXiv.1706.03762."
  },
  {
    "objectID": "slides/nuggets_review/index.html#explain-the-transformer-neural-network-architecture-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "href": "slides/nuggets_review/index.html#explain-the-transformer-neural-network-architecture-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "title": "A Summer of Nuggets",
    "section": "“Explain the transformer neural network architecture to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”",
    "text": "“Explain the transformer neural network architecture to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nAlright, let’s get into it! Imagine you’re at a party and you’re trying to catch snippets of multiple conversations. You’re not just listening to the words, but also noticing who’s talking to whom, the tone, the context, and you’re making judgments about what’s important or not. That’s kinda what the Transformer architecture does, but for sequences of data like sentences or time-series data.\nAt the core, a Transformer has two main parts: the Encoder and the Decoder. Each has multiple identical layers stacked on top of each other.\n\nEncoder: Takes in the sequence (like a sentence “Hello, how are you?”) and processes it as a whole. It outputs a sort of “summary” or “context” for each word in the sequence.\n\nSelf-Attention: Each word checks out all the other words and figures out which ones are important to it. The magic formula called attention scores helps in this.\nFeed-forward neural networks: After attention, each word passes through a mini neural network that’s the same for all words, transforming it yet again."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-1",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-1",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\n\nDecoder: Takes these encodings and starts generating the output sequence (say, a translation of the original sentence into another language).\n\nMasked Self-Attention: Similar to the encoder, but in a way that it can’t cheat and look at future words in the output sequence.\nEncoder-Decoder Attention: The decoder takes a peek at the encoder’s output to better understand the context and produce the correct next word.\nFeed-forward neural networks: Same drill as the encoder, another mini network for transforming words."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-2",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-2",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nSo the magic here is mainly in how words interact with each other through the attention mechanism. Each word looks at all the other words to decide how much focus it should get, like how you tune in to different voices at a party. It does this not once, but multiple times, diving deeper and deeper into the context each time.\nIt’s like a super-efficient assembly line for sequences, enabling models like me to generate text or translate languages at scale. And this architecture has been the basis for a lot of breakthroughs in natural language processing. It’s versatile, parallelizable, and mighty powerful!"
  },
  {
    "objectID": "slides/nuggets_review/index.html#some-llm-neural-networks-use-encoder-decoder-networks.-some-llm-neural-networks-are-encoder-only-and-some-are-decoder-only-like-gpt.-explain-that-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "href": "slides/nuggets_review/index.html#some-llm-neural-networks-use-encoder-decoder-networks.-some-llm-neural-networks-are-encoder-only-and-some-are-decoder-only-like-gpt.-explain-that-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "title": "A Summer of Nuggets",
    "section": "“Some LLM Neural Networks use encoder-decoder networks. Some LLM neural networks are encoder only and some are decoder only like GPT. Explain that to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”",
    "text": "“Some LLM Neural Networks use encoder-decoder networks. Some LLM neural networks are encoder only and some are decoder only like GPT. Explain that to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-3",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-3",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nAh, good question! Think of it like this: you’ve got three types of orchestras. One plays both classical and jazz seamlessly (encoder-decoder), another specializes only in classical (encoder), and the last one is all about that jazz (decoder).\n\nEncoder-Decoder Networks: These are like your all-rounder orchestras. In the machine learning world, these models are often used for tasks like machine translation. The encoder part processes the input language, let’s say, English, and the decoder part spits out the output in another language, maybe Spanish. They work together like a well-conducted orchestra, each contributing to the final masterpiece.\nEncoder-Only Networks: Imagine an orchestra that’s focused entirely on classical music, where each musician feeds into the other to create a beautiful symphony. In tech, these models are good for tasks like text classification or sentiment analysis. The encoder processes the text and summarizes it in a way that lets you say, “Ah, this review is positive!”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-4",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-4",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\n\nDecoder-Only Networks: Now, these are your jazz specialists, all about improvisation and solos. GPT models, like the one you’re talking to, belong to this category. The decoder starts with a seed (your prompt) and keeps generating one word at a time, predicting the next best word until it forms a coherent reply. It doesn’t need to look back at an original input sentence like in translation; it just jams out text based on what it has learned during its training.\n\nSo, you’ve got different setups for different gigs. If you need a two-way conversation between languages, you go for the encoder-decoder. If you want to understand the essence of a piece of text, you’d lean on the encoder. And if you want to generate text, like writing or even code, the decoder is your go-to musician. Each has its own style, its own instruments, and its own unique approach to making beautiful “music”—or in our case, useful computations."
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-do-these-relate-to-the-transformer-architecture",
    "href": "slides/nuggets_review/index.html#how-do-these-relate-to-the-transformer-architecture",
    "title": "A Summer of Nuggets",
    "section": "“How do these relate to the Transformer architecture”",
    "text": "“How do these relate to the Transformer architecture”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-5",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-5",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nGreat follow-up! Alright, think of the Transformer architecture as a fancy new instrument—a versatile electric guitar, let’s say, that can produce a whole range of sounds from classical to rock to jazz. Now, just like you can use that electric guitar in different types of bands, you can use parts of the Transformer architecture in different types of models.\n\nEncoder-Decoder Networks with Transformers: When people initially talked about Transformers, they were often referring to the full shebang—both encoder and decoder. In a language translation model, the Transformer’s encoder reads an English sentence and compresses its essence. The decoder then takes this essence and generates a Spanish sentence. Both sides are using self-attention, layer normalization, and all those Transformer goodies to do their jobs.\nEncoder-Only Transformers: In some tasks, you don’t need the full band; a guitar solo will do. For instance, BERT (Bidirectional Encoder Representations from Transformers) uses just the encoder part of the Transformer architecture. It processes a sentence and spits out a rich, contextual representation of each word, which can then be used for tasks like text classification or filling in blanks.\nDecoder-Only Transformers: Now, what if we only want to jam and improvise? That’s where models like GPT (Generative Pre-trained Transformer) come in. These models use only the decoder part of the Transformer architecture to generate new text. They still use self-attention and feed-forward layers, but they are more about predicting the next note—or in our case, the next word—in a sequence."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-6",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-6",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nSo there you go! Just like our versatile electric guitar can be part of a full orchestra, a rock band, or a solo act, different pieces of the Transformer architecture can be used to construct different kinds of neural network models. Each specialized version takes the core principles of the Transformer and applies them in a way that’s tailored to specific tasks."
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-to-build-a-chatgpt",
    "href": "slides/nuggets_review/index.html#how-to-build-a-chatgpt",
    "title": "A Summer of Nuggets",
    "section": "How to Build a ChatGPT?",
    "text": "How to Build a ChatGPT?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt-you-should-watch-this",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt-you-should-watch-this",
    "title": "A Summer of Nuggets",
    "section": "“The state of GPT” – You should watch this!",
    "text": "“The state of GPT” – You should watch this!\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt",
    "title": "A Summer of Nuggets",
    "section": "“The state of GPT”",
    "text": "“The state of GPT”\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-from-a-more-general-view",
    "href": "slides/nuggets_review/index.html#large-language-models-from-a-more-general-view",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models from a more general view…",
    "text": "Large Language Models from a more general view…\n\n\n\n\n“Making Large Language Models Work for You.” Accessed August 27, 2023. https://simonwillison.net/2023/Aug/27/wordcamp-llms/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#text-to-numbers",
    "href": "slides/nuggets_review/index.html#text-to-numbers",
    "title": "A Summer of Nuggets",
    "section": "Text to numbers…",
    "text": "Text to numbers…\n\n\n\n\n“Tiktokenizer.” Accessed August 27, 2023. https://tiktokenizer.vercel.app/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt",
    "href": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt",
    "title": "A Summer of Nuggets",
    "section": "Base models create general representations through “Pre-Training” (GPT)",
    "text": "Base models create general representations through “Pre-Training” (GPT)\n\n\n\n\nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” n.d."
  },
  {
    "objectID": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt-1",
    "href": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt-1",
    "title": "A Summer of Nuggets",
    "section": "Base models create general representations through “Pre-Training” (GPT)",
    "text": "Base models create general representations through “Pre-Training” (GPT)\n\n\n\n\nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” n.d."
  },
  {
    "objectID": "slides/nuggets_review/index.html#pre-training-datasets",
    "href": "slides/nuggets_review/index.html#pre-training-datasets",
    "title": "A Summer of Nuggets",
    "section": "“Pre-Training Datasets?”",
    "text": "“Pre-Training Datasets?”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models",
    "href": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models",
    "title": "A Summer of Nuggets",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, et al. “LLaMA: Open and Efficient Foundation Language Models.” arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models-1",
    "href": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models-1",
    "title": "A Summer of Nuggets",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, et al. “LLaMA: Open and Efficient Foundation Language Models.” arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gao-et-al.-the-pile",
    "href": "slides/nuggets_review/index.html#gao-et-al.-the-pile",
    "title": "A Summer of Nuggets",
    "section": "Gao et al. “The Pile”?",
    "text": "Gao et al. “The Pile”?\n\n\n\n\n \n\n\nGao, Leo, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, et al. “The Pile: An 800GB Dataset of Diverse Text for Language Modeling.” arXiv, December 31, 2020. https://doi.org/10.48550/arXiv.2101.00027."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gao-et-al.-the-pile-1",
    "href": "slides/nuggets_review/index.html#gao-et-al.-the-pile-1",
    "title": "A Summer of Nuggets",
    "section": "Gao et al. “The Pile”?",
    "text": "Gao et al. “The Pile”?\n\n\n\n\n \n\n\nGao, Leo, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, et al. “The Pile: An 800GB Dataset of Diverse Text for Language Modeling.” arXiv, December 31, 2020. https://doi.org/10.48550/arXiv.2101.00027."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong-1",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong-1",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\n\n\n\n“Sarah Silverman Sues OpenAI and Meta Alleging Copyright Infringement | CNN Business.” Accessed August 27, 2023. https://www.cnn.com/2023/07/10/tech/sarah-silverman-openai-meta-lawsuit/index.html."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong-2",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong-2",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\n\n\n\n“Would I forbid the teaching (if that is the word) of my stories to computers? Not even if I could. I might as well be King Canute, forbidding the tide to come in. Or a Luddite trying to stop industrial progress by hammering a steam loom to pieces.” – Stephen King\n\n\nReisner, Alex. “Revealed: The Authors Whose Pirated Books Are Powering Generative AI.” The Atlantic, August 19, 2023. https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/.\nKing, Stephen. “Stephen King: My Books Were Used to Train AI.” The Atlantic, August 23, 2023. https://www.theatlantic.com/books/archive/2023/08/stephen-king-books-ai-writing/675088/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-language-models-are-few-shot-learners-2020",
    "href": "slides/nuggets_review/index.html#gpt-3-language-models-are-few-shot-learners-2020",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Language Models are Few-Shot Learners (2020)",
    "text": "(GPT-3) Language Models are Few-Shot Learners (2020)\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. “Language Models Are Few-Shot Learners.” arXiv, July 22, 2020. https://doi.org/10.48550/arXiv.2005.14165."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-in-context-learning",
    "href": "slides/nuggets_review/index.html#gpt-3-in-context-learning",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) In-Context Learning",
    "text": "(GPT-3) In-Context Learning\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. “Language Models Are Few-Shot Learners.” arXiv, July 22, 2020. https://doi.org/10.48550/arXiv.2005.14165."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "href": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. “Training Language Models to Follow Instructions with Human Feedback.” arXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback-1",
    "href": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. “Training Language Models to Follow Instructions with Human Feedback.” arXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nBubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-1",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nBubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-2",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-2",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nBubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-3",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-3",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nSparks of AGI: Early Experiments with GPT-4, 2023. https://www.youtube.com/watch?v=qbIk7-JPB2c."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llm-behavior-changes-with-time",
    "href": "slides/nuggets_review/index.html#llm-behavior-changes-with-time",
    "title": "A Summer of Nuggets",
    "section": "LLM Behavior Changes with Time!",
    "text": "LLM Behavior Changes with Time!\n\n\n\n\nChen, Lingjiao, Matei Zaharia, and James Zou. “How Is ChatGPT’s Behavior Changing over Time?” arXiv, July 18, 2023. http://arxiv.org/abs/2307.09009."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-towards-truthgpt",
    "href": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-towards-truthgpt",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) OpenAI Reinforcement Learning – “Towards TruthGPT”",
    "text": "(GPT-4) OpenAI Reinforcement Learning – “Towards TruthGPT”\n\n\n\n\nJohn Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges, 2023. https://www.youtube.com/watch?v=hhiLw5Q_UFg."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-conceptual-models",
    "href": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-conceptual-models",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) OpenAI Reinforcement Learning – “Conceptual Models”",
    "text": "(GPT-4) OpenAI Reinforcement Learning – “Conceptual Models”\n\n\n\n\nJohn Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges, 2023. https://www.youtube.com/watch?v=hhiLw5Q_UFg."
  },
  {
    "objectID": "slides/nuggets_review/index.html#claude-constitutional-ai",
    "href": "slides/nuggets_review/index.html#claude-constitutional-ai",
    "title": "A Summer of Nuggets",
    "section": "(Claude) “Constitutional AI”",
    "text": "(Claude) “Constitutional AI”\n\n\n\n\nAnthropic. “Claude’s Constitution.” Accessed August 28, 2023. https://www.anthropic.com/index/claudes-constitution.\nBai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, et al. “Constitutional AI: Harmlessness from AI Feedback.” arXiv, December 15, 2022. https://doi.org/10.48550/arXiv.2212.08073."
  },
  {
    "objectID": "slides/nuggets_review/index.html#claude-foundation-model-in-aws-bedrock",
    "href": "slides/nuggets_review/index.html#claude-foundation-model-in-aws-bedrock",
    "title": "A Summer of Nuggets",
    "section": "(Claude) “Foundation Model in AWS Bedrock”",
    "text": "(Claude) “Foundation Model in AWS Bedrock”\n\n\n\n\n\n\n\nAnthropic. “Claude 2.” Accessed August 28, 2023. https://www.anthropic.com/index/claude-2.\nAnthropic. “Claude 2 on Amazon Bedrock.” Accessed August 28, 2023. https://www.anthropic.com/index/claude-2-amazon-bedrock."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-2open-license-large-language-models",
    "href": "slides/nuggets_review/index.html#llama-2open-license-large-language-models",
    "title": "A Summer of Nuggets",
    "section": "(Llama 2)“Open-License” Large Language Models",
    "text": "(Llama 2)“Open-License” Large Language Models\n\n\n\n\nMeta AI. “Meta and Microsoft Introduce the Next Generation of Llama.” Accessed August 28, 2023. https://ai.meta.com/blog/llama-2/.\nMeta AI. “Llama 2.” Accessed August 28, 2023. https://ai.meta.com/llama-project."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt-recommendations",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt-recommendations",
    "title": "A Summer of Nuggets",
    "section": "“The state of GPT” Recommendations",
    "text": "“The state of GPT” Recommendations\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#reasoning",
    "href": "slides/nuggets_review/index.html#reasoning",
    "title": "A Summer of Nuggets",
    "section": "Reasoning…",
    "text": "Reasoning…"
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "href": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. “Large Language Models Are Zero-Shot Reasoners.” arXiv, January 29, 2023. https://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning-1",
    "href": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. “Large Language Models Are Zero-Shot Reasoners.” arXiv, January 29, 2023. https://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\n“ReAct: Synergizing Reasoning and Acting in Language Models.” Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. “ReAct: Synergizing Reasoning and Acting in Language Models.” arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-1",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-1",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\n“ReAct: Synergizing Reasoning and Acting in Language Models.” Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. “ReAct: Synergizing Reasoning and Acting in Language Models.” arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-2",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-2",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\n“ReAct: Synergizing Reasoning and Acting in Language Models.” Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. “ReAct: Synergizing Reasoning and Acting in Language Models.” arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#prompt-engineering",
    "href": "slides/nuggets_review/index.html#prompt-engineering",
    "title": "A Summer of Nuggets",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n\n\n\n\n“Prompt Engineering Guide.” Accessed August 22, 2023. https://www.promptingguide.ai/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners",
    "href": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models are Semantic Reasoners",
    "text": "Large Language Models are Semantic Reasoners\n\n\n\n\nTang, Xiaojuan, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. “Large Language Models Are In-Context Semantic Reasoners Rather than Symbolic Reasoners.” arXiv, June 8, 2023. http://arxiv.org/abs/2305.14825."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners-1",
    "href": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners-1",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models are Semantic Reasoners",
    "text": "Large Language Models are Semantic Reasoners\n\n\n\n\n\n\n\nTang, Xiaojuan, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. “Large Language Models Are In-Context Semantic Reasoners Rather than Symbolic Reasoners.” arXiv, June 8, 2023. http://arxiv.org/abs/2305.14825."
  },
  {
    "objectID": "slides/nuggets_review/index.html#our-research",
    "href": "slides/nuggets_review/index.html#our-research",
    "title": "A Summer of Nuggets",
    "section": "Our Research…",
    "text": "Our Research…"
  },
  {
    "objectID": "slides/nuggets_review/index.html#retrevial-augmented-generation",
    "href": "slides/nuggets_review/index.html#retrevial-augmented-generation",
    "title": "A Summer of Nuggets",
    "section": "Retrevial Augmented Generation",
    "text": "Retrevial Augmented Generation"
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-and-llms-must-read",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-and-llms-must-read",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs and LLMs – Must Read!",
    "text": "Knowledge Graphs and LLMs – Must Read!\n\n\n\n\nPan, Shirui, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-and-frameworks",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-and-frameworks",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs and Frameworks",
    "text": "Knowledge Graphs and Frameworks\n\n\n\n\nPan, Shirui, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-about-trusted-ai",
    "href": "slides/nuggets_review/index.html#what-about-trusted-ai",
    "title": "A Summer of Nuggets",
    "section": "What About Trusted AI?",
    "text": "What About Trusted AI?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-to-talk-about-llms-must-read",
    "href": "slides/nuggets_review/index.html#how-to-talk-about-llms-must-read",
    "title": "A Summer of Nuggets",
    "section": "How to talk about LLMs? Must Read!",
    "text": "How to talk about LLMs? Must Read!\n\n\n\n\nShanahan, Murray. “Talking About Large Language Models.” arXiv, February 16, 2023. https://doi.org/10.48550/arXiv.2212.03551."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to “translational research,” a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your “About” page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "href": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to “translational research,” a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your “About” page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#our-toolset",
    "href": "about.html#our-toolset",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Our Toolset",
    "text": "Our Toolset\nAI Success Factors: Engineering Trust in Deployments is more than just a blog - it’s a demonstration of how modern data science tools can streamline and simplify complex processes.\nOur blogging platform is built using Quarto, an open-source scientific and technical publishing system known for its flexibility and robustness. Quarto has the unique ability to support a wide range of content types, including Jupyter notebooks, R Markdown, and even Python or R scripts. Quarto’s distinctive feature is its ability to include executable code within the documents from various languages such as Python, R, and others. This allows us to create data-driven blog posts where the output - be it a graph, a table, or other data representations - is generated directly from the included code. This adds an interactive element to our posts, giving readers a deeper understanding of the concepts and analyses presented. Quarto supports multiple output formats including HTML, PDF, EPUB, and Word, providing us the versatility to tailor our content to suit different needs. This flexible tool, coupled with its capability to handle larger projects made up of multiple files, allows us to efficiently manage our blog while maintaining consistency and quality across our posts. Quarto presentations are also used to generate revealjs presentations for weekly slide shows. Quarto forms the basis for Fast.ai’s nbdev framework for exploritory programming allowing for software development in Jupyter Notebooks and automated generation of Python modules and documentation from the notebooks.\nDevelopment Containers serve as our primary environment for data science, providing a consistent and replicable framework for running our analyses. These containerized environments allow us to standardize our work and ensure that our research is reproducible and reliable. The dev container uses the Mamba solver to provision the python environment from the specification in the environment.yml.\nWe use Visual Studio Code (VS Code) as our primary code editor, taking advantage of its rich ecosystem of extensions and in-built features. VS Code’s Jupyter notebook support allows us to interactively develop and visualize our data models directly within the editor, enabling us to produce intuitive, data-driven narratives for our blog posts.\nAll of our content is version controlled and hosted on GitHub. GitHub’s robust versioning system allows us to effectively manage changes, track progress, and ensure that every piece of content we publish is up to date and accurate.\nThe blog is published using GitHub Page, a platform that simplifies the deployment process and seamlessly integrates with our existing GitHub repository. This setup enables us to provide a reliable, accessible resource for our readers, irrespective of where they are or when they choose to access our content.\nFinally, we utilize GitHub Code Spaces to create a fully-featured, cloud-hosted development environment that can be accessed from any device. This not only allows us to work from anywhere but also ensures that our setup can be easily replicated by other researchers and developers who wish to explore our code.\nEach tool in our stack has been chosen for its ability to facilitate efficient, reliable, and transparent data science. By sharing our toolset, we hope to provide insight into our workflows and encourage a culture of open, reproducible research within the AI community."
  },
  {
    "objectID": "about.html#generative-ai-in-content-creation",
    "href": "about.html#generative-ai-in-content-creation",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Generative AI in Content Creation",
    "text": "Generative AI in Content Creation\nIn creating AI Success Factors: Engineering Trust in Deployments, we harness the power of artificial intelligence in conjunction with human expertise. We utilize advanced Generative AI models such as ChatGPT, Bing Chat, and Anthropic Claude in a guided, iterative process that combines the best of AI and human capabilities.\nOur use of Generative AI begins with the drafting stage. These models, trained on extensive datasets, generate human-like text that matches our specified tone and style, providing us with a solid foundation for each blog post. This allows us to focus on the larger narrative without getting mired in the nitty-gritty details from the outset.\nThe AI-generated drafts, while sophisticated, are just the starting point. We employ a methodology that involves guiding the AI to improve its output. This includes providing more detailed prompts, specifying the format we want the output in, or asking the model to think step-by-step before settling on a conclusion.\nOnce we have a draft that we’re satisfied with, it’s time for human intervention. Our team reviews the AI-generated content, refining and editing it to ensure it maintains the standards of accuracy, relevance, and depth that our readers expect. This process leverages critical human skills of creativity, critical thinking, and domain expertise that even the most advanced AI can’t replicate.\nThis approach exemplifies our vision of a symbiotic relationship between AI and humans. By effectively integrating Generative AI into our content creation process, we not only boost our productivity and efficiency but also demonstrate the practical application of AI technologies in real-world scenarios. Thus, the blog becomes a testament to our commitment to translational research and our pursuit of an AI-integrated future."
  },
  {
    "objectID": "slides/tools_sept24/index.html#prompt-engineering",
    "href": "slides/tools_sept24/index.html#prompt-engineering",
    "title": "Tools for Building Agentic Systems",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n\nAnthropic Prompt Engineering Tutorial"
  },
  {
    "objectID": "slides/tools_sept24/index.html#anthropic-prompt-engineering-tutorial",
    "href": "slides/tools_sept24/index.html#anthropic-prompt-engineering-tutorial",
    "title": "Tools for Building Agentic Systems",
    "section": "Anthropic Prompt Engineering Tutorial",
    "text": "Anthropic Prompt Engineering Tutorial\n\nPrompt Engineering Interactive Tutorial"
  },
  {
    "objectID": "slides/tools_sept24/index.html#openai-playground",
    "href": "slides/tools_sept24/index.html#openai-playground",
    "title": "Tools for Building Agentic Systems",
    "section": "OpenAI Playground",
    "text": "OpenAI Playground\n\nOpenAI Playground"
  },
  {
    "objectID": "slides/tools_sept24/index.html#agentic-patterns",
    "href": "slides/tools_sept24/index.html#agentic-patterns",
    "title": "Tools for Building Agentic Systems",
    "section": "Agentic Patterns",
    "text": "Agentic Patterns\n\nAgentic Workflows"
  },
  {
    "objectID": "slides/tools_sept24/index.html#berkeley-agents-course",
    "href": "slides/tools_sept24/index.html#berkeley-agents-course",
    "title": "Tools for Building Agentic Systems",
    "section": "Berkeley Agents Course",
    "text": "Berkeley Agents Course\n\nAgents Course HomepageYoutube Playlist"
  },
  {
    "objectID": "slides/tools_sept24/index.html#genai-agents-comprehensive-repository-for-development-and-implementation",
    "href": "slides/tools_sept24/index.html#genai-agents-comprehensive-repository-for-development-and-implementation",
    "title": "Tools for Building Agentic Systems",
    "section": "GenAI Agents: Comprehensive Repository for Development and Implementation",
    "text": "GenAI Agents: Comprehensive Repository for Development and Implementation\n\nGenAI Agents"
  },
  {
    "objectID": "slides/tools_sept24/index.html#choosing-between-software-frameworks-for-agents",
    "href": "slides/tools_sept24/index.html#choosing-between-software-frameworks-for-agents",
    "title": "Tools for Building Agentic Systems",
    "section": "Choosing Between Software Frameworks for Agents",
    "text": "Choosing Between Software Frameworks for Agents\n\nChoosing Between LLM Agent Frameworks\nGitHub Repo"
  },
  {
    "objectID": "slides/tools_sept24/index.html#introspection-and-observability",
    "href": "slides/tools_sept24/index.html#introspection-and-observability",
    "title": "Tools for Building Agentic Systems",
    "section": "Introspection and Observability",
    "text": "Introspection and Observability"
  },
  {
    "objectID": "slides/tools_sept24/index.html#phoenix",
    "href": "slides/tools_sept24/index.html#phoenix",
    "title": "Tools for Building Agentic Systems",
    "section": "Phoenix",
    "text": "Phoenix\n\nArize Phoenix AI Observability and Evaluation"
  },
  {
    "objectID": "slides/tools_sept24/index.html#langfuse",
    "href": "slides/tools_sept24/index.html#langfuse",
    "title": "Tools for Building Agentic Systems",
    "section": "LangFuse",
    "text": "LangFuse\n\nOpen Source LLM Engineering Platform"
  },
  {
    "objectID": "slides/tools_sept24/index.html#papers-this-week",
    "href": "slides/tools_sept24/index.html#papers-this-week",
    "title": "Tools for Building Agentic Systems",
    "section": "Papers this week",
    "text": "Papers this week"
  },
  {
    "objectID": "slides/tools_sept24/index.html#reasoning-agents",
    "href": "slides/tools_sept24/index.html#reasoning-agents",
    "title": "Tools for Building Agentic Systems",
    "section": "Reasoning Agents",
    "text": "Reasoning Agents\n\nCrispino, Nicholas, Kyle Montgomery, Fankun Zeng, Dawn Song, and Chenguang Wang. 2024. “Agent Instructs Large Language Models to Be General Zero-Shot Reasoners.” arXiv. http://arxiv.org/abs/2310.03710."
  },
  {
    "objectID": "slides/tools_sept24/index.html#now-for-the-bad-new",
    "href": "slides/tools_sept24/index.html#now-for-the-bad-new",
    "title": "Tools for Building Agentic Systems",
    "section": "Now for the bad new",
    "text": "Now for the bad new"
  },
  {
    "objectID": "slides/tools_sept24/index.html#llms-still-cant-plan",
    "href": "slides/tools_sept24/index.html#llms-still-cant-plan",
    "title": "Tools for Building Agentic Systems",
    "section": "LLMs (Still) Can’t Plan",
    "text": "LLMs (Still) Can’t Plan\n\nValmeekam, Karthik, Kaya Stechly, and Subbarao Kambhampati. 2024. “LLMs Still Can’t Plan.” arXiv. http://arxiv.org/abs/2409.13373"
  },
  {
    "objectID": "slides/tools_sept24/index.html#gpt-4o1-does-better-at-a-cost",
    "href": "slides/tools_sept24/index.html#gpt-4o1-does-better-at-a-cost",
    "title": "Tools for Building Agentic Systems",
    "section": "GPT-4o1 Does Better at a Cost",
    "text": "GPT-4o1 Does Better at a Cost\n\n\n\nValmeekam, Karthik, Kaya Stechly, and Subbarao Kambhampati. 2024. “LLMs Still Can’t Plan.” arXiv. http://arxiv.org/abs/2409.13373\n\n\n\n\n\n\nhttps://la3d.github.io/nuggets/\n\n\n\n\n\n\n\n \n\n\nLaboratory for Assured AI Application Development (LA3D)"
  },
  {
    "objectID": "slides/tools_sept24/index.html#now-for-the-bad-news",
    "href": "slides/tools_sept24/index.html#now-for-the-bad-news",
    "title": "Tools for Building Agentic Systems",
    "section": "Now for the bad news",
    "text": "Now for the bad news"
  }
]
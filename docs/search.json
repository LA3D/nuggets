[
  {
    "objectID": "instruction_prompt.html",
    "href": "instruction_prompt.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "ChatGPT, please assist in drafting a blog post for AI Success Factors: Engineering Trust in Deployments. As a generative AI, your input serves as a starting point for discussion and is meticulously reviewed and edited by a team of AI researchers at the Laboratory for Assured AI Applications Development at the University of Notre Dame’s Center for Research Computing.\nThe intended audience includes students, professionals, and enthusiasts interested in the progression of AI, with a focus on the successful deployment of AI technologies. Each post aims to disseminate recent advancements and knowledge in AI, particularly in the fields of AI engineering, trust in AI, and knowledge engineering.\nFor this post, please generate content on the importance of trust in successful AI deployments. Begin with a general introduction to AI deployments, transition into the crucial role of trust, and provide real-world examples where the absence of trust led to issues. Discuss strategies for building trust in AI systems and conclude with insights on future trends in trust within the AI landscape. The tone should be academic yet accessible to our diverse readership."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "href": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing and CI/CD for Trusted AI",
    "text": "Testing and CI/CD for Trusted AI\nTesting and CI/CD are software engineering practices that aim to ensure the quality, reliability, and security of software applications. They are especially important for AI applications, which involve complex and dynamic data, models, and algorithms."
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "href": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What is Software 1.0 and Software 2.0?",
    "text": "What is Software 1.0 and Software 2.0?\nSoftware 1.0 refers to the traditional way of developing software by writing code that specifies the logic and rules of the application. Software 2.0 refers to the emerging way of developing software by using machine learning (ML) models that learn from data and generate code or behavior."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why do we need testing and CI/CD for AI?",
    "text": "Why do we need testing and CI/CD for AI?\nAI applications pose unique challenges and risks for testing and CI/CD, such as:\n\nData quality and availability: AI applications depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: AI models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: AI applications may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "href": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing and CI/CD can help address these challenges and risks by:",
    "text": "Testing and CI/CD can help address these challenges and risks by:\n\nAutomating and streamlining the data, model, and code workflows of AI development\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in AI applications\nEnsuring that AI applications meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of AI applications"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How do we implement testing and CI/CD for AI?",
    "text": "How do we implement testing and CI/CD for AI?\nTesting and CI/CD for AI involve applying software engineering best practices to the data, model, and code components of AI applications. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing AI models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of AI models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates AI models"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Real World Machine Learning “Pipelines”",
    "text": "Real World Machine Learning “Pipelines”\n\n\nTwitter: Andrej Karpathy\nLearn More: Autonomous Vehicle Training & Tesla’s Data Engine Explained, TESLA’S DATA ENGINE AND WHAT WE SHOULD LEARN FROM IT CVPR’20 Workshop on Scalability in Autonomous Driving Keynote - Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Real World Machine Learning “Data Engine”",
    "text": "Real World Machine Learning “Data Engine”\n\n\nTwitter: Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "href": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How Tesla’s Data Engine works",
    "text": "How Tesla’s Data Engine works\n\nThe FSD computer in each Tesla car records and sends any inaccuracies or discrepancies between its actions and the human driver’s actions to Tesla’s servers.\nTesla’s servers use these inaccuracies to create unit tests, which are scenarios that the FSD neural network should be able to handle correctly.\nTesla’s servers also use these inaccuracies to search for similar situations in the vast amount of data collected from all the cars in the fleet and create a well-labeled dataset.\nTesla’s servers use this dataset to re-train the FSD neural network using machine learning algorithms and improve its performance and functionality.\nTesla’s servers deploy the updated FSD neural network to the cars’ FSD computers in “shadow mode” to compare its actions with the human driver’s actions."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "href": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why Tesla’s Data Engine matters",
    "text": "Why Tesla’s Data Engine matters\n\nTesla’s Data Engine allows them to leverage the power of big data analytics and artificial intelligence in their self-driving cars.\nTesla’s Data Engine enables them to address the long tail problem of autonomous driving, which is the challenge of handling rare or complex situations on the road.\nTesla’s Data Engine ensures that the FSD neural network is constantly improving and not regressing or introducing new errors.\n\n\nLearn More: [Tesla’s Data Engine and what we should learn from it]"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "href": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What is “Testing” for AI vs Traditional Software Testing",
    "text": "What is “Testing” for AI vs Traditional Software Testing\n\n\nLearn More: Effective testing for machine learning systems\nYoutube Discussion: MLOps Chat: How Should We Test ML Models? with Data Scientist Jeremy Jordan"
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why do we need testing for ML systems?",
    "text": "Why do we need testing for ML systems?\nML systems pose unique challenges and risks for testing, such as:\n\nData quality and availability: ML systems depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: ML models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: ML systems may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability.\n\nTesting ML systems can help address these challenges and risks by:\n\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in ML systems\nEnsuring that ML systems meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of ML systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "href": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How do we test ML systems?",
    "text": "How do we test ML systems?\nTesting ML systems involves applying software engineering best practices to the data, model, and code components of ML systems. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing ML models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of ML models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates ML models"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "href": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What are some tools and techniques for testing ML systems?",
    "text": "What are some tools and techniques for testing ML systems?\nThere are different tools and techniques that can help us test ML systems effectively and efficiently. Some examples are:\n\nData validation tools: Tools that help us check the schema, statistics, anomalies, drifts, and distributions of our data. For example: TensorFlow Data Validation, Great Expectations, Deequ.\nModel validation tools: Tools that help us measure the performance of our models on various metrics and scenarios. For example: TensorFlow Model Analysis, Scikit-Learn, PyTorch.\nCode validation tools: Tools that help us check the syntax, style, coverage, complexity, and security of our code. For example: PyLint, PyTest, Bandit."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "href": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing “Software 1.0” vs “Software 2.0”",
    "text": "Testing “Software 1.0” vs “Software 2.0”\n\n\nLearn More: Effective testing for machine learning systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "href": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "“Beyond Accuracy: Behavioral Testing of NLP Models with CheckList”",
    "text": "“Beyond Accuracy: Behavioral Testing of NLP Models with CheckList”\n\n\nLearn More: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\nGitHub:Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Examples of “real world” testing",
    "text": "Examples of “real world” testing\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Examples of “real world” testing as a starting point",
    "text": "Examples of “real world” testing as a starting point\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "href": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Test Structure in the Microsoft Recommenders",
    "text": "Test Structure in the Microsoft Recommenders\nThe Microsoft Recommenders repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repository also includes various tests to ensure the quality, reliability, and security of the code and the notebooks."
  },
  {
    "objectID": "slides/tai_testing/index.html#types-of-tests",
    "href": "slides/tai_testing/index.html#types-of-tests",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Types of Tests",
    "text": "Types of Tests\nThere are three types of tests in the Microsoft Recommenders repository:\n\nUnit tests: These are tests that check the functionality and correctness of individual modules, functions, or classes. They are located in the unit folder and use pytest as the testing framework. They are triggered by pull requests to the main or staging branches.\nSmoke tests: These are tests that check if the notebooks can run without errors and produce the expected outputs. They are located in the smoke folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches.\nIntegration tests: These are tests that check if the notebooks can run end-to-end on different environments and platforms, such as CPU, GPU, or Spark. They are located in the integration folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Azure DevOps",
    "text": "Testing Infrastructure: Azure DevOps\nThe Microsoft Recommenders repository uses Azure DevOps as the testing infrastructure. Azure DevOps is a cloud-based platform that provides various services and tools for software development, such as version control, project management, testing, deployment, and monitoring.\nThere are 19 pipelines for Linux tests and 19 pipelines for Windows tests, each corresponding to a different type of test, branch, and environment. For example:\n\nunit_tests: This pipeline runs unit tests on Linux CPU for pull requests to the main branch.\nunit_tests_staging: This pipeline runs unit tests on Linux CPU for pull requests to the staging branch.\ngpu_unit_tests: This pipeline runs unit tests on Linux GPU for pull requests to the main branch.\ngpu_unit_tests_staging: This pipeline runs unit tests on Linux GPU for pull requests to the staging branch.\nnightly_cpu: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the main branch.\nnightly_staging: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the staging branch.\nnightly_gpu: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the main branch.\nnightly_gpu_staging: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the staging branch.\nnightly_spark: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the main branch.\nnightly_spark_staging: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the staging branch.\n\n\nLearn More: [Test Strategy · microsoft/recommenders Wiki · GitHub]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "href": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Conda Environments",
    "text": "Testing Infrastructure: Conda Environments\nThe pipelines use conda environments to manage dependencies and run tests. Conda is an open-source package and environment management system that allows us to create and use different configurations of software packages and libraries.\nA script, generate_conda_file.py, is used to create conda environments for different combinations of CPU, GPU, and Spark. For example:\n\nreco_base: This is the basic CPU environment.\nreco_full: This is the environment that includes CPU, GPU, and Spark.\nreco_gpu: This is the environment that includes CPU and GPU.\nreco_pyspark: This is the environment that includes CPU and Spark.\n\n\nLearn More: [Conda — Conda documentation]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Azure Machine Learning",
    "text": "Testing Infrastructure: Azure Machine Learning\nThe pipelines also use Azure Machine Learning (AML) to run some of the tests on different compute clusters. AML is a cloud-based service that provides various tools and features for ML development, such as data preparation, model training, model deployment, model management, and model monitoring.\nAML provides scalable and flexible compute resources for ML development. For example:\n\nAMLCompute clustername Experiment VM Nodes\nreco-cpu-test2 cpu_unit_tests standard_d3_v2 0..4\nreco-gpu-test gpu_unit_tests standard_nc6_v3 0..4\nreco-spark-test spark_unit_tests standard_d12_v2 0..4\n\n\nLearn More: [What is Azure Machine Learning? - Azure Machine Learning | Microsoft Docs]"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPT’s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPT’s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Tracking LLM “Agent Abilities”",
    "text": "Tracking LLM “Agent Abilities”\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Tracking LLM “Agent Abilities”",
    "text": "Tracking LLM “Agent Abilities”\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing in the context of CI/CD",
    "text": "Testing in the context of CI/CD\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing in the context of SBoMs",
    "text": "Testing in the context of SBoMs\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#other-updates",
    "href": "slides/tai_testing/index.html#other-updates",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Other Updates",
    "text": "Other Updates"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai",
    "href": "slides/tai_testing/index.html#juypter-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter\nGitHub: A generative AI extension for JupyterLab"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai-1",
    "href": "slides/tai_testing/index.html#juypter-ai-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter"
  },
  {
    "objectID": "slides/tai_testing/index.html#kaggle-llm-resource",
    "href": "slides/tai_testing/index.html#kaggle-llm-resource",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Kaggle LLM Resource",
    "text": "Kaggle LLM Resource\n\n\nLearn More: Getting Started With LLMs"
  },
  {
    "objectID": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "href": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Prompt Enginnering Guide",
    "text": "Prompt Enginnering Guide\n\n\nLearn More: Prompt Engineering Guide"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "href": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "title": "KG Construction",
    "section": "KG Construction Pipeline",
    "text": "KG Construction Pipeline"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "href": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "title": "KG Construction",
    "section": "LLM KG Construction Frameworks Llamaindex",
    "text": "LLM KG Construction Frameworks Llamaindex\n\nLearn more: Llamaindex"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#rebel-large-model",
    "href": "slides/kg-llamaindex/index.html#rebel-large-model",
    "title": "KG Construction",
    "section": "Rebel Large Model",
    "text": "Rebel Large Model\n#| echo: true\nfrom transformers import pipeline\n\ntriplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets(text):\n    triplets = []\n    relation, subject, relation, object_ = '', '', '', ''\n    text = text.strip()\n    current = 'x'\n    for token in text.replace(\"&lt;s&gt;\", \"\").replace(\"&lt;pad&gt;\", \"\").replace(\"&lt;/s&gt;\", \"\").split():\n        if token == \"&lt;triplet&gt;\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n                relation = ''\n            subject = ''\n        elif token == \"&lt;subj&gt;\":\n            current = 's'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n            object_ = ''\n        elif token == \"&lt;obj&gt;\":\n            current = 'o'\n            relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '':\n        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n    return triplets\nextracted_triplets = extract_triplets(extracted_text[0])\nprint(extracted_triplets)\n\nLearn more: Rebel Large"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel",
    "text": "LlamaIndex with Rebel\n\n\nLearn more: Llamaindex with Rebel Colab Notebook"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel and Neo4j",
    "text": "LlamaIndex with Rebel and Neo4j\n\n\nLearn more: Neo4j Graph Store\nGitHub: Tomaz Bratanic"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "href": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "title": "KG Construction",
    "section": "Weaviate With Llama 2 and Llamaindex",
    "text": "Weaviate With Llama 2 and Llamaindex\n\n\nLearn more: Welcome to the quick notebook on using Llama 2"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "title": "KG Construction",
    "section": "Weaviate “Knowledge Graphs”",
    "text": "Weaviate “Knowledge Graphs”\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "title": "KG Construction",
    "section": "Weaviate “Knowledge Graphs”",
    "text": "Weaviate “Knowledge Graphs”\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#aws-neptune",
    "href": "slides/kg-llamaindex/index.html#aws-neptune",
    "title": "KG Construction",
    "section": "AWS Neptune",
    "text": "AWS Neptune\n\n\nLearn More: Amazon Neptune"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "href": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "title": "KG Construction",
    "section": "Amazon Science ReFinED",
    "text": "Amazon Science ReFinED\n\n\nPaper: ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking\nPaper: Improving Entity Disambiguation by Reasoning over a Knowledge Base\nGitHub: ReFinED is an efficient and accurate entity linking (EL) system."
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "href": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "title": "KG Construction",
    "section": "Amazon Science KGQA",
    "text": "Amazon Science KGQA\n\n\nWebsite: Language models as controlled natural language semantic parsers for knowledge graph question answering GitHub: Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering"
  },
  {
    "objectID": "slides/tai-tools/index.html#trusted-ai-frameworks-for-knowledge-enginnering",
    "href": "slides/tai-tools/index.html#trusted-ai-frameworks-for-knowledge-enginnering",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Trusted AI Frameworks for Knowledge Enginnering",
    "text": "Trusted AI Frameworks for Knowledge Enginnering"
  },
  {
    "objectID": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-chatgpt",
    "href": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-chatgpt",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "What is Trusted AI – Let’s ask ChatGPT!",
    "text": "What is Trusted AI – Let’s ask ChatGPT!\nTrusted AI encompasses systems that are not only ethically aligned but also reliable, robust, secure, transparent, and accountable. While ethical considerations form a crucial aspect, Trusted AI extends to include the technical quality and performance of the system. The goal is to create AI technologies that various stakeholders—including users, developers, businesses, and regulators—can trust to behave as intended and to meet specific performance, security, and governance standards.\nThe concept integrates aspects from multiple domains, such as:\n\nEthics: Fairness, transparency, and accountability.\nReliability: Consistent and dependable system performance.\nRobustness: Ability to handle unexpected inputs or conditions without failing.\nSecurity: Measures to protect data and models from unauthorized access and tampering.\nTransparency: Understandability of system decisions and actions.\nAccountability: Mechanisms to trace actions back to the responsible entities for evaluation and auditing.\n\nIn this broader context, “trust” is a multidimensional construct. It’s not just about being ethical but about fulfilling a wide range of expectations and standards that make a system worthy of trust."
  },
  {
    "objectID": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-claude-2",
    "href": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-claude-2",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "What is Trusted AI – Let’s ask Claude 2!",
    "text": "What is Trusted AI – Let’s ask Claude 2!\nTrusted AI refers to artificial intelligence systems that are designed and validated to be reliable, safe and technically robust. Key principles of trusted AI include:\n\nReliability - AI systems consistently produce accurate, reproducible results that can be externally validated. Models are unbiased and decisions explainable.\nSafety and security - AI systems are developed using secure software practices and are resilient against attacks, hacking or misuse. They protect privacy and confidentiality.\nExternal oversight - There are independent audits and ongoing monitoring of AI systems to ensure transparency and identify issues. Public disclosure builds trust.\nHuman control - Humans remain fully in control of AI systems, which augment human intelligence rather than replace it. Autonomous systems have human supervision.\nProportionality - AI capabilities do not exceed what is appropriate for the task. AI is not used when less advanced technology suffices.\nTechnical robustness - AI systems are thoroughly tested for stability, scalability and corner cases. Failsafes prevent glitches or unintended harm.\n\nIn contrast to responsible AI, trusted AI emphasizes technical system properties over organizational processes. It focuses on engineering reliable, safe and externally validated AI, rather than holistic internal governance."
  },
  {
    "objectID": "slides/tai-tools/index.html#our-evolving-vision-of-trusted-ai",
    "href": "slides/tai-tools/index.html#our-evolving-vision-of-trusted-ai",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Our, evolving vision of Trusted AI",
    "text": "Our, evolving vision of Trusted AI"
  },
  {
    "objectID": "slides/tai-tools/index.html#responsible-ai",
    "href": "slides/tai-tools/index.html#responsible-ai",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Responsible AI",
    "text": "Responsible AI\n\nResponsible AI: This term is broader and refers to the ethical design, development, and deployment of AI. This includes considerations not just of the AI’s technical behavior (e.g., is it transparent and accountable?), but also of the socio-economic implications, like job displacement, and broader ethical considerations like data privacy and environmental impact."
  },
  {
    "objectID": "slides/tai-tools/index.html#why-a-framework",
    "href": "slides/tai-tools/index.html#why-a-framework",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Why a Framework?",
    "text": "Why a Framework?\n\n\n\n\n“Course22/06-Why-You-Should-Use-a-Framework.Ipynb at Master · Fastai/Course22.” Accessed August 29, 2023. https://github.com/fastai/course22/blob/master/06-why-you-should-use-a-framework.ipynb."
  },
  {
    "objectID": "slides/tai-tools/index.html#foundational-components-for-trusted-ai",
    "href": "slides/tai-tools/index.html#foundational-components-for-trusted-ai",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Foundational Components for Trusted AI",
    "text": "Foundational Components for Trusted AI\n\nAutomate the integration and deployment of code, ensuring quality and operational efficiency.\nStandardized Development Environments: Establish consistent, easily replicable environments to accelerate development and experimentation.\nData & Experiment Versioning: Implement robust systems to track changes in data and experiments, allowing for traceability and repeatability.\nModel Lifecycle Management: Streamline the training, deployment, monitoring, and updating of machine learning models.\nFlexibility Across Layers: Design the architecture to allow for different levels of customization, from high-level APIs to low-level controls, facilitating adaptability."
  },
  {
    "objectID": "slides/tai-tools/index.html#this-is-a-living-set-of-slides",
    "href": "slides/tai-tools/index.html#this-is-a-living-set-of-slides",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "This is a “living” set of slides!",
    "text": "This is a “living” set of slides!"
  },
  {
    "objectID": "slides/tai-tools/index.html#python",
    "href": "slides/tai-tools/index.html#python",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Python",
    "text": "Python\n\n\nLearn More: Think Python 2e: https://greenteapress.com/wp/think-python-2e/"
  },
  {
    "objectID": "slides/tai-tools/index.html#sneek-peek-at",
    "href": "slides/tai-tools/index.html#sneek-peek-at",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Sneek Peek at 🔥",
    "text": "Sneek Peek at 🔥\n\n\n\n\n“Modular Docs - Mojo🔥.” Accessed August 29, 2023. https://docs.modular.com/mojo/."
  },
  {
    "objectID": "slides/tai-tools/index.html#setting-up-environment",
    "href": "slides/tai-tools/index.html#setting-up-environment",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Setting up Environment",
    "text": "Setting up Environment\n\nFastAI Setup: https://github.com/fastai/fastsetup\nTmux: https://github.com/tmux/tmux/wiki/Getting-Started\ndotfiles: https://github.com/fastai/dotfiles\nFastAI Live Coding: https://forums.fast.ai/t/live-coding-aka-walk-thrus/96617\nFastAI Git, SSH, TMUX: https://forums.fast.ai/t/live-coding-2/96690\nBeginner’s Guide to Mambaforge Installation: https://qbiwan.github.io/fastpages/mamba-installation"
  },
  {
    "objectID": "slides/tai-tools/index.html#python-for-data-analysis",
    "href": "slides/tai-tools/index.html#python-for-data-analysis",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Python for Data Analysis",
    "text": "Python for Data Analysis\n\n\nPractical Deep Learning: https://wesmckinney.com/book/"
  },
  {
    "objectID": "slides/tai-tools/index.html#ai-and-machine-learning",
    "href": "slides/tai-tools/index.html#ai-and-machine-learning",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "AI and Machine Learning",
    "text": "AI and Machine Learning\n\n\nPractical Deep Learning: https://course.fast.ai/ FastAI GitHub: https://github.com/fastai"
  },
  {
    "objectID": "slides/tai-tools/index.html#visual-studio-code",
    "href": "slides/tai-tools/index.html#visual-studio-code",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Visual Studio Code",
    "text": "Visual Studio Code\n\n\nVisual Studio Code - Code Editing. Redefined: https://code.visualstudio.com/"
  },
  {
    "objectID": "slides/tai-tools/index.html#visual-studio-code-plugins",
    "href": "slides/tai-tools/index.html#visual-studio-code-plugins",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Visual Studio Code Plugins",
    "text": "Visual Studio Code Plugins\n\nDraw.io Integration\nDVC Integration\nnbdev VSCode\nJupyter\nQuarto\nRDF Sketch\nStardog/RDF Languages Extension Pack\n\n\nVisual Studio Code - Code Editing. Redefined: https://code.visualstudio.com/"
  },
  {
    "objectID": "slides/tai-tools/index.html#github",
    "href": "slides/tai-tools/index.html#github",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "GitHub",
    "text": "GitHub"
  },
  {
    "objectID": "slides/tai-tools/index.html#homebrewwsl-mac-and-windows",
    "href": "slides/tai-tools/index.html#homebrewwsl-mac-and-windows",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Homebrew/WSL (Mac and Windows)",
    "text": "Homebrew/WSL (Mac and Windows)"
  },
  {
    "objectID": "slides/tai-tools/index.html#markdown",
    "href": "slides/tai-tools/index.html#markdown",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Markdown",
    "text": "Markdown\n\n\n\n\n\nMarkdown Guide"
  },
  {
    "objectID": "slides/tai-tools/index.html#knowledge-graphs",
    "href": "slides/tai-tools/index.html#knowledge-graphs",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs"
  },
  {
    "objectID": "slides/tai-tools/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "href": "slides/tai-tools/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nRManLuo/Awesome-LLM-KG: Awesome papers about unifying LLMs and KGs (https://github.com/RManLuo/Awesome-LLM-KG)"
  },
  {
    "objectID": "slides/tai-tools/index.html#jsonl-ld-for-linked-datsa",
    "href": "slides/tai-tools/index.html#jsonl-ld-for-linked-datsa",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "JSONL LD for Linked Datsa",
    "text": "JSONL LD for Linked Datsa\n\n\nJSON-LD 1.1: A JSON-based Serialization for Linked Data"
  },
  {
    "objectID": "slides/tai-tools/index.html#llm-assisted-odps-using-pattern-templates",
    "href": "slides/tai-tools/index.html#llm-assisted-odps-using-pattern-templates",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "LLM assisted ODPs using Pattern Templates",
    "text": "LLM assisted ODPs using Pattern Templates"
  },
  {
    "objectID": "slides/tai-tools/index.html#leveraging-standards",
    "href": "slides/tai-tools/index.html#leveraging-standards",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Leveraging Standards",
    "text": "Leveraging Standards\n\nSchema.org - schemas and supporting software"
  },
  {
    "objectID": "slides/tai-tools/index.html#ontology-engineering-in-a-age-of-llms",
    "href": "slides/tai-tools/index.html#ontology-engineering-in-a-age-of-llms",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Ontology Engineering in a Age of LLMs",
    "text": "Ontology Engineering in a Age of LLMs"
  },
  {
    "objectID": "slides/tai-tools/index.html#applying-software-engineering-to-ontologies",
    "href": "slides/tai-tools/index.html#applying-software-engineering-to-ontologies",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Applying Software Engineering to Ontologies",
    "text": "Applying Software Engineering to Ontologies\n\n\nEva Blomqvist, Karl Hammar, and Valentina Presutti. “Engineering Ontologies with Patterns – The EXtreme Design Methodology.” In Ontology Engineering with Ontology Design Patterns, 23–50. IOS Press, 2016. https://doi.org/10.3233/978-1-61499-676-7-23."
  },
  {
    "objectID": "slides/tai-tools/index.html#applying-software-engineering-to-ontologies-1",
    "href": "slides/tai-tools/index.html#applying-software-engineering-to-ontologies-1",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Applying Software Engineering to Ontologies",
    "text": "Applying Software Engineering to Ontologies\n\n\nCogan Shimizu, Karl Hammar, and Pascal Hitzler. “Modular Ontology Modeling.” Edited by Sabrina Kirrane, Axel-Cyrille Ngonga Ngomo, Sabrina Kirrane, and Axel-Cyrille Ngonga Ngomo. Semantic Web 14, no. 3 (April 5, 2023): 459–89. https://doi.org/10.3233/SW-222886."
  },
  {
    "objectID": "slides/tai-tools/index.html#fair-ontologies-and-vocabularies",
    "href": "slides/tai-tools/index.html#fair-ontologies-and-vocabularies",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "FAIR Ontologies and Vocabularies",
    "text": "FAIR Ontologies and Vocabularies\n\n\nGarijo, Daniel, and María Poveda-Villalón. “Best Practices for Implementing FAIR Vocabularies and Ontologies on the Web.” arXiv, March 29, 2020. http://arxiv.org/abs/2003.13084."
  },
  {
    "objectID": "slides/tai-tools/index.html#visual-ontology-development",
    "href": "slides/tai-tools/index.html#visual-ontology-development",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Visual Ontology Development",
    "text": "Visual Ontology Development\n\n\nGarijo, Daniel, and María Poveda-Villalón. “Best Practices for Implementing FAIR Vocabularies and Ontologies on the Web.” arXiv, March 29, 2020. http://arxiv.org/abs/2003.13084."
  },
  {
    "objectID": "slides/tai-tools/index.html#self-documenting-ontologies",
    "href": "slides/tai-tools/index.html#self-documenting-ontologies",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Self Documenting Ontologies",
    "text": "Self Documenting Ontologies\n\n\nGarijo, Daniel. “WIDOCO: A Wizard for Documenting Ontologies.” In International Semantic Web Conference, 94–102. Springer, Cham, 2017. https://doi.org/10.1007/978-3-319-68204-4_9.http://dgarijo.com/papers/widoco-iswc2017.pdf Garijo, Daniel. “WIDOCO: A Wizard for Documenting Ontologies.” Java, 2017. https://doi.org/10.1007/978-3-319-68204-4_9.https://github.com/dgarijo/Widoco"
  },
  {
    "objectID": "slides/tai-tools/index.html#kgc-master-class-on-json-ld-pipeline",
    "href": "slides/tai-tools/index.html#kgc-master-class-on-json-ld-pipeline",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "KGC Master Class on JSON-LD Pipeline",
    "text": "KGC Master Class on JSON-LD Pipeline\n\n\nLearn More: Converting Legacy Enterprise Data into Knowledge Graphs with AI and JSON LD"
  },
  {
    "objectID": "slides/tai-tools/index.html#ontologies-and-data-integration",
    "href": "slides/tai-tools/index.html#ontologies-and-data-integration",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Ontologies and data integration",
    "text": "Ontologies and data integration\n\n\nKGC 2023 Talk: In Defense of Inconsistency, On Managing Truth in a Knowledge Graph - YouTube"
  },
  {
    "objectID": "slides/tai-tools/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "href": "slides/tai-tools/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn More: [RManLuo/Awesome-LLM-KG: Awesome papers about unifying LLMs and KGs (github.com)"
  },
  {
    "objectID": "slides/tai-tools/index.html#the-knowledge-graph-book",
    "href": "slides/tai-tools/index.html#the-knowledge-graph-book",
    "title": "TAI Knowledge Engineering: A Tools Perspective",
    "section": "The Knowledge Graph Book",
    "text": "The Knowledge Graph Book\n\n\nHogan, Aidan, Claudio Gutierrez, Michael Cochez, Gerard De Melo, Sabrina Kirrane, Axel Polleres, Roberto Navigli, et al. Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge. Cham: Springer International Publishing, 2022. https://doi.org/10.1007/978-3-031-01918-0."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "Welcome To AI Success Factors: Engineering Trust in Deployments\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "At the University of Notre Dame’s Center for Research Computing (CRC), the Laboratory for Assured AI Applications Development (LA3D) represents a critical step in the field of artificial intelligence (AI). As part of CRC’s commitment to leveraging advanced computation for discovery and innovation, LA3D focuses on ensuring the responsible development and application of AI technologies. This initiative aligns with both the technological evolution of AI and the broader goals of CRC and Notre Dame.\nThe mission of LA3D is robust, layered, and rooted in a commitment to research, develop, and deploy AI models and systems that are not just innovative but trustworthy and ethically aligned. With a focus on AI Engineering, Trusted AI, Knowledge Engineering, FAIR (Findable, Accessible, Interoperable, and Reusable) data, and CyberInfrastructure, LA3D presents a multifaceted approach.\nAI’s Transformative Potential: The transformative potential of AI is no longer a distant aspiration but a present-day reality. Whether in healthcare, finance, transportation, or education, AI’s capacity to innovate is unparalleled. LA3D recognizes this potential and strives to harness it, directing AI’s power towards constructive, ethical, and sustainable ends.\nConnection to the Center for Research Computing: LA3D’s home in the CRC is more than a mere geographical placement. It symbolizes a shared vision of advancing science through computational methods, high-performance computing, and now, AI-driven solutions. By integrating into the CRC’s vibrant ecosystem, LA3D amplifies the pursuit of excellence, pushing the boundaries of what’s achievable with AI.\nMission Overview: LA3D’s mission transcends traditional boundaries, aiming to advance fields like AI Engineering, with its critical role in transitioning prototypes to production; Trusted AI, embodying ethical and reliable systems; Knowledge Engineering, embracing the new frontiers of Large Language Models; FAIR data principles; and the rapidly evolving CyberInfrastructure. Each of these elements comes together to create a synergy that fuels LA3D’s ambition to lead AI into an era marked by integrity, ingenuity, and human-centric focus.\nThe launch of LA3D marks a promising beginning in a journey filled with exploration, challenge, and opportunity. It sets the stage for an intellectual adventure that seeks to navigate the complex landscape of AI, unlocking its potentials while remaining anchored to values and ethical principles. Welcome to the Laboratory for Assured AI Applications Development – a place where AI’s promise transforms into tangible progress."
  },
  {
    "objectID": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "href": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "The Imperative of the Disciplines",
    "text": "The Imperative of the Disciplines\n\nAI Engineering: Bridging the Gap from Prototype to Production\nIn the complex, multifaceted realm of AI, the journey from concept to realization is fraught with challenges and intricacies. AI Engineering, a core discipline at the Laboratory for Assured AI Applications Development (LA3D), stands as a beacon guiding this intricate transition from prototypes to production-grade applications.\n\nTransitioning Prototypes to Production: At LA3D, we recognize that the gap between experimental AI prototypes and fully functional production systems is vast. AI Engineering provides the methodologies, tools, and practices needed to navigate this gap. It’s about ensuring that promising concepts don’t just remain on paper but evolve into tangible applications. The recent Gartner research resonates with our approach, identifying that only 53% of AI projects transition from prototypes to production, underscoring the need for an engineering-driven approach.\nCore Pillars: DataOps, ModelOps, DevOps: DataOps focuses on data management and quality, ModelOps on model lifecycle management, and DevOps for seamless integration. These three core pillars together facilitate performance, scalability, interpretability, and reliability of AI models, maximizing the value of AI investments.\nAssurance in AI Models and Mechanistic Interpretability: Assurance in AI Models and Mechanistic Interpretability: Trust and reliability lie at the core of AI Engineering. At LA3D, the utilization of energy-based modeling, specifically Joint Energy-Based Models (JEMs), offers a transparent and statistically grounded approach to AI. By learning joint distributions over observed and latent variables, and associating lower energies with more likely configurations, JEMs help in aligning AI models with ethical guidelines and intended purposes. This mechanistic interpretability, coupled with the robust design inherent in JEMs, ensures predictability and engenders trust. Such alignment is vital for Assured AI, where understanding the underlying patterns and regularities in data becomes a cornerstone for creating reliable and responsible applications.\nScalability, Efficiency, Lifecycle Management, and Data-Centric AI: Ensuring consistent performance across different scales and complexities is crucial. LA3D’s AI Engineering practices enable models to be deployed in various environments without losing integrity or performance. Managing AI models throughout their lifecycle through continuous monitoring, validation, and maintenance ensures adaptability and alignment with evolving objectives. The emphasis on Data-Centric AI reflects LA3D’s commitment to focusing on the quality of data, recognizing that data is the lifeblood of AI systems.\nInterdisciplinary Collaboration and Alignment with Human Values: AI Engineering fosters collaboration among data scientists, engineers, domain experts, and ethical compliance teams. The result is cohesive AI development, where varying perspectives merge to create solutions resonating with diverse needs and values. At LA3D, AI serves human values and societal needs, ensuring that technology is not only technically sound but also socially responsible.\nEmbracing CyberSecurity: Coupled with a growing interest in CyberSecurity, LA3D extends the scope of AI Engineering to safeguard information and assure security in AI applications.\n\nAI Engineering is not merely a process at LA3D; it’s a philosophy and an imperative discipline. It’s the bedrock that ensures AI models are not just innovative but also responsible, practical, and aligned with the human experience. Bridging the gap from prototype to production, AI Engineering paves the way for a future where AI is not just a tool but a reliable partner for progress. Join us on this journey as we delve deeper into AI Engineering, exploring its challenges, triumphs, and nuances.\n\n\nTrusted AI: A Cornerstone of Ethical and Reliable Systems\nTrusted AI is not just a concept; it’s a commitment to integrity, ethics, and societal alignment that LA3D wholeheartedly embraces. Trust in AI is an essential component in our technological landscape, and it embodies various facets that work in synergy to create ethical and reliable systems.\n\nAssurance in AI Models: At LA3D, assurance goes beyond mere compliance; it’s about creating AI models that can be understood, scrutinized, and validated. Building AI models that can explain their reasoning and provide clarity in their decisions is integral to creating trust.\nTransparency and Accountability: The quest for Trusted AI demands complete transparency in both process and outcomes. LA3D adheres to an open and comprehensible approach that allows all stakeholders to understand how decisions are made and who is accountable for them. Ensuring this level of transparency fosters an environment where AI models can be thoroughly evaluated and critiqued, reinforcing trust in their use.\nResponsible AI: While Trusted AI focuses on reliability and ethics, Responsible AI broadens the spectrum to include considerations such as fairness, inclusivity, privacy, and societal impact. At LA3D, we recognize that AI systems must not only operate within ethical guidelines but also actively contribute to the well-being of society. This commitment to social responsibility aligns with our holistic approach to developing technology that enriches lives.\nCyberSecurity in AI: As AI systems become more intertwined with our daily lives, the need to secure them becomes paramount. LA3D is committed to incorporating CyberSecurity measures within the AI development process, safeguarding data and protecting the integrity of AI systems. We understand that trust in AI also depends on the security of the systems, and we dedicate our resources to ensure that our AI applications are robust against threats.\n\nTrusted AI is a cornerstone at LA3D, reflecting our relentless pursuit of aligning technology with human values and ethical principles. It’s about creating AI that people can rely on, understand, and feel safe using. The interplay between transparency, accountability, Responsible AI, and CyberSecurity forms a unified approach to build AI systems that not only perform exceptionally but also resonate with the broader societal goals.\nJoin us as we explore further the nuances of Trusted AI, a field where technology and ethics merge to pave the way for a future where AI is a dependable ally. Our commitment to this discipline underscores the depth of our understanding of the complexities involved in crafting AI that is truly trusted.\nThis section outlines the key areas of Trusted AI that LA3D focuses on, emphasizing the importance of trust, transparency, responsibility, and security within the AI domain. It underscores the laboratory’s dedication to ethical and reliable AI systems, aligning with societal needs and values.\n\n\nKnowledge Engineering and Prompt Engineering: The New Frontiers\nIn the rapidly evolving landscape of artificial intelligence, Knowledge Engineering and Prompt Engineering emerge as exciting new frontiers that promise to reshape the way we conceptualize, create, and leverage AI systems. At the Laboratory for Assured AI Applications Development (LA3D), we recognize the vital role of these disciplines in shaping the next generation of AI applications.\n\nKnowledge Graphs: Knowledge graphs represent a transformative approach to organizing and connecting information. By modeling relationships between entities in a structured and semantically rich format, knowledge graphs enable more intelligent querying and reasoning. LA3D actively leverages knowledge graphs to power more insightful and context-aware AI solutions.\nOntology Design Patterns: A specialized aspect of Knowledge Engineering, ontology design patterns allow for the formal representation of concepts and their relationships within a specific domain. By utilizing these patterns, LA3D ensures that AI systems have a solid conceptual foundation, enabling more precise interpretation and decision-making.\nLLM Techniques: Large Language Models (LLMs) are revolutionizing natural language processing. By employing techniques like Prompt Engineering, LA3D refines the interaction with LLMs, enhancing their responsiveness and adaptability. This method allows for more effective communication with AI systems, aligning them closer to human-like understanding.\nAI Models as Surrogates: At LA3D, we explore the exciting potential of AI models as surrogates for complex mathematical or physical models. These AI surrogates can provide faster and more accessible simulations, accelerating research and opening new avenues for exploration in science and engineering.\nAI Co-Pilots for Various Tasks: Beyond acting as mere tools, AI models are now being developed as intelligent co-pilots, assisting human experts in a variety of tasks. Whether aiding in data analysis, guiding complex problem-solving, or enhancing creative processes, AI co-pilots represent a new paradigm of collaboration between human and machine intelligence.\n\nKnowledge Engineering and Prompt Engineering are not mere additions to the AI toolkit; they are pivotal advancements that herald a new era in AI application design and interaction. By embracing these new frontiers, LA3D reinforces its commitment to innovation, excellence, and the relentless pursuit of AI that is not just cutting-edge but profoundly attuned to human needs and aspirations. Join us as we explore these new horizons, uncovering the immense potential and profound implications they hold for the future of AI.\n\n\nThe Evolution of CyberInfrastructure and AI-Driven Science AI-Driven Science\nThe seamless integration of CyberInfrastructure with AI-driven science marks a transformative phase in research and innovation. As part of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing (CRC), we are at the forefront of this exciting convergence, pioneering approaches that harness the power of advanced computing technologies to accelerate scientific discovery.\n\nAI-Driven Science: The infusion of AI into scientific research has ushered in a new era of data-driven exploration and insight. At LA3D, we employ AI models to analyze complex data sets, predict outcomes, and even guide experimental design. From enhancing medical diagnostics to predicting climate patterns, AI-driven science is unlocking unprecedented opportunities for understanding and innovation.\nRelevance to CRC: The Center for Research Computing at Notre Dame is committed to providing cutting-edge computational resources and expertise. The collaboration with LA3D amplifies this commitment by aligning AI research with state-of-the-art CyberInfrastructure. Together, we’re pushing the boundaries of what’s possible in computational science.\nAI Surrogates for Mathematical Models: Building on the AI surrogates concept, we utilize AI models to replicate complex mathematical or physical systems within CRC. These surrogates enable faster simulations and insights, thus accelerating research and expanding our ability to tackle previously intractable problems.\nAI Co-Pilots for Scientific Exploration: The development of AI co-pilots has extended into the realm of scientific exploration at CRC. These intelligent systems act as collaborators, assisting researchers in hypothesis formulation, data analysis, and problem-solving. It’s a revolutionary approach that augments human intelligence with AI, fostering a new level of creativity and rigor in scientific inquiry.\nIntegration of CyberInfrastructure: A robust CyberInfrastructure is foundational to AI-driven science at CRC. By weaving together high-performance computing, cloud technologies, and specialized software, we’re creating a dynamic environment where AI and computational science flourish. It’s a synergy that optimizes research processes, enhances collaboration, and catalyzes breakthroughs.\n\nThe evolution of CyberInfrastructure and AI-driven science at CRC represents more than technological advancement; it’s a paradigm shift in how we approach research and discovery. Through strategic collaboration and relentless innovation, we’re crafting a future where technology and human intellect unite to illuminate the unknown. Join us on this path, as we explore the incredible potential and promise of this convergence, continually striving to redefine the boundaries of what is possible in science and beyond."
  },
  {
    "objectID": "posts/welcome/index.html#blogs-objective-and-overview",
    "href": "posts/welcome/index.html#blogs-objective-and-overview",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "Blog’s Objective and Overview",
    "text": "Blog’s Objective and Overview\nIn alignment with the University of Notre Dame’s mission to seek knowledge that addresses humanity’s pressing challenges, and the Center for Research Computing’s (CRC) commitment to driving innovation, the Laboratory for Assured AI Applications Development (LA3D) is pleased to unveil this blog as an essential platform.\n\nWeekly Updates: Engage with regular insights into the ongoing research, technological advancements, and creative pursuits within LA3D. From AI Engineering to Trusted AI, we’ll keep our community abreast of the exciting developments shaping our field.\nInsights into Trusted AI, CI-Compass, and More: Delve into the core projects and collaborations within LA3D, including specialized explorations into the worlds of Trusted AI, CI-Compass, CyberSecurity in AI, and the nuances of Responsible AI.\nAI Workforce Development: Recognizing the need for a skilled and knowledgeable AI workforce, this blog will feature initiatives, programs, and strategies dedicated to cultivating the next generation of AI professionals. Together with CRC, we strive to foster education, mentorship, and career development in AI.\nResearch Publications and Highlights: Discover the rich tapestry of research being woven at LA3D. We’ll highlight key publications, conference achievements, and innovative studies that reflect our commitment to excellence and alignment with Notre Dame’s values.\nCommunity Engagement and Collaboration: Building on Notre Dame’s emphasis on community and service, this blog invites you to participate, share, and learn. Join a lively dialogue that celebrates diversity of thought and collaboration in pursuit of a greater understanding of Assured AI.\nSpotlight on CyberSecurity in AI and Emerging Topics: As part of our comprehensive view of modern AI, we will dedicate specific sections to explore critical areas like CyberSecurity and the delicate balance between Responsible and Trusted AI.\nConnection to Notre Dame’s and CRC’s Mission: This blog embodies the spirit of Notre Dame and CRC’s shared mission to advance knowledge, foster innovation, and contribute to society. We strive to make the pursuit of AI not only a scientific endeavor but also a means to enrich lives and address societal needs.\n\nIn the introduction, we’ve outlined the essential areas of focus at the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. From AI Engineering’s crucial role in transitioning prototypes to production, to the ethical imperatives in Trusted AI, Knowledge Engineering, CyberSecurity in AI, and the blog’s alignment with the missions of CRC and Notre Dame, we’ve set the stage for a comprehensive exploration.\nOur blog serves as a platform to dive into these topics, including AI workforce development and the ways in which AI intersects with societal needs and technological advancements. As we move forward, we’ll examine these subjects in detail, shedding light on the challenges, successes, and ongoing efforts in these fields.\nStay tuned as we delve into the complexities of AI, with insights and updates that reflect LA3D’s commitment to innovation, responsibility, and real-world applicability. Join us in this exploration, as we strive to make AI not just a tool, but a reliable partner for progress."
  },
  {
    "objectID": "slideindex.html",
    "href": "slideindex.html",
    "title": "Weekly Nugget Presentations",
    "section": "",
    "text": "TAI Knowledge Engineering\n\n\n\n\n\n\n\nTools\n\n\nFrameworks\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nTAI Knowledge Engineering: A Tools Perspective\n\n\n\n\n\n\n\nTools\n\n\nFrameworks\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nBuilding “Stuff”?\n\n\n\n\n\n\n\nAgents\n\n\ntrustedAI\n\n\nDevelopment\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nA Summer of Nuggets\n\n\n\n\n\n\n\nnuggets\n\n\ntrustedAI\n\n\nLLMs\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nWhat Dr. Vardeman is worried about: Trusted cognitive Agents\n\n\n\n\n\n\n\nAgents\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nThings that concern Dr. Vardeman: Testing\n\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\nTesting\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nKG Construction\n\n\n\n\n\n\n\nKnowledge Engineering\n\n\nKG Construction\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nTrust and Causal Reasoning\n\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tatical-ammunition-management-micro-services-tamms",
    "href": "slides/agents_summer23/index.html#motivation-tatical-ammunition-management-micro-services-tamms",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: Tatical ammunition management Micro Services (TAMMS)",
    "text": "Motivation: Tatical ammunition management Micro Services (TAMMS)"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tamms-cognitive-agents",
    "href": "slides/agents_summer23/index.html#motivation-tamms-cognitive-agents",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: TAMMS cognitive Agents",
    "text": "Motivation: TAMMS cognitive Agents"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tamms-kg",
    "href": "slides/agents_summer23/index.html#motivation-tamms-kg",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: TAMMS KG",
    "text": "Motivation: TAMMS KG"
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs",
    "text": "Cognitive Agents based on LLMs\n\n\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv, August 5, 2023. http://arxiv.org/abs/2304.03442."
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs Architecture",
    "text": "Cognitive Agents based on LLMs Architecture\n\n\nJoon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv, August 5, 2023. http://arxiv.org/abs/2304.03442."
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture-framework",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture-framework",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs Architecture Framework",
    "text": "Cognitive Agents based on LLMs Architecture Framework\n\n\nPark, Joon Sung. “Generative Agents: Interactive Simulacra of Human Behavior,” August 22, 2023. https://github.com/joonspk-research/generative_agents."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-web-agents",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-web-agents",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Web Agents",
    "text": "Activity Specific Agents: Web Agents\n\n\nDeng, Xiang, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. “Mind2Web: Towards a Generalist Agent for the Web.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.06070."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-web-agents-architecture",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-web-agents-architecture",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Web Agents Architecture",
    "text": "Activity Specific Agents: Web Agents Architecture\n\n\nDeng, Xiang, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. “Mind2Web: Towards a Generalist Agent for the Web.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.06070."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Visual Agents",
    "text": "Activity Specific Agents: Visual Agents\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#visual-agents-architecture-different-llms-based-on-role",
    "href": "slides/agents_summer23/index.html#visual-agents-architecture-different-llms-based-on-role",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Visual Agents Architecture: Different LLMs based on Role",
    "text": "Visual Agents Architecture: Different LLMs based on Role\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents-transition-graph",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents-transition-graph",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Visual Agents Transition Graph",
    "text": "Activity Specific Agents: Visual Agents Transition Graph\n\n\n“Autonomous Visual Information Seeking with Large Language Models,” Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#aside-transformer-vision-and-segmentation-models",
    "href": "slides/agents_summer23/index.html#aside-transformer-vision-and-segmentation-models",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Aside: Transformer Vision and segmentation models",
    "text": "Aside: Transformer Vision and segmentation models\n\n\n“Alaamaalouf/FollowAnything.” Accessed August 22, 2023. https://github.com/alaamaalouf/FollowAnything.\nMaalouf, Alaa, Ninad Jadhav, Krishna Murthy Jatavallabhula, Makram Chahine, Daniel M. Vogt, Robert J. Wood, Antonio Torralba, and Daniela Rus. “Follow Anything: Open-Set Detection, Tracking, and Following in Real-Time.” arXiv, August 10, 2023. https://doi.org/10.48550/arXiv.2308.05737."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al. “Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-1",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-1",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al. “Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-2",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-2",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al. “Graph of Thoughts: Solving Elaborate Problems with Large Language Models.” arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#aside-prompt-engineering-guide",
    "href": "slides/agents_summer23/index.html#aside-prompt-engineering-guide",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Aside: Prompt Engineering Guide",
    "text": "Aside: Prompt Engineering Guide\n\n\n“Prompt Engineering Guide.” Accessed August 22, 2023. https://www.promptingguide.ai/."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools-gorilla",
    "href": "slides/agents_summer23/index.html#apis-as-tools-gorilla",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools: Gorilla",
    "text": "APIs as Tools: Gorilla\n\n\nPatil, Shishir G., Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. “Gorilla: Large Language Model Connected with Massive APIs.” arXiv, May 24, 2023. http://arxiv.org/abs/2305.15334."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools-architecture",
    "href": "slides/agents_summer23/index.html#apis-as-tools-architecture",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools: Architecture",
    "text": "APIs as Tools: Architecture\n\n\nPatil, Shishir G., Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. “Gorilla: Large Language Model Connected with Massive APIs.” arXiv, May 24, 2023. http://arxiv.org/abs/2305.15334."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools",
    "href": "slides/agents_summer23/index.html#apis-as-tools",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools",
    "text": "APIs as Tools\n\n\nPatil, Shishir. “Gorilla: Large Language Model Connected with Massive APIs [Project Website].” Python, August 22, 2023. https://github.com/ShishirPatil/gorilla."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llm-personality-traits",
    "href": "slides/agents_summer23/index.html#llm-personality-traits",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LLM Personality Traits",
    "text": "LLM Personality Traits\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#using-personality-tests",
    "href": "slides/agents_summer23/index.html#using-personality-tests",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Using Personality Tests",
    "text": "Using Personality Tests\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#behavior-persona-through-prompting",
    "href": "slides/agents_summer23/index.html#behavior-persona-through-prompting",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Behavior Persona Through Prompting",
    "text": "Behavior Persona Through Prompting\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llm-personality-traits-malleability",
    "href": "slides/agents_summer23/index.html#llm-personality-traits-malleability",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LLM Personality Traits Malleability",
    "text": "LLM Personality Traits Malleability\n\n\nSafdari, Mustafa, Greg Serapio-García, Clément Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja Matarić. “Personality Traits in Large Language Models.” arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#grounding-through-hybrid-kgs",
    "href": "slides/agents_summer23/index.html#grounding-through-hybrid-kgs",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Grounding Through Hybrid KGs",
    "text": "Grounding Through Hybrid KGs\n\n\nShirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs",
    "href": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\nLiu, Jerry. “LlamaIndex.” Python, November 2022. https://doi.org/10.5281/zenodo.1234."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs-1",
    "href": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs-1",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\n“Custom Retriever Combining KG Index and VectorStore Index - LlamaIndex 🦙 0.8.5.Post2.” Accessed August 22, 2023. https://gpt-index.readthedocs.io/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#data-agents-in-llamaindex",
    "href": "slides/agents_summer23/index.html#data-agents-in-llamaindex",
    "title": "What Dr. Vardeman is worried about: Trusted cognitive Agents",
    "section": "Data Agents in LlamaIndex",
    "text": "Data Agents in LlamaIndex\n\n\nFrom: Liu, Jerry. “Data Agents.” LlamaIndex Blog (blog), July 13, 2023. https://medium.com/llamaindex-blog/data-agents-eed797d7972f."
  },
  {
    "objectID": "slides/building_stuff/index.html#section",
    "href": "slides/building_stuff/index.html#section",
    "title": "Building “Stuff”?",
    "section": "",
    "text": "Building Stuff?\n\n\n\nBuilding Agents based on Large Language Models!"
  },
  {
    "objectID": "slides/building_stuff/index.html#you-are-here",
    "href": "slides/building_stuff/index.html#you-are-here",
    "title": "Building “Stuff”?",
    "section": "You are here ⬇️",
    "text": "You are here ⬇️"
  },
  {
    "objectID": "slides/building_stuff/index.html#what-kind-of-llm-agents-are-we-trying-to-build",
    "href": "slides/building_stuff/index.html#what-kind-of-llm-agents-are-we-trying-to-build",
    "title": "Building “Stuff”?",
    "section": "What Kind of LLM Agents are we trying to build?",
    "text": "What Kind of LLM Agents are we trying to build?\n\n\nConversational Agents\nvs. Cognitive Autonomous Agents\nvs. Agents tuned for a Data Processing Task"
  },
  {
    "objectID": "slides/building_stuff/index.html#section-1",
    "href": "slides/building_stuff/index.html#section-1",
    "title": "Building “Stuff”?",
    "section": "",
    "text": "We will focus on Conversational Agents…"
  },
  {
    "objectID": "slides/building_stuff/index.html#the-best-advice-we-can-give",
    "href": "slides/building_stuff/index.html#the-best-advice-we-can-give",
    "title": "Building “Stuff”?",
    "section": "The Best Advice we can Give",
    "text": "The Best Advice we can Give\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#section-2",
    "href": "slides/building_stuff/index.html#section-2",
    "title": "Building “Stuff”?",
    "section": "",
    "text": "Andrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#caveat-you-are-at-the-edge-of-research-and-practice",
    "href": "slides/building_stuff/index.html#caveat-you-are-at-the-edge-of-research-and-practice",
    "title": "Building “Stuff”?",
    "section": "Caveat: You are at the Edge of Research and Practice!",
    "text": "Caveat: You are at the Edge of Research and Practice!"
  },
  {
    "objectID": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual",
    "href": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual",
    "title": "Building “Stuff”?",
    "section": "We want Large Language Models to be Factual!",
    "text": "We want Large Language Models to be Factual!\n\n\n“Fine Tuning”\nRetrieval Augmented Generation (RAG)"
  },
  {
    "objectID": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual-1",
    "href": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual-1",
    "title": "Building “Stuff”?",
    "section": "We want Large Language Models to be Factual!",
    "text": "We want Large Language Models to be Factual!\n\nFine-Tuning: augment the behavior of the model\nRetrieval: introduce new knowledge to the model\nRetreval Aware Training (RAT) Fine-tune the model to use or ignore retrieved content"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned ML Website",
    "text": "Towards Trustworthy and Aligned ML Website\n\n\nTowards Trustworthy and Aligned ML"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#causal-reasoning",
    "href": "slides/trust-causal/index.html#causal-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Causal Reasoning",
    "text": "Causal Reasoning\n\n\nLearn more: Amazon Book of Why"
  },
  {
    "objectID": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "href": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "title": "Trust and Causal Reasoning",
    "section": "Trustworthy ML Initiative (TrustML)",
    "text": "Trustworthy ML Initiative (TrustML)\n\n\nLearn more: Trustworthy ML Org"
  },
  {
    "objectID": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "href": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "title": "Trust and Causal Reasoning",
    "section": "Gorilla API to Ground “Tool Use”",
    "text": "Gorilla API to Ground “Tool Use”\n\n\nLearn more: Gorilla: Large Language Model Connected with Massive APIs"
  },
  {
    "objectID": "slides/trust-causal/index.html#llama2-accessory",
    "href": "slides/trust-causal/index.html#llama2-accessory",
    "title": "Trust and Causal Reasoning",
    "section": "LLaMA2-Accessory",
    "text": "LLaMA2-Accessory\n\n\nLearn more: LLaMA2-Accessory"
  },
  {
    "objectID": "slides/trust-causal/index.html#multilingual-token-analysis",
    "href": "slides/trust-causal/index.html#multilingual-token-analysis",
    "title": "Trust and Causal Reasoning",
    "section": "MultiLingual Token Analysis",
    "text": "MultiLingual Token Analysis\n\n\nLearn more: Video: LLaMA2 Multilingual Models and Fine Tuning\nGoogle Collab Notebook:"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2",
    "href": "slides/trust-causal/index.html#metaai-dinov2",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2",
    "text": "MetaAI DINOv2\n\n\nLearn more: DINOv2 by Meta AI"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "href": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2 Huggingface Release",
    "text": "MetaAI DINOv2 Huggingface Release\n\n\nLearn more: DINOv2 by Meta AI Huggingface"
  },
  {
    "objectID": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "href": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "title": "Trust and Causal Reasoning",
    "section": "Example notebook for DINOv2 Semantic Segmentation",
    "text": "Example notebook for DINOv2 Semantic Segmentation\n\n\nLearn more: Linear probing of DINOv2 for semantic segmentation"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/nuggets_review/index.html#where-we-started",
    "href": "slides/nuggets_review/index.html#where-we-started",
    "title": "A Summer of Nuggets",
    "section": "Where we started…",
    "text": "Where we started…"
  },
  {
    "objectID": "slides/nuggets_review/index.html#where-were-going",
    "href": "slides/nuggets_review/index.html#where-were-going",
    "title": "A Summer of Nuggets",
    "section": "Where we’re going…",
    "text": "Where we’re going…\n\n\n\n\nAI Success Factors: Engineering Trust in Deployments"
  },
  {
    "objectID": "slides/nuggets_review/index.html#this-is-meant-to-provide-something-of-a-roadmap",
    "href": "slides/nuggets_review/index.html#this-is-meant-to-provide-something-of-a-roadmap",
    "title": "A Summer of Nuggets",
    "section": "This is meant to provide something of a “Roadmap”!",
    "text": "This is meant to provide something of a “Roadmap”!"
  },
  {
    "objectID": "slides/nuggets_review/index.html#video-link",
    "href": "slides/nuggets_review/index.html#video-link",
    "title": "A Summer of Nuggets",
    "section": "Video Link",
    "text": "Video Link"
  },
  {
    "objectID": "slides/nuggets_review/index.html#old-school-ai-and-the-web",
    "href": "slides/nuggets_review/index.html#old-school-ai-and-the-web",
    "title": "A Summer of Nuggets",
    "section": "“Old School AI” and the Web…",
    "text": "“Old School AI” and the Web…\n\n\nA vision of “Ontologies”, “Linked Data”, and “Software Agents”…\n\n\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. “The Semantic Web.” Scientific American 284, no. 5 (2001): 34–43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/nuggets_review/index.html#old-school-cool-ai-and-the-web-2001",
    "href": "slides/nuggets_review/index.html#old-school-cool-ai-and-the-web-2001",
    "title": "A Summer of Nuggets",
    "section": "Old School “Cool” AI and the Web (2001)…",
    "text": "Old School “Cool” AI and the Web (2001)…\n\n\nThe semantic web had a vision of Agents with Shared Understanding through Ontologies, the ability to Use Tools Like the Web and Consume a Web of Linked Data as Distibuted Knowledge Graphs.\n\n\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. “The Semantic Web.” Scientific American 284, no. 5 (2001): 34–43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/nuggets_review/index.html#whats-an-ontology",
    "href": "slides/nuggets_review/index.html#whats-an-ontology",
    "title": "A Summer of Nuggets",
    "section": "What’s an Ontology?",
    "text": "What’s an Ontology?\n\n\nTom Gruber. “Ontology.” In Encyclopedia of Database Systems, edited by Ling Liu and M. Tamer Özsu, 1–3. New York, NY: Springer, 2016. https://doi.org/10.1007/978-1-4899-7993-3_1318-2."
  },
  {
    "objectID": "slides/nuggets_review/index.html#ontology-design-patterns",
    "href": "slides/nuggets_review/index.html#ontology-design-patterns",
    "title": "A Summer of Nuggets",
    "section": "Ontology Design Patterns",
    "text": "Ontology Design Patterns\n\n\n\n\n\n\n\n\nEva Blomqvist, Pascal Hitzler, Krzysztof Janowicz, Adila Krisnadhi, Tom Narock, and Monika Solanki. “Considerations Regarding Ontology Design Patterns.” Semantic Web 7, no. 1 (November 10, 2015): 1–7. https://doi.org/10.3233/SW-150202."
  },
  {
    "objectID": "slides/nuggets_review/index.html#google-search-and-the-semantic-web",
    "href": "slides/nuggets_review/index.html#google-search-and-the-semantic-web",
    "title": "A Summer of Nuggets",
    "section": "Google Search and the “Semantic Web”",
    "text": "Google Search and the “Semantic Web”\n\n\n\n\n\n\n\n\nGoogle. “Introducing the Knowledge Graph: Things, Not Strings,” May 16, 2012. https://blog.google/products/search/introducing-knowledge-graph-things-not/.\nGoogle. “A Reintroduction to Our Knowledge Graph and Knowledge Panels,” May 20, 2020. https://blog.google/products/search/about-knowledge-graph-and-knowledge-panels/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs",
    "href": "slides/nuggets_review/index.html#knowledge-graphs",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs\n\n\n\n\n\n\n\n\nHogan, Aidan, Eva Blomqvist, Michael Cochez, Claudia d’Amato, Gerard de Melo, Claudio Gutiérrez, Sabrina Kirrane, et al. Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge 22. Springer, 2021. https://doi.org/10.2200/S01125ED1V01Y202109DSK022."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-1",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-1",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs\n\n\nWhat’s a Knowledge Graph?\n\n\n\n\n\nHogan, Aidan, Eva Blomqvist, Michael Cochez, Claudia d’Amato, Gerard de Melo, Claudio Gutiérrez, Sabrina Kirrane, et al. Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge 22. Springer, 2021. https://doi.org/10.2200/S01125ED1V01Y202109DSK022."
  },
  {
    "objectID": "slides/nuggets_review/index.html#ai-in-2023..",
    "href": "slides/nuggets_review/index.html#ai-in-2023..",
    "title": "A Summer of Nuggets",
    "section": "AI in 2023..",
    "text": "AI in 2023.."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-ai-social-disruption",
    "href": "slides/nuggets_review/index.html#the-ai-social-disruption",
    "title": "A Summer of Nuggets",
    "section": "The “AI Social Disruption”",
    "text": "The “AI Social Disruption”\n\n\n\n\nJames Gary, “AI – The Social Disruption”, AI Magazine 42, no. 1 (April 12, 2021), Cover."
  },
  {
    "objectID": "slides/nuggets_review/index.html#pretrained-foundation-models",
    "href": "slides/nuggets_review/index.html#pretrained-foundation-models",
    "title": "A Summer of Nuggets",
    "section": "Pretrained Foundation Models…",
    "text": "Pretrained Foundation Models…\n\n\n\n\nZhou, Ce, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, et al. “A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.” arXiv, May 1, 2023. https://doi.org/10.48550/arXiv.2302.09419."
  },
  {
    "objectID": "slides/nuggets_review/index.html#evolution-of-large-language-models",
    "href": "slides/nuggets_review/index.html#evolution-of-large-language-models",
    "title": "A Summer of Nuggets",
    "section": "Evolution of Large Language Models",
    "text": "Evolution of Large Language Models\n\n\n\n\nYang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. “Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.” arXiv, April 27, 2023. https://doi.org/10.48550/arXiv.2304.13712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformerattention-is-all-you-need",
    "href": "slides/nuggets_review/index.html#transformerattention-is-all-you-need",
    "title": "A Summer of Nuggets",
    "section": "Transformer:“Attention is all you need”",
    "text": "Transformer:“Attention is all you need”\n\n\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” arXiv, August 1, 2023. https://doi.org/10.48550/arXiv.1706.03762."
  },
  {
    "objectID": "slides/nuggets_review/index.html#explain-the-transformer-neural-network-architecture-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "href": "slides/nuggets_review/index.html#explain-the-transformer-neural-network-architecture-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "title": "A Summer of Nuggets",
    "section": "“Explain the transformer neural network architecture to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”",
    "text": "“Explain the transformer neural network architecture to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nAlright, let’s get into it! Imagine you’re at a party and you’re trying to catch snippets of multiple conversations. You’re not just listening to the words, but also noticing who’s talking to whom, the tone, the context, and you’re making judgments about what’s important or not. That’s kinda what the Transformer architecture does, but for sequences of data like sentences or time-series data.\nAt the core, a Transformer has two main parts: the Encoder and the Decoder. Each has multiple identical layers stacked on top of each other.\n\nEncoder: Takes in the sequence (like a sentence “Hello, how are you?”) and processes it as a whole. It outputs a sort of “summary” or “context” for each word in the sequence.\n\nSelf-Attention: Each word checks out all the other words and figures out which ones are important to it. The magic formula called attention scores helps in this.\nFeed-forward neural networks: After attention, each word passes through a mini neural network that’s the same for all words, transforming it yet again."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-1",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-1",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\n\nDecoder: Takes these encodings and starts generating the output sequence (say, a translation of the original sentence into another language).\n\nMasked Self-Attention: Similar to the encoder, but in a way that it can’t cheat and look at future words in the output sequence.\nEncoder-Decoder Attention: The decoder takes a peek at the encoder’s output to better understand the context and produce the correct next word.\nFeed-forward neural networks: Same drill as the encoder, another mini network for transforming words."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-2",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-2",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nSo the magic here is mainly in how words interact with each other through the attention mechanism. Each word looks at all the other words to decide how much focus it should get, like how you tune in to different voices at a party. It does this not once, but multiple times, diving deeper and deeper into the context each time.\nIt’s like a super-efficient assembly line for sequences, enabling models like me to generate text or translate languages at scale. And this architecture has been the basis for a lot of breakthroughs in natural language processing. It’s versatile, parallelizable, and mighty powerful!"
  },
  {
    "objectID": "slides/nuggets_review/index.html#some-llm-neural-networks-use-encoder-decoder-networks.-some-llm-neural-networks-are-encoder-only-and-some-are-decoder-only-like-gpt.-explain-that-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "href": "slides/nuggets_review/index.html#some-llm-neural-networks-use-encoder-decoder-networks.-some-llm-neural-networks-are-encoder-only-and-some-are-decoder-only-like-gpt.-explain-that-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "title": "A Summer of Nuggets",
    "section": "“Some LLM Neural Networks use encoder-decoder networks. Some LLM neural networks are encoder only and some are decoder only like GPT. Explain that to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”",
    "text": "“Some LLM Neural Networks use encoder-decoder networks. Some LLM neural networks are encoder only and some are decoder only like GPT. Explain that to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-3",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-3",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nAh, good question! Think of it like this: you’ve got three types of orchestras. One plays both classical and jazz seamlessly (encoder-decoder), another specializes only in classical (encoder), and the last one is all about that jazz (decoder).\n\nEncoder-Decoder Networks: These are like your all-rounder orchestras. In the machine learning world, these models are often used for tasks like machine translation. The encoder part processes the input language, let’s say, English, and the decoder part spits out the output in another language, maybe Spanish. They work together like a well-conducted orchestra, each contributing to the final masterpiece.\nEncoder-Only Networks: Imagine an orchestra that’s focused entirely on classical music, where each musician feeds into the other to create a beautiful symphony. In tech, these models are good for tasks like text classification or sentiment analysis. The encoder processes the text and summarizes it in a way that lets you say, “Ah, this review is positive!”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-4",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-4",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\n\nDecoder-Only Networks: Now, these are your jazz specialists, all about improvisation and solos. GPT models, like the one you’re talking to, belong to this category. The decoder starts with a seed (your prompt) and keeps generating one word at a time, predicting the next best word until it forms a coherent reply. It doesn’t need to look back at an original input sentence like in translation; it just jams out text based on what it has learned during its training.\n\nSo, you’ve got different setups for different gigs. If you need a two-way conversation between languages, you go for the encoder-decoder. If you want to understand the essence of a piece of text, you’d lean on the encoder. And if you want to generate text, like writing or even code, the decoder is your go-to musician. Each has its own style, its own instruments, and its own unique approach to making beautiful “music”—or in our case, useful computations."
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-do-these-relate-to-the-transformer-architecture",
    "href": "slides/nuggets_review/index.html#how-do-these-relate-to-the-transformer-architecture",
    "title": "A Summer of Nuggets",
    "section": "“How do these relate to the Transformer architecture”",
    "text": "“How do these relate to the Transformer architecture”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-5",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-5",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nGreat follow-up! Alright, think of the Transformer architecture as a fancy new instrument—a versatile electric guitar, let’s say, that can produce a whole range of sounds from classical to rock to jazz. Now, just like you can use that electric guitar in different types of bands, you can use parts of the Transformer architecture in different types of models.\n\nEncoder-Decoder Networks with Transformers: When people initially talked about Transformers, they were often referring to the full shebang—both encoder and decoder. In a language translation model, the Transformer’s encoder reads an English sentence and compresses its essence. The decoder then takes this essence and generates a Spanish sentence. Both sides are using self-attention, layer normalization, and all those Transformer goodies to do their jobs.\nEncoder-Only Transformers: In some tasks, you don’t need the full band; a guitar solo will do. For instance, BERT (Bidirectional Encoder Representations from Transformers) uses just the encoder part of the Transformer architecture. It processes a sentence and spits out a rich, contextual representation of each word, which can then be used for tasks like text classification or filling in blanks.\nDecoder-Only Transformers: Now, what if we only want to jam and improvise? That’s where models like GPT (Generative Pre-trained Transformer) come in. These models use only the decoder part of the Transformer architecture to generate new text. They still use self-attention and feed-forward layers, but they are more about predicting the next note—or in our case, the next word—in a sequence."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-6",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-6",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nSo there you go! Just like our versatile electric guitar can be part of a full orchestra, a rock band, or a solo act, different pieces of the Transformer architecture can be used to construct different kinds of neural network models. Each specialized version takes the core principles of the Transformer and applies them in a way that’s tailored to specific tasks."
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-to-build-a-chatgpt",
    "href": "slides/nuggets_review/index.html#how-to-build-a-chatgpt",
    "title": "A Summer of Nuggets",
    "section": "How to Build a ChatGPT?",
    "text": "How to Build a ChatGPT?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt-you-should-watch-this",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt-you-should-watch-this",
    "title": "A Summer of Nuggets",
    "section": "“The state of GPT” – You should watch this!",
    "text": "“The state of GPT” – You should watch this!\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt",
    "title": "A Summer of Nuggets",
    "section": "“The state of GPT”",
    "text": "“The state of GPT”\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-from-a-more-general-view",
    "href": "slides/nuggets_review/index.html#large-language-models-from-a-more-general-view",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models from a more general view…",
    "text": "Large Language Models from a more general view…\n\n\n\n\n“Making Large Language Models Work for You.” Accessed August 27, 2023. https://simonwillison.net/2023/Aug/27/wordcamp-llms/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#text-to-numbers",
    "href": "slides/nuggets_review/index.html#text-to-numbers",
    "title": "A Summer of Nuggets",
    "section": "Text to numbers…",
    "text": "Text to numbers…\n\n\n\n\n“Tiktokenizer.” Accessed August 27, 2023. https://tiktokenizer.vercel.app/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt",
    "href": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt",
    "title": "A Summer of Nuggets",
    "section": "Base models create general representations through “Pre-Training” (GPT)",
    "text": "Base models create general representations through “Pre-Training” (GPT)\n\n\n\n\nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” n.d."
  },
  {
    "objectID": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt-1",
    "href": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt-1",
    "title": "A Summer of Nuggets",
    "section": "Base models create general representations through “Pre-Training” (GPT)",
    "text": "Base models create general representations through “Pre-Training” (GPT)\n\n\n\n\nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. “Improving Language Understanding by Generative Pre-Training,” n.d."
  },
  {
    "objectID": "slides/nuggets_review/index.html#pre-training-datasets",
    "href": "slides/nuggets_review/index.html#pre-training-datasets",
    "title": "A Summer of Nuggets",
    "section": "“Pre-Training Datasets?”",
    "text": "“Pre-Training Datasets?”"
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models",
    "href": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models",
    "title": "A Summer of Nuggets",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, et al. “LLaMA: Open and Efficient Foundation Language Models.” arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models-1",
    "href": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models-1",
    "title": "A Summer of Nuggets",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, et al. “LLaMA: Open and Efficient Foundation Language Models.” arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gao-et-al.-the-pile",
    "href": "slides/nuggets_review/index.html#gao-et-al.-the-pile",
    "title": "A Summer of Nuggets",
    "section": "Gao et al. “The Pile”?",
    "text": "Gao et al. “The Pile”?\n\n\n\n\n \n\n\n\nGao, Leo, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, et al. “The Pile: An 800GB Dataset of Diverse Text for Language Modeling.” arXiv, December 31, 2020. https://doi.org/10.48550/arXiv.2101.00027."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gao-et-al.-the-pile-1",
    "href": "slides/nuggets_review/index.html#gao-et-al.-the-pile-1",
    "title": "A Summer of Nuggets",
    "section": "Gao et al. “The Pile”?",
    "text": "Gao et al. “The Pile”?\n\n\n\n\n \n\n\n\nGao, Leo, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, et al. “The Pile: An 800GB Dataset of Diverse Text for Language Modeling.” arXiv, December 31, 2020. https://doi.org/10.48550/arXiv.2101.00027."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong-1",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong-1",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\n\n\n\n“Sarah Silverman Sues OpenAI and Meta Alleging Copyright Infringement | CNN Business.” Accessed August 27, 2023. https://www.cnn.com/2023/07/10/tech/sarah-silverman-openai-meta-lawsuit/index.html."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong-2",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong-2",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\n\n\n\n“Would I forbid the teaching (if that is the word) of my stories to computers? Not even if I could. I might as well be King Canute, forbidding the tide to come in. Or a Luddite trying to stop industrial progress by hammering a steam loom to pieces.” – Stephen King\n\n\n\nReisner, Alex. “Revealed: The Authors Whose Pirated Books Are Powering Generative AI.” The Atlantic, August 19, 2023. https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/.\nKing, Stephen. “Stephen King: My Books Were Used to Train AI.” The Atlantic, August 23, 2023. https://www.theatlantic.com/books/archive/2023/08/stephen-king-books-ai-writing/675088/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-language-models-are-few-shot-learners-2020",
    "href": "slides/nuggets_review/index.html#gpt-3-language-models-are-few-shot-learners-2020",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Language Models are Few-Shot Learners (2020)",
    "text": "(GPT-3) Language Models are Few-Shot Learners (2020)\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. “Language Models Are Few-Shot Learners.” arXiv, July 22, 2020. https://doi.org/10.48550/arXiv.2005.14165."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-in-context-learning",
    "href": "slides/nuggets_review/index.html#gpt-3-in-context-learning",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) In-Context Learning",
    "text": "(GPT-3) In-Context Learning\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. “Language Models Are Few-Shot Learners.” arXiv, July 22, 2020. https://doi.org/10.48550/arXiv.2005.14165."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "href": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. “Training Language Models to Follow Instructions with Human Feedback.” arXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback-1",
    "href": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al. “Training Language Models to Follow Instructions with Human Feedback.” arXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nBubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-1",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nBubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-2",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-2",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nBubeck, Sébastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al. “Sparks of Artificial General Intelligence: Early Experiments with GPT-4.” arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-3",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-3",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) “Sparks of AGI”?",
    "text": "(GPT-4) “Sparks of AGI”?\n\n\n\n\nSparks of AGI: Early Experiments with GPT-4, 2023. https://www.youtube.com/watch?v=qbIk7-JPB2c."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llm-behavior-changes-with-time",
    "href": "slides/nuggets_review/index.html#llm-behavior-changes-with-time",
    "title": "A Summer of Nuggets",
    "section": "LLM Behavior Changes with Time!",
    "text": "LLM Behavior Changes with Time!\n\n\n\n\nChen, Lingjiao, Matei Zaharia, and James Zou. “How Is ChatGPT’s Behavior Changing over Time?” arXiv, July 18, 2023. http://arxiv.org/abs/2307.09009."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-towards-truthgpt",
    "href": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-towards-truthgpt",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) OpenAI Reinforcement Learning – “Towards TruthGPT”",
    "text": "(GPT-4) OpenAI Reinforcement Learning – “Towards TruthGPT”\n\n\n\n\nJohn Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges, 2023. https://www.youtube.com/watch?v=hhiLw5Q_UFg."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-conceptual-models",
    "href": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-conceptual-models",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) OpenAI Reinforcement Learning – “Conceptual Models”",
    "text": "(GPT-4) OpenAI Reinforcement Learning – “Conceptual Models”\n\n\n\n\nJohn Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges, 2023. https://www.youtube.com/watch?v=hhiLw5Q_UFg."
  },
  {
    "objectID": "slides/nuggets_review/index.html#claude-constitutional-ai",
    "href": "slides/nuggets_review/index.html#claude-constitutional-ai",
    "title": "A Summer of Nuggets",
    "section": "(Claude) “Constitutional AI”",
    "text": "(Claude) “Constitutional AI”\n\n\n\n\nAnthropic. “Claude’s Constitution.” Accessed August 28, 2023. https://www.anthropic.com/index/claudes-constitution.\nBai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, et al. “Constitutional AI: Harmlessness from AI Feedback.” arXiv, December 15, 2022. https://doi.org/10.48550/arXiv.2212.08073."
  },
  {
    "objectID": "slides/nuggets_review/index.html#claude-foundation-model-in-aws-bedrock",
    "href": "slides/nuggets_review/index.html#claude-foundation-model-in-aws-bedrock",
    "title": "A Summer of Nuggets",
    "section": "(Claude) “Foundation Model in AWS Bedrock”",
    "text": "(Claude) “Foundation Model in AWS Bedrock”\n\n\n\n\n\n\n\n\nAnthropic. “Claude 2.” Accessed August 28, 2023. https://www.anthropic.com/index/claude-2.\nAnthropic. “Claude 2 on Amazon Bedrock.” Accessed August 28, 2023. https://www.anthropic.com/index/claude-2-amazon-bedrock."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-2open-license-large-language-models",
    "href": "slides/nuggets_review/index.html#llama-2open-license-large-language-models",
    "title": "A Summer of Nuggets",
    "section": "(Llama 2)“Open-License” Large Language Models",
    "text": "(Llama 2)“Open-License” Large Language Models\n\n\n\n\nMeta AI. “Meta and Microsoft Introduce the Next Generation of Llama.” Accessed August 28, 2023. https://ai.meta.com/blog/llama-2/.\nMeta AI. “Llama 2.” Accessed August 28, 2023. https://ai.meta.com/llama-project."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt-recommendations",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt-recommendations",
    "title": "A Summer of Nuggets",
    "section": "“The state of GPT” Recommendations",
    "text": "“The state of GPT” Recommendations\n\n\n\n\nAndrej Karpathy, “State of GPT” | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#reasoning",
    "href": "slides/nuggets_review/index.html#reasoning",
    "title": "A Summer of Nuggets",
    "section": "Reasoning…",
    "text": "Reasoning…"
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "href": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. “Large Language Models Are Zero-Shot Reasoners.” arXiv, January 29, 2023. https://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning-1",
    "href": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. “Large Language Models Are Zero-Shot Reasoners.” arXiv, January 29, 2023. https://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\n“ReAct: Synergizing Reasoning and Acting in Language Models.” Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. “ReAct: Synergizing Reasoning and Acting in Language Models.” arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-1",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-1",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\n“ReAct: Synergizing Reasoning and Acting in Language Models.” Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. “ReAct: Synergizing Reasoning and Acting in Language Models.” arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-2",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-2",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\n“ReAct: Synergizing Reasoning and Acting in Language Models.” Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. “ReAct: Synergizing Reasoning and Acting in Language Models.” arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#prompt-engineering",
    "href": "slides/nuggets_review/index.html#prompt-engineering",
    "title": "A Summer of Nuggets",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n\n\n\n\n“Prompt Engineering Guide.” Accessed August 22, 2023. https://www.promptingguide.ai/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners",
    "href": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models are Semantic Reasoners",
    "text": "Large Language Models are Semantic Reasoners\n\n\n\n\nTang, Xiaojuan, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. “Large Language Models Are In-Context Semantic Reasoners Rather than Symbolic Reasoners.” arXiv, June 8, 2023. http://arxiv.org/abs/2305.14825."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners-1",
    "href": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners-1",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models are Semantic Reasoners",
    "text": "Large Language Models are Semantic Reasoners\n\n\n\n\n\n\n\n\nTang, Xiaojuan, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. “Large Language Models Are In-Context Semantic Reasoners Rather than Symbolic Reasoners.” arXiv, June 8, 2023. http://arxiv.org/abs/2305.14825."
  },
  {
    "objectID": "slides/nuggets_review/index.html#our-research",
    "href": "slides/nuggets_review/index.html#our-research",
    "title": "A Summer of Nuggets",
    "section": "Our Research…",
    "text": "Our Research…"
  },
  {
    "objectID": "slides/nuggets_review/index.html#retrevial-augmented-generation",
    "href": "slides/nuggets_review/index.html#retrevial-augmented-generation",
    "title": "A Summer of Nuggets",
    "section": "Retrevial Augmented Generation",
    "text": "Retrevial Augmented Generation"
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-and-llms-must-read",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-and-llms-must-read",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs and LLMs – Must Read!",
    "text": "Knowledge Graphs and LLMs – Must Read!\n\n\n\n\nPan, Shirui, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-and-frameworks",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-and-frameworks",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs and Frameworks",
    "text": "Knowledge Graphs and Frameworks\n\n\n\n\nPan, Shirui, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-about-trusted-ai",
    "href": "slides/nuggets_review/index.html#what-about-trusted-ai",
    "title": "A Summer of Nuggets",
    "section": "What About Trusted AI?",
    "text": "What About Trusted AI?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-to-talk-about-llms-must-read",
    "href": "slides/nuggets_review/index.html#how-to-talk-about-llms-must-read",
    "title": "A Summer of Nuggets",
    "section": "How to talk about LLMs? Must Read!",
    "text": "How to talk about LLMs? Must Read!\n\n\n\n\nShanahan, Murray. “Talking About Large Language Models.” arXiv, February 16, 2023. https://doi.org/10.48550/arXiv.2212.03551."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to “translational research,” a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your “About” page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "href": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to “translational research,” a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your “About” page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#our-toolset",
    "href": "about.html#our-toolset",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Our Toolset",
    "text": "Our Toolset\nAI Success Factors: Engineering Trust in Deployments is more than just a blog - it’s a demonstration of how modern data science tools can streamline and simplify complex processes.\nOur blogging platform is built using Quarto, an open-source scientific and technical publishing system known for its flexibility and robustness. Quarto has the unique ability to support a wide range of content types, including Jupyter notebooks, R Markdown, and even Python or R scripts. Quarto’s distinctive feature is its ability to include executable code within the documents from various languages such as Python, R, and others. This allows us to create data-driven blog posts where the output - be it a graph, a table, or other data representations - is generated directly from the included code. This adds an interactive element to our posts, giving readers a deeper understanding of the concepts and analyses presented. Quarto supports multiple output formats including HTML, PDF, EPUB, and Word, providing us the versatility to tailor our content to suit different needs. This flexible tool, coupled with its capability to handle larger projects made up of multiple files, allows us to efficiently manage our blog while maintaining consistency and quality across our posts. Quarto presentations are also used to generate revealjs presentations for weekly slide shows. Quarto forms the basis for Fast.ai’s nbdev framework for exploritory programming allowing for software development in Jupyter Notebooks and automated generation of Python modules and documentation from the notebooks.\nDevelopment Containers serve as our primary environment for data science, providing a consistent and replicable framework for running our analyses. These containerized environments allow us to standardize our work and ensure that our research is reproducible and reliable. The dev container uses the Mamba solver to provision the python environment from the specification in the environment.yml.\nWe use Visual Studio Code (VS Code) as our primary code editor, taking advantage of its rich ecosystem of extensions and in-built features. VS Code’s Jupyter notebook support allows us to interactively develop and visualize our data models directly within the editor, enabling us to produce intuitive, data-driven narratives for our blog posts.\nAll of our content is version controlled and hosted on GitHub. GitHub’s robust versioning system allows us to effectively manage changes, track progress, and ensure that every piece of content we publish is up to date and accurate.\nThe blog is published using GitHub Page, a platform that simplifies the deployment process and seamlessly integrates with our existing GitHub repository. This setup enables us to provide a reliable, accessible resource for our readers, irrespective of where they are or when they choose to access our content.\nFinally, we utilize GitHub Code Spaces to create a fully-featured, cloud-hosted development environment that can be accessed from any device. This not only allows us to work from anywhere but also ensures that our setup can be easily replicated by other researchers and developers who wish to explore our code.\nEach tool in our stack has been chosen for its ability to facilitate efficient, reliable, and transparent data science. By sharing our toolset, we hope to provide insight into our workflows and encourage a culture of open, reproducible research within the AI community."
  },
  {
    "objectID": "about.html#generative-ai-in-content-creation",
    "href": "about.html#generative-ai-in-content-creation",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Generative AI in Content Creation",
    "text": "Generative AI in Content Creation\nIn creating AI Success Factors: Engineering Trust in Deployments, we harness the power of artificial intelligence in conjunction with human expertise. We utilize advanced Generative AI models such as ChatGPT, Bing Chat, and Anthropic Claude in a guided, iterative process that combines the best of AI and human capabilities.\nOur use of Generative AI begins with the drafting stage. These models, trained on extensive datasets, generate human-like text that matches our specified tone and style, providing us with a solid foundation for each blog post. This allows us to focus on the larger narrative without getting mired in the nitty-gritty details from the outset.\nThe AI-generated drafts, while sophisticated, are just the starting point. We employ a methodology that involves guiding the AI to improve its output. This includes providing more detailed prompts, specifying the format we want the output in, or asking the model to think step-by-step before settling on a conclusion.\nOnce we have a draft that we’re satisfied with, it’s time for human intervention. Our team reviews the AI-generated content, refining and editing it to ensure it maintains the standards of accuracy, relevance, and depth that our readers expect. This process leverages critical human skills of creativity, critical thinking, and domain expertise that even the most advanced AI can’t replicate.\nThis approach exemplifies our vision of a symbiotic relationship between AI and humans. By effectively integrating Generative AI into our content creation process, we not only boost our productivity and efficiency but also demonstrate the practical application of AI technologies in real-world scenarios. Thus, the blog becomes a testament to our commitment to translational research and our pursuit of an AI-integrated future."
  },
  {
    "objectID": "slides/building_stuff/index.html#building-stuff",
    "href": "slides/building_stuff/index.html#building-stuff",
    "title": "Building “Stuff”?",
    "section": "Building “Stuff”…",
    "text": "Building “Stuff”…\n\n\nLearn More: Effective testing for machine learning systems\nYoutube Discussion: MLOps Chat: How Should We Test ML Models? with Data Scientist Jeremy Jordan"
  },
  {
    "objectID": "slides/building_stuff/index.html#building-stuff-1",
    "href": "slides/building_stuff/index.html#building-stuff-1",
    "title": "Building “Stuff”?",
    "section": "Building “Stuff”…",
    "text": "Building “Stuff”…\n\n\n\n\n\n\n\n\n\n\n\nLearn More: Effective testing for machine learning systems"
  },
  {
    "objectID": "slides/building_stuff/index.html#instruction-prompts",
    "href": "slides/building_stuff/index.html#instruction-prompts",
    "title": "Building “Stuff”?",
    "section": "Instruction Prompts",
    "text": "Instruction Prompts"
  },
  {
    "objectID": "slides/building_stuff/index.html#reasoning-prompts",
    "href": "slides/building_stuff/index.html#reasoning-prompts",
    "title": "Building “Stuff”?",
    "section": "Reasoning Prompts",
    "text": "Reasoning Prompts"
  },
  {
    "objectID": "slides/building_stuff/index.html#big-models-vs-small-models",
    "href": "slides/building_stuff/index.html#big-models-vs-small-models",
    "title": "Building “Stuff”?",
    "section": "“Big Models” vs “Small Models”",
    "text": "“Big Models” vs “Small Models”"
  },
  {
    "objectID": "slides/building_stuff/index.html#open-source-community",
    "href": "slides/building_stuff/index.html#open-source-community",
    "title": "Building “Stuff”?",
    "section": "Open Source Community",
    "text": "Open Source Community\n\n\n\n\n\n\n\n\nMatt Bronstein and Rajko Radovanovic, “Supporting the Open Source AI Community,” Andreessen Horowitz, Aug. 30, 2023.\nhttps://a16z.com/2023/08/30/supporting-the-open-source-ai-community/ (accessed Sep. 03, 2023)."
  }
]
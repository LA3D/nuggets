[
  {
    "objectID": "instruction_prompt.html",
    "href": "instruction_prompt.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "ChatGPT, please assist in drafting a blog post for AI Success Factors: Engineering Trust in Deployments. As a generative AI, your input serves as a starting point for discussion and is meticulously reviewed and edited by a team of AI researchers at the Laboratory for Assured AI Applications Development at the University of Notre Dameâ€™s Center for Research Computing.\nThe intended audience includes students, professionals, and enthusiasts interested in the progression of AI, with a focus on the successful deployment of AI technologies. Each post aims to disseminate recent advancements and knowledge in AI, particularly in the fields of AI engineering, trust in AI, and knowledge engineering.\nFor this post, please generate content on the importance of trust in successful AI deployments. Begin with a general introduction to AI deployments, transition into the crucial role of trust, and provide real-world examples where the absence of trust led to issues. Discuss strategies for building trust in AI systems and conclude with insights on future trends in trust within the AI landscape. The tone should be academic yet accessible to our diverse readership."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "href": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing and CI/CD for Trusted AI",
    "text": "Testing and CI/CD for Trusted AI\nTesting and CI/CD are software engineering practices that aim to ensure the quality, reliability, and security of software applications. They are especially important for AI applications, which involve complex and dynamic data, models, and algorithms."
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "href": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "What is Software 1.0 and Software 2.0?",
    "text": "What is Software 1.0 and Software 2.0?\nSoftware 1.0 refers to the traditional way of developing software by writing code that specifies the logic and rules of the application. Software 2.0 refers to the emerging way of developing software by using machine learning (ML) models that learn from data and generate code or behavior."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Why do we need testing and CI/CD for AI?",
    "text": "Why do we need testing and CI/CD for AI?\nAI applications pose unique challenges and risks for testing and CI/CD, such as:\n\nData quality and availability: AI applications depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: AI models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: AI applications may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "href": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing and CI/CD can help address these challenges and risks by:",
    "text": "Testing and CI/CD can help address these challenges and risks by:\n\nAutomating and streamlining the data, model, and code workflows of AI development\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in AI applications\nEnsuring that AI applications meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of AI applications"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "How do we implement testing and CI/CD for AI?",
    "text": "How do we implement testing and CI/CD for AI?\nTesting and CI/CD for AI involve applying software engineering best practices to the data, model, and code components of AI applications. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing AI models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of AI models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates AI models"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Real World Machine Learning â€œPipelinesâ€",
    "text": "Real World Machine Learning â€œPipelinesâ€\n\n\nTwitter: Andrej Karpathy\nLearn More: Autonomous Vehicle Training & Teslaâ€™s Data Engine Explained, TESLAâ€™S DATA ENGINE AND WHAT WE SHOULD LEARN FROM IT CVPRâ€™20 Workshop on Scalability in Autonomous Driving Keynote - Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Real World Machine Learning â€œData Engineâ€",
    "text": "Real World Machine Learning â€œData Engineâ€\n\n\nTwitter: Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "href": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "How Teslaâ€™s Data Engine works",
    "text": "How Teslaâ€™s Data Engine works\n\nThe FSD computer in each Tesla car records and sends any inaccuracies or discrepancies between its actions and the human driverâ€™s actions to Teslaâ€™s servers.\nTeslaâ€™s servers use these inaccuracies to create unit tests, which are scenarios that the FSD neural network should be able to handle correctly.\nTeslaâ€™s servers also use these inaccuracies to search for similar situations in the vast amount of data collected from all the cars in the fleet and create a well-labeled dataset.\nTeslaâ€™s servers use this dataset to re-train the FSD neural network using machine learning algorithms and improve its performance and functionality.\nTeslaâ€™s servers deploy the updated FSD neural network to the carsâ€™ FSD computers in â€œshadow modeâ€ to compare its actions with the human driverâ€™s actions."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "href": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Why Teslaâ€™s Data Engine matters",
    "text": "Why Teslaâ€™s Data Engine matters\n\nTeslaâ€™s Data Engine allows them to leverage the power of big data analytics and artificial intelligence in their self-driving cars.\nTeslaâ€™s Data Engine enables them to address the long tail problem of autonomous driving, which is the challenge of handling rare or complex situations on the road.\nTeslaâ€™s Data Engine ensures that the FSD neural network is constantly improving and not regressing or introducing new errors.\n\n\nLearn More: [Teslaâ€™s Data Engine and what we should learn from it]"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "href": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "What is â€œTestingâ€ for AI vs Traditional Software Testing",
    "text": "What is â€œTestingâ€ for AI vs Traditional Software Testing\n\n\nLearn More: Effective testing for machine learning systems\nYoutube Discussion: MLOps Chat: How Should We Test ML Models? with Data Scientist Jeremy Jordan"
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Why do we need testing for ML systems?",
    "text": "Why do we need testing for ML systems?\nML systems pose unique challenges and risks for testing, such as:\n\nData quality and availability: ML systems depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: ML models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: ML systems may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability.\n\nTesting ML systems can help address these challenges and risks by:\n\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in ML systems\nEnsuring that ML systems meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of ML systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "href": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "How do we test ML systems?",
    "text": "How do we test ML systems?\nTesting ML systems involves applying software engineering best practices to the data, model, and code components of ML systems. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing ML models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of ML models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates ML models"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "href": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "What are some tools and techniques for testing ML systems?",
    "text": "What are some tools and techniques for testing ML systems?\nThere are different tools and techniques that can help us test ML systems effectively and efficiently. Some examples are:\n\nData validation tools: Tools that help us check the schema, statistics, anomalies, drifts, and distributions of our data. For example: TensorFlow Data Validation, Great Expectations, Deequ.\nModel validation tools: Tools that help us measure the performance of our models on various metrics and scenarios. For example: TensorFlow Model Analysis, Scikit-Learn, PyTorch.\nCode validation tools: Tools that help us check the syntax, style, coverage, complexity, and security of our code. For example: PyLint, PyTest, Bandit."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "href": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing â€œSoftware 1.0â€ vs â€œSoftware 2.0â€",
    "text": "Testing â€œSoftware 1.0â€ vs â€œSoftware 2.0â€\n\n\nLearn More: Effective testing for machine learning systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "href": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "â€œBeyond Accuracy: Behavioral Testing of NLP Models with CheckListâ€",
    "text": "â€œBeyond Accuracy: Behavioral Testing of NLP Models with CheckListâ€\n\n\nLearn More: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\nGitHub:Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Examples of â€œreal worldâ€ testing",
    "text": "Examples of â€œreal worldâ€ testing\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Examples of â€œreal worldâ€ testing as a starting point",
    "text": "Examples of â€œreal worldâ€ testing as a starting point\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "href": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Test Structure in the Microsoft Recommenders",
    "text": "Test Structure in the Microsoft Recommenders\nThe Microsoft Recommenders repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repository also includes various tests to ensure the quality, reliability, and security of the code and the notebooks."
  },
  {
    "objectID": "slides/tai_testing/index.html#types-of-tests",
    "href": "slides/tai_testing/index.html#types-of-tests",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Types of Tests",
    "text": "Types of Tests\nThere are three types of tests in the Microsoft Recommenders repository:\n\nUnit tests: These are tests that check the functionality and correctness of individual modules, functions, or classes. They are located in the unit folder and use pytest as the testing framework. They are triggered by pull requests to the main or staging branches.\nSmoke tests: These are tests that check if the notebooks can run without errors and produce the expected outputs. They are located in the smoke folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches.\nIntegration tests: These are tests that check if the notebooks can run end-to-end on different environments and platforms, such as CPU, GPU, or Spark. They are located in the integration folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing Infrastructure: Azure DevOps",
    "text": "Testing Infrastructure: Azure DevOps\nThe Microsoft Recommenders repository uses Azure DevOps as the testing infrastructure. Azure DevOps is a cloud-based platform that provides various services and tools for software development, such as version control, project management, testing, deployment, and monitoring.\nThere are 19 pipelines for Linux tests and 19 pipelines for Windows tests, each corresponding to a different type of test, branch, and environment. For example:\n\nunit_tests: This pipeline runs unit tests on Linux CPU for pull requests to the main branch.\nunit_tests_staging: This pipeline runs unit tests on Linux CPU for pull requests to the staging branch.\ngpu_unit_tests: This pipeline runs unit tests on Linux GPU for pull requests to the main branch.\ngpu_unit_tests_staging: This pipeline runs unit tests on Linux GPU for pull requests to the staging branch.\nnightly_cpu: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the main branch.\nnightly_staging: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the staging branch.\nnightly_gpu: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the main branch.\nnightly_gpu_staging: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the staging branch.\nnightly_spark: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the main branch.\nnightly_spark_staging: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the staging branch.\n\n\nLearn More: [Test Strategy Â· microsoft/recommenders Wiki Â· GitHub]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "href": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing Infrastructure: Conda Environments",
    "text": "Testing Infrastructure: Conda Environments\nThe pipelines use conda environments to manage dependencies and run tests. Conda is an open-source package and environment management system that allows us to create and use different configurations of software packages and libraries.\nA script, generate_conda_file.py, is used to create conda environments for different combinations of CPU, GPU, and Spark. For example:\n\nreco_base: This is the basic CPU environment.\nreco_full: This is the environment that includes CPU, GPU, and Spark.\nreco_gpu: This is the environment that includes CPU and GPU.\nreco_pyspark: This is the environment that includes CPU and Spark.\n\n\nLearn More: [Conda â€” Conda documentation]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing Infrastructure: Azure Machine Learning",
    "text": "Testing Infrastructure: Azure Machine Learning\nThe pipelines also use Azure Machine Learning (AML) to run some of the tests on different compute clusters. AML is a cloud-based service that provides various tools and features for ML development, such as data preparation, model training, model deployment, model management, and model monitoring.\nAML provides scalable and flexible compute resources for ML development. For example:\n\nAMLCompute clustername Experiment VM Nodes\nreco-cpu-test2 cpu_unit_tests standard_d3_v2 0..4\nreco-gpu-test gpu_unit_tests standard_nc6_v3 0..4\nreco-spark-test spark_unit_tests standard_d12_v2 0..4\n\n\nLearn More: [What is Azure Machine Learning? - Azure Machine Learning | Microsoft Docs]"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPTâ€™s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPTâ€™s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Tracking LLM â€œAgent Abilitiesâ€",
    "text": "Tracking LLM â€œAgent Abilitiesâ€\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Tracking LLM â€œAgent Abilitiesâ€",
    "text": "Tracking LLM â€œAgent Abilitiesâ€\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing in the context of CI/CD",
    "text": "Testing in the context of CI/CD\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Testing in the context of SBoMs",
    "text": "Testing in the context of SBoMs\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#other-updates",
    "href": "slides/tai_testing/index.html#other-updates",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Other Updates",
    "text": "Other Updates"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai",
    "href": "slides/tai_testing/index.html#juypter-ai",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter\nGitHub: A generative AI extension for JupyterLab"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai-1",
    "href": "slides/tai_testing/index.html#juypter-ai-1",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter"
  },
  {
    "objectID": "slides/tai_testing/index.html#kaggle-llm-resource",
    "href": "slides/tai_testing/index.html#kaggle-llm-resource",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Kaggle LLM Resource",
    "text": "Kaggle LLM Resource\n\n\nLearn More: Getting Started With LLMs"
  },
  {
    "objectID": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "href": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "title": "Things that concern Dr.Â Vardeman: Testing",
    "section": "Prompt Enginnering Guide",
    "text": "Prompt Enginnering Guide\n\n\nLearn More: Prompt Engineering Guide"
  },
  {
    "objectID": "slides/building_stuff/index.html#slides-link-httpsla3d.github.ionuggetsslideindex.html",
    "href": "slides/building_stuff/index.html#slides-link-httpsla3d.github.ionuggetsslideindex.html",
    "title": "Building â€œStuffâ€?",
    "section": "Slides Link: https://la3d.github.io/nuggets/slideindex.html",
    "text": "Slides Link: https://la3d.github.io/nuggets/slideindex.html"
  },
  {
    "objectID": "slides/building_stuff/index.html#building-stuff",
    "href": "slides/building_stuff/index.html#building-stuff",
    "title": "Building â€œStuffâ€?",
    "section": "Building â€œStuffâ€â€¦",
    "text": "Building â€œStuffâ€â€¦\n\n\nJeremy Jordan. â€œEffective Testing for Machine Learning Systems.,â€\nAugust 19, 2020. https://www.jeremyjordan.me/testing-ml/."
  },
  {
    "objectID": "slides/building_stuff/index.html#building-stuff-1",
    "href": "slides/building_stuff/index.html#building-stuff-1",
    "title": "Building â€œStuffâ€?",
    "section": "Building â€œStuffâ€â€¦",
    "text": "Building â€œStuffâ€â€¦"
  },
  {
    "objectID": "slides/building_stuff/index.html#section",
    "href": "slides/building_stuff/index.html#section",
    "title": "Building â€œStuffâ€?",
    "section": "",
    "text": "Building Stuff?\n\n\n\nBuilding Agents based on Large Language Models!"
  },
  {
    "objectID": "slides/building_stuff/index.html#you-are-almost-here",
    "href": "slides/building_stuff/index.html#you-are-almost-here",
    "title": "Building â€œStuffâ€?",
    "section": "You are â€œalmostâ€ here â¬‡ï¸",
    "text": "You are â€œalmostâ€ here â¬‡ï¸"
  },
  {
    "objectID": "slides/building_stuff/index.html#building-agents-involves-pre-trained-foundation-models",
    "href": "slides/building_stuff/index.html#building-agents-involves-pre-trained-foundation-models",
    "title": "Building â€œStuffâ€?",
    "section": "Building â€œAgentsâ€ Involves Pre-trained Foundation Modelsâ€¦",
    "text": "Building â€œAgentsâ€ Involves Pre-trained Foundation Modelsâ€¦\n\n\n\n\nZhou, Ce, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, et al.Â \nâ€œA Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.â€\narXiv, May 1, 2023.https://doi.org/10.48550/arXiv.2302.09419."
  },
  {
    "objectID": "slides/building_stuff/index.html#how-do-we-program-a-large-language-model",
    "href": "slides/building_stuff/index.html#how-do-we-program-a-large-language-model",
    "title": "Building â€œStuffâ€?",
    "section": "How do we â€œprogramâ€ a Large Language Model?",
    "text": "How do we â€œprogramâ€ a Large Language Model?"
  },
  {
    "objectID": "slides/building_stuff/index.html#autoregressive-large-language-model",
    "href": "slides/building_stuff/index.html#autoregressive-large-language-model",
    "title": "Building â€œStuffâ€?",
    "section": "Autoregressive Large Language Model",
    "text": "Autoregressive Large Language Model\nâ€œAn autoregressive large language model (AR-LLM) is a type of neural network model that can generate natural language text. It has a very large number of parameters (billions or trillions) that are trained on a huge amount of text data from various sources. The main goal of an AR-LLM is to predict the next word or token based on the previous words or tokens in the input text. For example, if the input text isâ€The sky isâ€, the AR-LLM might predict â€œblueâ€ as the next word. AR-LLMs can also generate text from scratch by sampling words from a probability distribution. For example, if the input text is empty, the AR-LLM might generate â€œOnce upon a time, there was a princess who lived in a castle.â€ as the output text.â€1\nBing Chat, Accessed: 09-05-23 https://sl.bing.net/vDC45Llquq"
  },
  {
    "objectID": "slides/building_stuff/index.html#ar-llms-can-simulate-turing-machines",
    "href": "slides/building_stuff/index.html#ar-llms-can-simulate-turing-machines",
    "title": "Building â€œStuffâ€?",
    "section": "AR-LLMs can simulate â€œTuring Machinesâ€",
    "text": "AR-LLMs can simulate â€œTuring Machinesâ€\n\n\n\n\nAbstract: We show that transformer-based large language models are computationally universal when augmented with an external memory. Any deterministic language model that conditions on strings of bounded length is equivalent to a finite automaton, hence computationally limited. However, augmenting such models with a read-write memory creates the possibility of processing arbitrarily large inputs and, potentially, simulating any algorithm. We establish that an existing large language model, Flan-U-PaLM 540B, can be combined with an associative read-write memory to exactly simulate the execution of a universal Turing machine, \\(U_{15,2}\\). A key aspect of the finding is that it does not require any modification of the language model weights. Instead, the construction relies solely on designing a form of stored instruction computer that can subsequently be programmed with a specific set of prompts.\n\n\nSchuurmans, Dale. â€œMemory Augmented Large Language Models Are Computationally Universal.â€\narXiv, January 9, 2023. https://doi.org/10.48550/arXiv.2301.04589."
  },
  {
    "objectID": "slides/building_stuff/index.html#what-kind-of-llm-agents-are-we-trying-to-build",
    "href": "slides/building_stuff/index.html#what-kind-of-llm-agents-are-we-trying-to-build",
    "title": "Building â€œStuffâ€?",
    "section": "What Kind of LLM Agents are we trying to build?",
    "text": "What Kind of LLM Agents are we trying to build?\n\n\nConversational Agents\nvs. Cognitive Autonomous Agents\nvs. Agents tuned for a Data Processing Task"
  },
  {
    "objectID": "slides/building_stuff/index.html#section-1",
    "href": "slides/building_stuff/index.html#section-1",
    "title": "Building â€œStuffâ€?",
    "section": "",
    "text": "We will focus on Conversational Agentsâ€¦"
  },
  {
    "objectID": "slides/building_stuff/index.html#the-best-advice-we-can-give",
    "href": "slides/building_stuff/index.html#the-best-advice-we-can-give",
    "title": "Building â€œStuffâ€?",
    "section": "The Best Advice we can Giveâ€¦",
    "text": "The Best Advice we can Giveâ€¦\n\n\n\n\nAndrej Karpathy, â€œState of GPTâ€ | BRK216HFS, Microsoft Build, 2023.\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#section-2",
    "href": "slides/building_stuff/index.html#section-2",
    "title": "Building â€œStuffâ€?",
    "section": "",
    "text": "Andrej Karpathy, â€œState of GPTâ€ | BRK216HFS, Microsoft Build, 2023.\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#caveat-you-are-at-the-edge-of-research-and-practice",
    "href": "slides/building_stuff/index.html#caveat-you-are-at-the-edge-of-research-and-practice",
    "title": "Building â€œStuffâ€?",
    "section": "Caveat: You are at the Edge of Research and Practice!",
    "text": "Caveat: You are at the Edge of Research and Practice!"
  },
  {
    "objectID": "slides/building_stuff/index.html#prompt-engineering",
    "href": "slides/building_stuff/index.html#prompt-engineering",
    "title": "Building â€œStuffâ€?",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nâ€œPrompt engineering is the process of designing and refining the prompts or input stimuli for a language model to generate specific types of output. Prompt engineering involves selecting appropriate keywords, providing context, and shaping the input in a way that encourages the model to produce the desired response and is a vital technique to actively shape the behavior and output of foundation models.â€1\nâ€œPrompt Engineering for Foundation Models - Amazon SageMaker.â€ Accessed September 4, 2023. http://tiny.cc/p3mavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "href": "slides/building_stuff/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "title": "Building â€œStuffâ€?",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al.\nâ€œTraining Language Models to Follow Instructions with Human Feedback.â€\narXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/building_stuff/index.html#instruction-tuning-facilitate-conversational-agents-to-converse-in-a-set-style",
    "href": "slides/building_stuff/index.html#instruction-tuning-facilitate-conversational-agents-to-converse-in-a-set-style",
    "title": "Building â€œStuffâ€?",
    "section": "Instruction Tuning Facilitate Conversational Agents to â€œConverseâ€ in a Set Style!",
    "text": "Instruction Tuning Facilitate Conversational Agents to â€œConverseâ€ in a Set Style!"
  },
  {
    "objectID": "slides/building_stuff/index.html#tools-for-prompt-engineering",
    "href": "slides/building_stuff/index.html#tools-for-prompt-engineering",
    "title": "Building â€œStuffâ€?",
    "section": "Tools for â€œPrompt Engineeringâ€",
    "text": "Tools for â€œPrompt Engineeringâ€\n\n\n\n\nHenry Zeng, Lauryn Gayhardt, Jill Grant â€œWhat is Azure Machine Learning prompt flow\n(preview) - Azure Machine Learning,â€ Jul.Â 02, 2023.\nhttp://tiny.cc/kelavz (accessed Sep.Â 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#tools-for-prompt-engineering-1",
    "href": "slides/building_stuff/index.html#tools-for-prompt-engineering-1",
    "title": "Building â€œStuffâ€?",
    "section": "Tools for â€œPrompt Engineeringâ€",
    "text": "Tools for â€œPrompt Engineeringâ€\n\n\n\n\nHenry Zeng, Lauryn Gayhardt, Jill Grant â€œWhat is Azure Machine Learning prompt flow\n(preview) - Azure Machine Learning,â€ Jul.Â 02, 2023.\nhttp://tiny.cc/kelavz (accessed Sep.Â 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents",
    "href": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents",
    "title": "Building â€œStuffâ€?",
    "section": "Trusted â€œPrompt Engineeringâ€ for Conversational Agents",
    "text": "Trusted â€œPrompt Engineeringâ€ for Conversational Agents\nâ€œNeMo Guardrails is an open-source toolkit for easily adding programmable guardrails to LLM-based conversational systems. Guardrails (orâ€railsâ€ for short) are specific ways of controlling the output of a large language model, such as not talking about politics, responding in a particular way to specific user requests, following a predefined dialog path, using a particular language style, extracting structured data, and more.â€1\nâ€œNeMo Guardrails.â€ NVIDIA Corporation, Sep.Â 05, 2023. Accessed: Sep.Â 05, 2023. [Online]. Available: https://github.com/NVIDIA/NeMo-Guardrails"
  },
  {
    "objectID": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents-1",
    "href": "slides/building_stuff/index.html#trusted-prompt-engineering-for-conversational-agents-1",
    "title": "Building â€œStuffâ€?",
    "section": "Trusted â€œPrompt Engineeringâ€ for Conversational Agents",
    "text": "Trusted â€œPrompt Engineeringâ€ for Conversational Agents\n\nBuilding Trustworthy, Safe, and Secure LLM Conversational Systems: The core value of using NeMo Guardrails is the ability to write rails to guide conversations. You can choose to define the behavior of your LLM-powered application on specific topics and prevent it from engaging in discussions on unwanted topics.\nConnect models, chains, services, and more via actions: NeMo Guardrails provides the ability to connect an LLM to other services (a.k.a. tools) seamlessly and securely.\n\n\nâ€œNeMo Guardrails.â€ NVIDIA Corporation, Sep.Â 05, 2023. Accessed: Sep.Â 05, 2023. [Online].\nAvailable: https://github.com/NVIDIA/NeMo-Guardrails"
  },
  {
    "objectID": "slides/building_stuff/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "href": "slides/building_stuff/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "title": "Building â€œStuffâ€?",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.\nâ€œLarge Language Models Are Zero-Shot Reasoners.â€ arXiv, January 29, 2023.\nhttps://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/building_stuff/index.html#llms-as-reasoners-using-prompts",
    "href": "slides/building_stuff/index.html#llms-as-reasoners-using-prompts",
    "title": "Building â€œStuffâ€?",
    "section": "LLMs as Reasoners using Prompts!",
    "text": "LLMs as Reasoners using Prompts!\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al\nâ€œGraph of Thoughts: Solving Elaborate Problems with Large Language Models.â€ arXiv, August 21, 2023.\nhttp://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/building_stuff/index.html#prompt-engineering-guide",
    "href": "slides/building_stuff/index.html#prompt-engineering-guide",
    "title": "Building â€œStuffâ€?",
    "section": "Prompt Engineering Guide",
    "text": "Prompt Engineering Guide\n\n\n\n\n\n\n\n\nâ€œPrompt Engineering Guide â€“ Nextra.â€\nhttps://www.promptingguide.ai/ (accessed Sep.Â 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual",
    "href": "slides/building_stuff/index.html#we-want-large-language-models-to-be-factual",
    "title": "Building â€œStuffâ€?",
    "section": "We want Large Language Models to be Factual!",
    "text": "We want Large Language Models to be Factual!\n\nFine-Tuning: augment the behavior of the model\nRetrieval: introduce new knowledge to the model\nRetreval Aware Training (RAT) Fine-tune the model to use or ignore retrieved content"
  },
  {
    "objectID": "slides/building_stuff/index.html#fine-tuning-foundation-models",
    "href": "slides/building_stuff/index.html#fine-tuning-foundation-models",
    "title": "Building â€œStuffâ€?",
    "section": "Fine-Tuning Foundation Models",
    "text": "Fine-Tuning Foundation Models\nâ€œFoundation models are computationally expensive and trained on a large, unlabeled corpus. Fine-tuning a pre-trained foundation model is an affordable way to take advantage of their broad capabilities while customizing a model on your own small, corpus. Fine-tuning is a customization method that involved further training and does change the weights of your modelâ€¦â€\nâ€œâ€¦There are two main approaches that you can take for fine-tuning depending on your use case and chosen foundation model. If youâ€™re interested in fine-tuning your model on domain-specific data, see Domain adaptation fine-tuning. If youâ€™re interested in instruction-based fine-tuning using prompt and response examples, see Instruction-based fine-tuning.â€1\nâ€œFine-tune a foundation model - Amazon SageMakerâ€, http://tiny.cc/grmavz (accessed Sep.Â 05, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#retrieval-augmented-generation-rag",
    "href": "slides/building_stuff/index.html#retrieval-augmented-generation-rag",
    "title": "Building â€œStuffâ€?",
    "section": "Retrieval Augmented Generation (RAG)",
    "text": "Retrieval Augmented Generation (RAG)\nâ€œFoundation models are usually trained offline, making the model agnostic to any data that is created after the model was trained. Additionally, foundation models are trained on very general domain corpora, making them less effective for domain-specific tasks. You can use Retrieval Augmented Generation (RAG) to retrieve data from outside a foundation model and augment your prompts by adding the relevant retrieved data in context. For more information about RAG model architecturesâ€1\nâ€œRetrieval Augmented Generation (RAG) - Amazon SageMaker.â€ Accessed September 4, 2023. http://tiny.cc/f3mavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#retrieval-augmented-generation-rag-1",
    "href": "slides/building_stuff/index.html#retrieval-augmented-generation-rag-1",
    "title": "Building â€œStuffâ€?",
    "section": "Retrieval Augmented Generation (RAG)",
    "text": "Retrieval Augmented Generation (RAG)\n\n\n\n\n\n\n\n\nâ€œRetrieval Augmented Generation (RAG) - Amazon SageMaker.â€ Accessed September 4, 2023.\nhttp://tiny.cc/f3mavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#llamaindex-to-build-hybrid-kgs",
    "href": "slides/building_stuff/index.html#llamaindex-to-build-hybrid-kgs",
    "title": "Building â€œStuffâ€?",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\n\n\n\n\n\n\nâ€œCustom Retriever Combining KG Index and VectorStore Index\n\nLlamaIndex ğŸ¦™ 0.8.5.Post2.â€ Accessed August 22, 2023.\n\nhttp://tiny.cc/oflavz."
  },
  {
    "objectID": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis",
    "href": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis",
    "title": "Building â€œStuffâ€?",
    "section": "Gorilla: Retrieval Aware Training for APIs",
    "text": "Gorilla: Retrieval Aware Training for APIs\n\n\n\n\n\n\n\n\nS. Patil, â€œGorilla: Large Language Model Connected with Massive APIs [Project Website].â€ Sep.Â 04, 2023.\nAccessed: Sep.Â 04, 2023. [Online]. Available: https://github.com/ShishirPatil/gorilla"
  },
  {
    "objectID": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis-1",
    "href": "slides/building_stuff/index.html#gorilla-retrieval-aware-training-for-apis-1",
    "title": "Building â€œStuffâ€?",
    "section": "Gorilla: Retrieval Aware Training for APIs",
    "text": "Gorilla: Retrieval Aware Training for APIs\n\n\n\n\n\n\n\n\nS. Patil, â€œGorilla: Large Language Model Connected with Massive APIs [Project Website].â€ Sep.Â 04, 2023.\nAccessed: Sep.Â 04, 2023. [Online]. Available: https://github.com/ShishirPatil/gorilla"
  },
  {
    "objectID": "slides/building_stuff/index.html#big-models-vs-small-models",
    "href": "slides/building_stuff/index.html#big-models-vs-small-models",
    "title": "Building â€œStuffâ€?",
    "section": "â€œBig Modelsâ€ vs â€œSmall Modelsâ€",
    "text": "â€œBig Modelsâ€ vs â€œSmall Modelsâ€\n\n\nModels as a service (Bedrock, OpenAI API, Anthropic Claude)\n\nGenerally more difficult to â€œFine-Tuneâ€ (GPT-3.5 turbo)1\nModels are generally more capable (Factuality, Instructions, Reasoning)]\nâ€œCoin-operatedâ€ pay per/token\n\nâ€œOpen Licenseâ€ 7B-70B Parameter Models\n\nMostly based on Meta AI LLama or LLama 2 models\nRequire more effort to work consistently\nModels can run on reduced hardware requirements\nCan be fine-tuned for task specific workflows\n\n\n\nâ€œGPT-3.5 Turbo fine-tuning and API updates.â€ https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates (accessed Sep.Â 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#small-models-with-custom-grammar-llama.cpp",
    "href": "slides/building_stuff/index.html#small-models-with-custom-grammar-llama.cpp",
    "title": "Building â€œStuffâ€?",
    "section": "Small Models with custom grammar (llama.cpp)",
    "text": "Small Models with custom grammar (llama.cpp)\nJSON-Grammar\nroot   ::= object\nvalue  ::= object | array | string | number | (\"true\" | \"false\" | \"null\") ws\n\nobject ::=\n  \"{\" ws (\n            string \":\" ws value\n    (\",\" ws string \":\" ws value)*\n  )? \"}\" ws\n\narray  ::=\n  \"[\" ws (\n            value\n    (\",\" ws value)*\n  )? \"]\" ws\n\nstring ::=\n  \"\\\"\" (\n    [^\"\\\\] |\n    \"\\\\\" ([\"\\\\/bfnrt] | \"u\" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]) # escapes\n  )* \"\\\"\" ws\n\nnumber ::= (\"-\"? ([0-9] | [1-9] [0-9]*)) (\".\" [0-9]+)? ([eE] [-+]? [0-9]+)? ws\n\n# Optional space: by convention, applied in this grammar after literal chars when allowed\nws ::= ([ \\t\\n] ws)?\n\nâ€œspeculativeâ€¯: add grammar support by ggerganov Â· Pull Request #2991 Â· ggerganov/llama.cpp,â€\nGitHub. https://github.com/ggerganov/llama.cpp/pull/2991 (accessed Sep.Â 04, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#the-state-of-gpt-recommendations",
    "href": "slides/building_stuff/index.html#the-state-of-gpt-recommendations",
    "title": "Building â€œStuffâ€?",
    "section": "â€œThe state of GPTâ€ Recommendations",
    "text": "â€œThe state of GPTâ€ Recommendations\n\n\n\n\nAndrej Karpathy, â€œState of GPTâ€ | BRK216HFS, Microsoft Build, 2023.\nhttps://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/building_stuff/index.html#open-source-community",
    "href": "slides/building_stuff/index.html#open-source-community",
    "title": "Building â€œStuffâ€?",
    "section": "Open Source Community",
    "text": "Open Source Community\n\n\n\n\n\n\n\n\nMatt Bronstein and Rajko Radovanovic, â€œSupporting the Open Source AI Community,â€\nAndreessen Horowitz, Aug.Â 30, 2023.\nhttp://tiny.cc/uflavz (accessed Sep.Â 03, 2023)."
  },
  {
    "objectID": "slides/building_stuff/index.html#on-to-the-first-steps-to-building-llm-based-applications",
    "href": "slides/building_stuff/index.html#on-to-the-first-steps-to-building-llm-based-applications",
    "title": "Building â€œStuffâ€?",
    "section": "On to the First Steps to Building LLM Based Applicationsâ€¦",
    "text": "On to the First Steps to Building LLM Based Applicationsâ€¦"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tatical-ammunition-management-micro-services-tamms",
    "href": "slides/agents_summer23/index.html#motivation-tatical-ammunition-management-micro-services-tamms",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: Tatical ammunition management Micro Services (TAMMS)",
    "text": "Motivation: Tatical ammunition management Micro Services (TAMMS)"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tamms-cognitive-agents",
    "href": "slides/agents_summer23/index.html#motivation-tamms-cognitive-agents",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: TAMMS cognitive Agents",
    "text": "Motivation: TAMMS cognitive Agents"
  },
  {
    "objectID": "slides/agents_summer23/index.html#motivation-tamms-kg",
    "href": "slides/agents_summer23/index.html#motivation-tamms-kg",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Motivation: TAMMS KG",
    "text": "Motivation: TAMMS KG"
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs",
    "text": "Cognitive Agents based on LLMs\n\n\nJoon Sung Park, Joseph C. Oâ€™Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. â€œGenerative Agents: Interactive Simulacra of Human Behavior.â€ arXiv, August 5, 2023. http://arxiv.org/abs/2304.03442."
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs Architecture",
    "text": "Cognitive Agents based on LLMs Architecture\n\n\nJoon Sung Park, Joseph C. Oâ€™Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. â€œGenerative Agents: Interactive Simulacra of Human Behavior.â€ arXiv, August 5, 2023. http://arxiv.org/abs/2304.03442."
  },
  {
    "objectID": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture-framework",
    "href": "slides/agents_summer23/index.html#cognitive-agents-based-on-llms-architecture-framework",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Cognitive Agents based on LLMs Architecture Framework",
    "text": "Cognitive Agents based on LLMs Architecture Framework\n\n\nPark, Joon Sung. â€œGenerative Agents: Interactive Simulacra of Human Behavior,â€ August 22, 2023. https://github.com/joonspk-research/generative_agents."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-web-agents",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-web-agents",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Web Agents",
    "text": "Activity Specific Agents: Web Agents\n\n\nDeng, Xiang, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. â€œMind2Web: Towards a Generalist Agent for the Web.â€ arXiv, June 14, 2023. http://arxiv.org/abs/2306.06070."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-web-agents-architecture",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-web-agents-architecture",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Web Agents Architecture",
    "text": "Activity Specific Agents: Web Agents Architecture\n\n\nDeng, Xiang, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. â€œMind2Web: Towards a Generalist Agent for the Web.â€ arXiv, June 14, 2023. http://arxiv.org/abs/2306.06070."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Visual Agents",
    "text": "Activity Specific Agents: Visual Agents\n\n\nâ€œAutonomous Visual Information Seeking with Large Language Models,â€ Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#visual-agents-architecture-different-llms-based-on-role",
    "href": "slides/agents_summer23/index.html#visual-agents-architecture-different-llms-based-on-role",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Visual Agents Architecture: Different LLMs based on Role",
    "text": "Visual Agents Architecture: Different LLMs based on Role\n\n\nâ€œAutonomous Visual Information Seeking with Large Language Models,â€ Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents-transition-graph",
    "href": "slides/agents_summer23/index.html#activity-specific-agents-visual-agents-transition-graph",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Activity Specific Agents: Visual Agents Transition Graph",
    "text": "Activity Specific Agents: Visual Agents Transition Graph\n\n\nâ€œAutonomous Visual Information Seeking with Large Language Models,â€ Google AI Blog,August 18, 2023. https://ai.googleblog.com/2023/08/autonomous-visual-information-seeking.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#aside-transformer-vision-and-segmentation-models",
    "href": "slides/agents_summer23/index.html#aside-transformer-vision-and-segmentation-models",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Aside: Transformer Vision and segmentation models",
    "text": "Aside: Transformer Vision and segmentation models\n\n\nâ€œAlaamaalouf/FollowAnything.â€ Accessed August 22, 2023. https://github.com/alaamaalouf/FollowAnything.\nMaalouf, Alaa, Ninad Jadhav, Krishna Murthy Jatavallabhula, Makram Chahine, Daniel M. Vogt, Robert J. Wood, Antonio Torralba, and Daniela Rus. â€œFollow Anything: Open-Set Detection, Tracking, and Following in Real-Time.â€ arXiv, August 10, 2023. https://doi.org/10.48550/arXiv.2308.05737."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al.Â â€œGraph of Thoughts: Solving Elaborate Problems with Large Language Models.â€ arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-1",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-1",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al.Â â€œGraph of Thoughts: Solving Elaborate Problems with Large Language Models.â€ arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-2",
    "href": "slides/agents_summer23/index.html#graphs-as-a-prompt-structure-2",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Graphs as a Prompt Structure",
    "text": "Graphs as a Prompt Structure\n\n\nBesta, Maciej, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, et al.Â â€œGraph of Thoughts: Solving Elaborate Problems with Large Language Models.â€ arXiv, August 21, 2023. http://arxiv.org/abs/2308.09687."
  },
  {
    "objectID": "slides/agents_summer23/index.html#aside-prompt-engineering-guide",
    "href": "slides/agents_summer23/index.html#aside-prompt-engineering-guide",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Aside: Prompt Engineering Guide",
    "text": "Aside: Prompt Engineering Guide\n\n\nâ€œPrompt Engineering Guide.â€ Accessed August 22, 2023. https://www.promptingguide.ai/."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools-gorilla",
    "href": "slides/agents_summer23/index.html#apis-as-tools-gorilla",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools: Gorilla",
    "text": "APIs as Tools: Gorilla\n\n\nPatil, Shishir G., Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. â€œGorilla: Large Language Model Connected with Massive APIs.â€ arXiv, May 24, 2023. http://arxiv.org/abs/2305.15334."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools-architecture",
    "href": "slides/agents_summer23/index.html#apis-as-tools-architecture",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools: Architecture",
    "text": "APIs as Tools: Architecture\n\n\nPatil, Shishir G., Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. â€œGorilla: Large Language Model Connected with Massive APIs.â€ arXiv, May 24, 2023. http://arxiv.org/abs/2305.15334."
  },
  {
    "objectID": "slides/agents_summer23/index.html#apis-as-tools",
    "href": "slides/agents_summer23/index.html#apis-as-tools",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "APIs as Tools",
    "text": "APIs as Tools\n\n\nPatil, Shishir. â€œGorilla: Large Language Model Connected with Massive APIs [Project Website].â€ Python, August 22, 2023. https://github.com/ShishirPatil/gorilla."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llm-personality-traits",
    "href": "slides/agents_summer23/index.html#llm-personality-traits",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "LLM Personality Traits",
    "text": "LLM Personality Traits\n\n\nSafdari, Mustafa, Greg Serapio-GarcÃ­a, ClÃ©ment Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja MatariÄ‡. â€œPersonality Traits in Large Language Models.â€ arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#using-personality-tests",
    "href": "slides/agents_summer23/index.html#using-personality-tests",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Using Personality Tests",
    "text": "Using Personality Tests\n\n\nSafdari, Mustafa, Greg Serapio-GarcÃ­a, ClÃ©ment Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja MatariÄ‡. â€œPersonality Traits in Large Language Models.â€ arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#behavior-persona-through-prompting",
    "href": "slides/agents_summer23/index.html#behavior-persona-through-prompting",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Behavior Persona Through Prompting",
    "text": "Behavior Persona Through Prompting\n\n\nSafdari, Mustafa, Greg Serapio-GarcÃ­a, ClÃ©ment Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja MatariÄ‡. â€œPersonality Traits in Large Language Models.â€ arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llm-personality-traits-malleability",
    "href": "slides/agents_summer23/index.html#llm-personality-traits-malleability",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "LLM Personality Traits Malleability",
    "text": "LLM Personality Traits Malleability\n\n\nSafdari, Mustafa, Greg Serapio-GarcÃ­a, ClÃ©ment Crepy, Stephen Fitz, Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja MatariÄ‡. â€œPersonality Traits in Large Language Models.â€ arXiv, June 30, 2023. http://arxiv.org/abs/2307.00184."
  },
  {
    "objectID": "slides/agents_summer23/index.html#grounding-through-hybrid-kgs",
    "href": "slides/agents_summer23/index.html#grounding-through-hybrid-kgs",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Grounding Through Hybrid KGs",
    "text": "Grounding Through Hybrid KGs\n\n\nShirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. â€œUnifying Large Language Models and Knowledge Graphs: A Roadmap.â€ arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs",
    "href": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\nLiu, Jerry. â€œLlamaIndex.â€ Python, November 2022. https://doi.org/10.5281/zenodo.1234."
  },
  {
    "objectID": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs-1",
    "href": "slides/agents_summer23/index.html#llamaindex-to-build-hybrid-kgs-1",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "LlamaIndex to Build Hybrid KGs",
    "text": "LlamaIndex to Build Hybrid KGs\n\n\nâ€œCustom Retriever Combining KG Index and VectorStore Index - LlamaIndex ğŸ¦™ 0.8.5.Post2.â€ Accessed August 22, 2023. https://gpt-index.readthedocs.io/en/stable/examples/index_structs/knowledge_graph/KnowledgeGraphIndex_vs_VectorStoreIndex_vs_CustomIndex_combined.html."
  },
  {
    "objectID": "slides/agents_summer23/index.html#data-agents-in-llamaindex",
    "href": "slides/agents_summer23/index.html#data-agents-in-llamaindex",
    "title": "What Dr.Â Vardeman is worried about: Trusted cognitive Agents",
    "section": "Data Agents in LlamaIndex",
    "text": "Data Agents in LlamaIndex\n\n\nFrom: Liu, Jerry. â€œData Agents.â€ LlamaIndex Blog (blog), July 13, 2023. https://medium.com/llamaindex-blog/data-agents-eed797d7972f."
  },
  {
    "objectID": "slideindex.html",
    "href": "slideindex.html",
    "title": "Weekly Nugget Presentations",
    "section": "",
    "text": "Tools for Trusted AI\n\n\n\n\n\n\n\nTools\n\n\nFrameworks\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nBuilding â€œStuffâ€?\n\n\n\n\n\n\n\nAgents\n\n\ntrustedAI\n\n\nDevelopment\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nA Summer of Nuggets\n\n\n\n\n\n\n\nnuggets\n\n\ntrustedAI\n\n\nLLMs\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nWhat Dr.Â Vardeman is worried about: Trusted cognitive Agents\n\n\n\n\n\n\n\nAgents\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nThings that concern Dr.Â Vardeman: Testing\n\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\nTesting\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nKG Construction\n\n\n\n\n\n\n\nKnowledge Engineering\n\n\nKG Construction\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nTrust and Causal Reasoning\n\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "At the University of Notre Dameâ€™s Center for Research Computing (CRC), the Laboratory for Assured AI Applications Development (LA3D) represents a critical step in the field of artificial intelligence (AI). As part of CRCâ€™s commitment to leveraging advanced computation for discovery and innovation, LA3D focuses on ensuring the responsible development and application of AI technologies. This initiative aligns with both the technological evolution of AI and the broader goals of CRC and Notre Dame.\nThe mission of LA3D is robust, layered, and rooted in a commitment to research, develop, and deploy AI models and systems that are not just innovative but trustworthy and ethically aligned. With a focus on AI Engineering, Trusted AI, Knowledge Engineering, FAIR (Findable, Accessible, Interoperable, and Reusable) data, and CyberInfrastructure, LA3D presents a multifaceted approach.\nAIâ€™s Transformative Potential: The transformative potential of AI is no longer a distant aspiration but a present-day reality. Whether in healthcare, finance, transportation, or education, AIâ€™s capacity to innovate is unparalleled. LA3D recognizes this potential and strives to harness it, directing AIâ€™s power towards constructive, ethical, and sustainable ends.\nConnection to the Center for Research Computing: LA3Dâ€™s home in the CRC is more than a mere geographical placement. It symbolizes a shared vision of advancing science through computational methods, high-performance computing, and now, AI-driven solutions. By integrating into the CRCâ€™s vibrant ecosystem, LA3D amplifies the pursuit of excellence, pushing the boundaries of whatâ€™s achievable with AI.\nMission Overview: LA3Dâ€™s mission transcends traditional boundaries, aiming to advance fields like AI Engineering, with its critical role in transitioning prototypes to production; Trusted AI, embodying ethical and reliable systems; Knowledge Engineering, embracing the new frontiers of Large Language Models; FAIR data principles; and the rapidly evolving CyberInfrastructure. Each of these elements comes together to create a synergy that fuels LA3Dâ€™s ambition to lead AI into an era marked by integrity, ingenuity, and human-centric focus.\nThe launch of LA3D marks a promising beginning in a journey filled with exploration, challenge, and opportunity. It sets the stage for an intellectual adventure that seeks to navigate the complex landscape of AI, unlocking its potentials while remaining anchored to values and ethical principles. Welcome to the Laboratory for Assured AI Applications Development â€“ a place where AIâ€™s promise transforms into tangible progress."
  },
  {
    "objectID": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "href": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "The Imperative of the Disciplines",
    "text": "The Imperative of the Disciplines\n\nAI Engineering: Bridging the Gap from Prototype to Production\nIn the complex, multifaceted realm of AI, the journey from concept to realization is fraught with challenges and intricacies. AI Engineering, a core discipline at the Laboratory for Assured AI Applications Development (LA3D), stands as a beacon guiding this intricate transition from prototypes to production-grade applications.\n\nTransitioning Prototypes to Production: At LA3D, we recognize that the gap between experimental AI prototypes and fully functional production systems is vast. AI Engineering provides the methodologies, tools, and practices needed to navigate this gap. Itâ€™s about ensuring that promising concepts donâ€™t just remain on paper but evolve into tangible applications. The recent Gartner research resonates with our approach, identifying that only 53% of AI projects transition from prototypes to production, underscoring the need for an engineering-driven approach.\nCore Pillars: DataOps, ModelOps, DevOps: DataOps focuses on data management and quality, ModelOps on model lifecycle management, and DevOps for seamless integration. These three core pillars together facilitate performance, scalability, interpretability, and reliability of AI models, maximizing the value of AI investments.\nAssurance in AI Models and Mechanistic Interpretability: Assurance in AI Models and Mechanistic Interpretability: Trust and reliability lie at the core of AI Engineering. At LA3D, the utilization of energy-based modeling, specifically Joint Energy-Based Models (JEMs), offers a transparent and statistically grounded approach to AI. By learning joint distributions over observed and latent variables, and associating lower energies with more likely configurations, JEMs help in aligning AI models with ethical guidelines and intended purposes. This mechanistic interpretability, coupled with the robust design inherent in JEMs, ensures predictability and engenders trust. Such alignment is vital for Assured AI, where understanding the underlying patterns and regularities in data becomes a cornerstone for creating reliable and responsible applications.\nScalability, Efficiency, Lifecycle Management, and Data-Centric AI: Ensuring consistent performance across different scales and complexities is crucial. LA3Dâ€™s AI Engineering practices enable models to be deployed in various environments without losing integrity or performance. Managing AI models throughout their lifecycle through continuous monitoring, validation, and maintenance ensures adaptability and alignment with evolving objectives. The emphasis on Data-Centric AI reflects LA3Dâ€™s commitment to focusing on the quality of data, recognizing that data is the lifeblood of AI systems.\nInterdisciplinary Collaboration and Alignment with Human Values: AI Engineering fosters collaboration among data scientists, engineers, domain experts, and ethical compliance teams. The result is cohesive AI development, where varying perspectives merge to create solutions resonating with diverse needs and values. At LA3D, AI serves human values and societal needs, ensuring that technology is not only technically sound but also socially responsible.\nEmbracing CyberSecurity: Coupled with a growing interest in CyberSecurity, LA3D extends the scope of AI Engineering to safeguard information and assure security in AI applications.\n\nAI Engineering is not merely a process at LA3D; itâ€™s a philosophy and an imperative discipline. Itâ€™s the bedrock that ensures AI models are not just innovative but also responsible, practical, and aligned with the human experience. Bridging the gap from prototype to production, AI Engineering paves the way for a future where AI is not just a tool but a reliable partner for progress. Join us on this journey as we delve deeper into AI Engineering, exploring its challenges, triumphs, and nuances.\n\n\nTrusted AI: A Cornerstone of Ethical and Reliable Systems\nTrusted AI is not just a concept; itâ€™s a commitment to integrity, ethics, and societal alignment that LA3D wholeheartedly embraces. Trust in AI is an essential component in our technological landscape, and it embodies various facets that work in synergy to create ethical and reliable systems.\n\nAssurance in AI Models: At LA3D, assurance goes beyond mere compliance; itâ€™s about creating AI models that can be understood, scrutinized, and validated. Building AI models that can explain their reasoning and provide clarity in their decisions is integral to creating trust.\nTransparency and Accountability: The quest for Trusted AI demands complete transparency in both process and outcomes. LA3D adheres to an open and comprehensible approach that allows all stakeholders to understand how decisions are made and who is accountable for them. Ensuring this level of transparency fosters an environment where AI models can be thoroughly evaluated and critiqued, reinforcing trust in their use.\nResponsible AI: While Trusted AI focuses on reliability and ethics, Responsible AI broadens the spectrum to include considerations such as fairness, inclusivity, privacy, and societal impact. At LA3D, we recognize that AI systems must not only operate within ethical guidelines but also actively contribute to the well-being of society. This commitment to social responsibility aligns with our holistic approach to developing technology that enriches lives.\nCyberSecurity in AI: As AI systems become more intertwined with our daily lives, the need to secure them becomes paramount. LA3D is committed to incorporating CyberSecurity measures within the AI development process, safeguarding data and protecting the integrity of AI systems. We understand that trust in AI also depends on the security of the systems, and we dedicate our resources to ensure that our AI applications are robust against threats.\n\nTrusted AI is a cornerstone at LA3D, reflecting our relentless pursuit of aligning technology with human values and ethical principles. Itâ€™s about creating AI that people can rely on, understand, and feel safe using. The interplay between transparency, accountability, Responsible AI, and CyberSecurity forms a unified approach to build AI systems that not only perform exceptionally but also resonate with the broader societal goals.\nJoin us as we explore further the nuances of Trusted AI, a field where technology and ethics merge to pave the way for a future where AI is a dependable ally. Our commitment to this discipline underscores the depth of our understanding of the complexities involved in crafting AI that is truly trusted.\nThis section outlines the key areas of Trusted AI that LA3D focuses on, emphasizing the importance of trust, transparency, responsibility, and security within the AI domain. It underscores the laboratoryâ€™s dedication to ethical and reliable AI systems, aligning with societal needs and values.\n\n\nKnowledge Engineering and Prompt Engineering: The New Frontiers\nIn the rapidly evolving landscape of artificial intelligence, Knowledge Engineering and Prompt Engineering emerge as exciting new frontiers that promise to reshape the way we conceptualize, create, and leverage AI systems. At the Laboratory for Assured AI Applications Development (LA3D), we recognize the vital role of these disciplines in shaping the next generation of AI applications.\n\nKnowledge Graphs: Knowledge graphs represent a transformative approach to organizing and connecting information. By modeling relationships between entities in a structured and semantically rich format, knowledge graphs enable more intelligent querying and reasoning. LA3D actively leverages knowledge graphs to power more insightful and context-aware AI solutions.\nOntology Design Patterns: A specialized aspect of Knowledge Engineering, ontology design patterns allow for the formal representation of concepts and their relationships within a specific domain. By utilizing these patterns, LA3D ensures that AI systems have a solid conceptual foundation, enabling more precise interpretation and decision-making.\nLLM Techniques: Large Language Models (LLMs) are revolutionizing natural language processing. By employing techniques like Prompt Engineering, LA3D refines the interaction with LLMs, enhancing their responsiveness and adaptability. This method allows for more effective communication with AI systems, aligning them closer to human-like understanding.\nAI Models as Surrogates: At LA3D, we explore the exciting potential of AI models as surrogates for complex mathematical or physical models. These AI surrogates can provide faster and more accessible simulations, accelerating research and opening new avenues for exploration in science and engineering.\nAI Co-Pilots for Various Tasks: Beyond acting as mere tools, AI models are now being developed as intelligent co-pilots, assisting human experts in a variety of tasks. Whether aiding in data analysis, guiding complex problem-solving, or enhancing creative processes, AI co-pilots represent a new paradigm of collaboration between human and machine intelligence.\n\nKnowledge Engineering and Prompt Engineering are not mere additions to the AI toolkit; they are pivotal advancements that herald a new era in AI application design and interaction. By embracing these new frontiers, LA3D reinforces its commitment to innovation, excellence, and the relentless pursuit of AI that is not just cutting-edge but profoundly attuned to human needs and aspirations. Join us as we explore these new horizons, uncovering the immense potential and profound implications they hold for the future of AI.\n\n\nThe Evolution of CyberInfrastructure and AI-Driven Science AI-Driven Science\nThe seamless integration of CyberInfrastructure with AI-driven science marks a transformative phase in research and innovation. As part of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dameâ€™s Center for Research Computing (CRC), we are at the forefront of this exciting convergence, pioneering approaches that harness the power of advanced computing technologies to accelerate scientific discovery.\n\nAI-Driven Science: The infusion of AI into scientific research has ushered in a new era of data-driven exploration and insight. At LA3D, we employ AI models to analyze complex data sets, predict outcomes, and even guide experimental design. From enhancing medical diagnostics to predicting climate patterns, AI-driven science is unlocking unprecedented opportunities for understanding and innovation.\nRelevance to CRC: The Center for Research Computing at Notre Dame is committed to providing cutting-edge computational resources and expertise. The collaboration with LA3D amplifies this commitment by aligning AI research with state-of-the-art CyberInfrastructure. Together, weâ€™re pushing the boundaries of whatâ€™s possible in computational science.\nAI Surrogates for Mathematical Models: Building on the AI surrogates concept, we utilize AI models to replicate complex mathematical or physical systems within CRC. These surrogates enable faster simulations and insights, thus accelerating research and expanding our ability to tackle previously intractable problems.\nAI Co-Pilots for Scientific Exploration: The development of AI co-pilots has extended into the realm of scientific exploration at CRC. These intelligent systems act as collaborators, assisting researchers in hypothesis formulation, data analysis, and problem-solving. Itâ€™s a revolutionary approach that augments human intelligence with AI, fostering a new level of creativity and rigor in scientific inquiry.\nIntegration of CyberInfrastructure: A robust CyberInfrastructure is foundational to AI-driven science at CRC. By weaving together high-performance computing, cloud technologies, and specialized software, weâ€™re creating a dynamic environment where AI and computational science flourish. Itâ€™s a synergy that optimizes research processes, enhances collaboration, and catalyzes breakthroughs.\n\nThe evolution of CyberInfrastructure and AI-driven science at CRC represents more than technological advancement; itâ€™s a paradigm shift in how we approach research and discovery. Through strategic collaboration and relentless innovation, weâ€™re crafting a future where technology and human intellect unite to illuminate the unknown. Join us on this path, as we explore the incredible potential and promise of this convergence, continually striving to redefine the boundaries of what is possible in science and beyond."
  },
  {
    "objectID": "posts/welcome/index.html#blogs-objective-and-overview",
    "href": "posts/welcome/index.html#blogs-objective-and-overview",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "Blogâ€™s Objective and Overview",
    "text": "Blogâ€™s Objective and Overview\nIn alignment with the University of Notre Dameâ€™s mission to seek knowledge that addresses humanityâ€™s pressing challenges, and the Center for Research Computingâ€™s (CRC) commitment to driving innovation, the Laboratory for Assured AI Applications Development (LA3D) is pleased to unveil this blog as an essential platform.\n\nWeekly Updates: Engage with regular insights into the ongoing research, technological advancements, and creative pursuits within LA3D. From AI Engineering to Trusted AI, weâ€™ll keep our community abreast of the exciting developments shaping our field.\nInsights into Trusted AI, CI-Compass, and More: Delve into the core projects and collaborations within LA3D, including specialized explorations into the worlds of Trusted AI, CI-Compass, CyberSecurity in AI, and the nuances of Responsible AI.\nAI Workforce Development: Recognizing the need for a skilled and knowledgeable AI workforce, this blog will feature initiatives, programs, and strategies dedicated to cultivating the next generation of AI professionals. Together with CRC, we strive to foster education, mentorship, and career development in AI.\nResearch Publications and Highlights: Discover the rich tapestry of research being woven at LA3D. Weâ€™ll highlight key publications, conference achievements, and innovative studies that reflect our commitment to excellence and alignment with Notre Dameâ€™s values.\nCommunity Engagement and Collaboration: Building on Notre Dameâ€™s emphasis on community and service, this blog invites you to participate, share, and learn. Join a lively dialogue that celebrates diversity of thought and collaboration in pursuit of a greater understanding of Assured AI.\nSpotlight on CyberSecurity in AI and Emerging Topics: As part of our comprehensive view of modern AI, we will dedicate specific sections to explore critical areas like CyberSecurity and the delicate balance between Responsible and Trusted AI.\nConnection to Notre Dameâ€™s and CRCâ€™s Mission: This blog embodies the spirit of Notre Dame and CRCâ€™s shared mission to advance knowledge, foster innovation, and contribute to society. We strive to make the pursuit of AI not only a scientific endeavor but also a means to enrich lives and address societal needs.\n\nIn the introduction, weâ€™ve outlined the essential areas of focus at the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dameâ€™s Center for Research Computing. From AI Engineeringâ€™s crucial role in transitioning prototypes to production, to the ethical imperatives in Trusted AI, Knowledge Engineering, CyberSecurity in AI, and the blogâ€™s alignment with the missions of CRC and Notre Dame, weâ€™ve set the stage for a comprehensive exploration.\nOur blog serves as a platform to dive into these topics, including AI workforce development and the ways in which AI intersects with societal needs and technological advancements. As we move forward, weâ€™ll examine these subjects in detail, shedding light on the challenges, successes, and ongoing efforts in these fields.\nStay tuned as we delve into the complexities of AI, with insights and updates that reflect LA3Dâ€™s commitment to innovation, responsibility, and real-world applicability. Join us in this exploration, as we strive to make AI not just a tool, but a reliable partner for progress."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "Welcome To AI Success Factors: Engineering Trust in Deployments\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/tai-tools/index.html#trusted-ai-frameworks-for-knowledge-engineering",
    "href": "slides/tai-tools/index.html#trusted-ai-frameworks-for-knowledge-engineering",
    "title": "Tools for Trusted AI",
    "section": "Trusted AI Frameworks for Knowledge Engineering",
    "text": "Trusted AI Frameworks for Knowledge Engineering"
  },
  {
    "objectID": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-chatgpt",
    "href": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-chatgpt",
    "title": "Tools for Trusted AI",
    "section": "What is Trusted AI â€“ Letâ€™s ask ChatGPT!",
    "text": "What is Trusted AI â€“ Letâ€™s ask ChatGPT!\nTrusted AI encompasses systems that are not only ethically aligned but also reliable, robust, secure, transparent, and accountable. While ethical considerations form a crucial aspect, Trusted AI extends to include the technical quality and performance of the system. The goal is to create AI technologies that various stakeholdersâ€”including users, developers, businesses, and regulatorsâ€”can trust to behave as intended and to meet specific performance, security, and governance standards.\nThe concept integrates aspects from multiple domains, such as:\n\nEthics: Fairness, transparency, and accountability.\nReliability: Consistent and dependable system performance.\nRobustness: Ability to handle unexpected inputs or conditions without failing.\nSecurity: Measures to protect data and models from unauthorized access and tampering.\nTransparency: Understandability of system decisions and actions.\nAccountability: Mechanisms to trace actions back to the responsible entities for evaluation and auditing.\n\nIn this broader context, â€œtrustâ€ is a multidimensional construct. Itâ€™s not just about being ethical but about fulfilling a wide range of expectations and standards that make a system worthy of trust."
  },
  {
    "objectID": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-claude-2",
    "href": "slides/tai-tools/index.html#what-is-trusted-ai-lets-ask-claude-2",
    "title": "Tools for Trusted AI",
    "section": "What is Trusted AI â€“ Letâ€™s ask Claude 2!",
    "text": "What is Trusted AI â€“ Letâ€™s ask Claude 2!\nTrusted AI refers to artificial intelligence systems that are designed and validated to be reliable, safe and technically robust. Key principles of trusted AI include:\n\nReliability - AI systems consistently produce accurate, reproducible results that can be externally validated. Models are unbiased and decisions explainable.\nSafety and security - AI systems are developed using secure software practices and are resilient against attacks, hacking or misuse. They protect privacy and confidentiality.\nExternal oversight - There are independent audits and ongoing monitoring of AI systems to ensure transparency and identify issues. Public disclosure builds trust.\nHuman control - Humans remain fully in control of AI systems, which augment human intelligence rather than replace it. Autonomous systems have human supervision.\nProportionality - AI capabilities do not exceed what is appropriate for the task. AI is not used when less advanced technology suffices.\nTechnical robustness - AI systems are thoroughly tested for stability, scalability and corner cases. Failsafes prevent glitches or unintended harm.\n\nIn contrast to responsible AI, trusted AI emphasizes technical system properties over organizational processes. It focuses on engineering reliable, safe and externally validated AI, rather than holistic internal governance."
  },
  {
    "objectID": "slides/tai-tools/index.html#our-evolving-vision-of-trusted-ai",
    "href": "slides/tai-tools/index.html#our-evolving-vision-of-trusted-ai",
    "title": "Tools for Trusted AI",
    "section": "Our, evolving vision of Trusted AI",
    "text": "Our, evolving vision of Trusted AI"
  },
  {
    "objectID": "slides/tai-tools/index.html#responsible-ai",
    "href": "slides/tai-tools/index.html#responsible-ai",
    "title": "Tools for Trusted AI",
    "section": "Responsible AI",
    "text": "Responsible AI\n\nResponsible AI: This term is broader and refers to the ethical design, development, and deployment of AI. This includes considerations not just of the AIâ€™s technical behavior (e.g., is it transparent and accountable?), but also of the socio-economic implications, like job displacement, and broader ethical considerations like data privacy and environmental impact."
  },
  {
    "objectID": "slides/tai-tools/index.html#foundational-components-for-trusted-ai",
    "href": "slides/tai-tools/index.html#foundational-components-for-trusted-ai",
    "title": "Tools for Trusted AI",
    "section": "Foundational Components for Trusted AI",
    "text": "Foundational Components for Trusted AI\n\nAutomate the integration and deployment of code, ensuring quality and operational efficiency.\nStandardized Development Environments: Establish consistent, easily replicable environments to accelerate development and experimentation.\nData & Experiment Versioning: Implement robust systems to track changes in data and experiments, allowing for traceability and repeatability.\nModel Lifecycle Management: Streamline the training, deployment, monitoring, and updating of machine learning models.\nFlexibility Across Layers: Design the architecture to allow for different levels of customization, from high-level APIs to low-level controls, facilitating adaptability."
  },
  {
    "objectID": "slides/tai-tools/index.html#why-a-framework",
    "href": "slides/tai-tools/index.html#why-a-framework",
    "title": "Tools for Trusted AI",
    "section": "Why a Framework?",
    "text": "Why a Framework?\n\n\n\n\nâ€œCourse22/06-Why-You-Should-Use-a-Framework.Ipynb at Master Â· Fastai/Course22.â€\nAccessed August 29, 2023. https://github.com/fastai/course22/blob/master/06-why-you-should-use-a-framework.ipynb."
  },
  {
    "objectID": "slides/tai-tools/index.html#this-is-a-living-set-of-slides",
    "href": "slides/tai-tools/index.html#this-is-a-living-set-of-slides",
    "title": "Tools for Trusted AI",
    "section": "This is a â€œlivingâ€ set of slides!",
    "text": "This is a â€œlivingâ€ set of slides!"
  },
  {
    "objectID": "slides/tai-tools/index.html#purpose-to-quickly-bootstrap-you-into-a-research-environment",
    "href": "slides/tai-tools/index.html#purpose-to-quickly-bootstrap-you-into-a-research-environment",
    "title": "Tools for Trusted AI",
    "section": "Purpose: To quickly â€œBootstrapâ€ you into a research environment",
    "text": "Purpose: To quickly â€œBootstrapâ€ you into a research environment"
  },
  {
    "objectID": "slides/tai-tools/index.html#our-framework-starts-with-github",
    "href": "slides/tai-tools/index.html#our-framework-starts-with-github",
    "title": "Tools for Trusted AI",
    "section": "Our Framework Starts with GitHub",
    "text": "Our Framework Starts with GitHub\n\n\n\n\nGitHub ND-Crane Organization"
  },
  {
    "objectID": "slides/tai-tools/index.html#step-1-create-a-github-account",
    "href": "slides/tai-tools/index.html#step-1-create-a-github-account",
    "title": "Tools for Trusted AI",
    "section": "(Step 1) Create a GitHub Account",
    "text": "(Step 1) Create a GitHub Account\n\n\n\n\nGitHub"
  },
  {
    "objectID": "slides/tai-tools/index.html#step-2-email-github-account-id",
    "href": "slides/tai-tools/index.html#step-2-email-github-account-id",
    "title": "Tools for Trusted AI",
    "section": "(Step 2) Email GitHub Account ID",
    "text": "(Step 2) Email GitHub Account ID\n\nIf you are not part of the nd-crane organization. Email pmoreira@nd.edu your GitHub ID so we can add it to the nd-crane organization"
  },
  {
    "objectID": "slides/tai-tools/index.html#step-3-go-through-github-skills-introduction-to-github",
    "href": "slides/tai-tools/index.html#step-3-go-through-github-skills-introduction-to-github",
    "title": "Tools for Trusted AI",
    "section": "(Step 3) Go through GitHub Skills Introduction to GitHub",
    "text": "(Step 3) Go through GitHub Skills Introduction to GitHub\n\n\n\nGo Through â€œFirst Day on GitHubâ€\n\nIntroduction to GitHub\nCommunicate using Markdown\nGitHub Pages (We will use this with Quarto)\n\nFirst week on GitHub\n\nReview pull requests\nResolve merge conflicts\nRelease-based workflow\nConnect the dots\nCode with Codespaces\n\n\n\n\n\n\n\nGitHub Skills: https://skills.github.com/"
  },
  {
    "objectID": "slides/tai-tools/index.html#ai-and-machine-learning",
    "href": "slides/tai-tools/index.html#ai-and-machine-learning",
    "title": "Tools for Trusted AI",
    "section": "AI and Machine Learning",
    "text": "AI and Machine Learning\n\n\nPractical Deep Learning: https://course.fast.ai/\nFastAI Book\nFastAI GitHub: https://github.com/fastai"
  },
  {
    "objectID": "slides/tai-tools/index.html#fastai-fastbook-a-production-mindset",
    "href": "slides/tai-tools/index.html#fastai-fastbook-a-production-mindset",
    "title": "Tools for Trusted AI",
    "section": "FastAI FastBook â€“ â€œA Production Mindsetâ€",
    "text": "FastAI FastBook â€“ â€œA Production Mindsetâ€\n\n\n\nIntroduction to Jupyter\n02_production.ipynb\nNatural Language (NLP)\n\nGetting started with NLP for absolute beginners"
  },
  {
    "objectID": "slides/tai-tools/index.html#a-preview",
    "href": "slides/tai-tools/index.html#a-preview",
    "title": "Tools for Trusted AI",
    "section": "A Previewâ€¦",
    "text": "A Previewâ€¦"
  },
  {
    "objectID": "slides/tai-tools/index.html#visual-studio-code",
    "href": "slides/tai-tools/index.html#visual-studio-code",
    "title": "Tools for Trusted AI",
    "section": "Visual Studio Code",
    "text": "Visual Studio Code\n\n\nVisual Studio Code - Code Editing. Redefined: https://code.visualstudio.com/"
  },
  {
    "objectID": "slides/tai-tools/index.html#peter-only-dev-containers-and-fastai",
    "href": "slides/tai-tools/index.html#peter-only-dev-containers-and-fastai",
    "title": "Tools for Trusted AI",
    "section": "(Peter Only!) â€œDev Containersâ€ and FastAI",
    "text": "(Peter Only!) â€œDev Containersâ€ and FastAI\nUsing Codespaces to work with the â€œPractical Deep Learning for Codersâ€ course"
  },
  {
    "objectID": "slides/tai-tools/index.html#but-dr.-vardeman-i-know-all-of-this",
    "href": "slides/tai-tools/index.html#but-dr.-vardeman-i-know-all-of-this",
    "title": "Tools for Trusted AI",
    "section": "But Dr.Â Vardeman, I know all of this!",
    "text": "But Dr.Â Vardeman, I know all of this!\nGetting Started With LLMs"
  },
  {
    "objectID": "slides/tai-tools/index.html#python",
    "href": "slides/tai-tools/index.html#python",
    "title": "Tools for Trusted AI",
    "section": "Python",
    "text": "Python\n\n\nLearn More: Think Python 2e: https://greenteapress.com/wp/think-python-2e/"
  },
  {
    "objectID": "slides/tai-tools/index.html#python-for-data-analysis",
    "href": "slides/tai-tools/index.html#python-for-data-analysis",
    "title": "Tools for Trusted AI",
    "section": "Python for Data Analysis",
    "text": "Python for Data Analysis\n\n\n\n\n\n\nPractical Deep Learning: https://wesmckinney.com/book/"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "href": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "title": "KG Construction",
    "section": "KG Construction Pipeline",
    "text": "KG Construction Pipeline"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "href": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "title": "KG Construction",
    "section": "LLM KG Construction Frameworks Llamaindex",
    "text": "LLM KG Construction Frameworks Llamaindex\n\nLearn more: Llamaindex"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#rebel-large-model",
    "href": "slides/kg-llamaindex/index.html#rebel-large-model",
    "title": "KG Construction",
    "section": "Rebel Large Model",
    "text": "Rebel Large Model\n#| echo: true\nfrom transformers import pipeline\n\ntriplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets(text):\n    triplets = []\n    relation, subject, relation, object_ = '', '', '', ''\n    text = text.strip()\n    current = 'x'\n    for token in text.replace(\"&lt;s&gt;\", \"\").replace(\"&lt;pad&gt;\", \"\").replace(\"&lt;/s&gt;\", \"\").split():\n        if token == \"&lt;triplet&gt;\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n                relation = ''\n            subject = ''\n        elif token == \"&lt;subj&gt;\":\n            current = 's'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n            object_ = ''\n        elif token == \"&lt;obj&gt;\":\n            current = 'o'\n            relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '':\n        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n    return triplets\nextracted_triplets = extract_triplets(extracted_text[0])\nprint(extracted_triplets)\n\nLearn more: Rebel Large"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel",
    "text": "LlamaIndex with Rebel\n\n\nLearn more: Llamaindex with Rebel Colab Notebook"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel and Neo4j",
    "text": "LlamaIndex with Rebel and Neo4j\n\n\nLearn more: Neo4j Graph Store\nGitHub: Tomaz Bratanic"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "href": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "title": "KG Construction",
    "section": "Weaviate With Llama 2 and Llamaindex",
    "text": "Weaviate With Llama 2 and Llamaindex\n\n\nLearn more: Welcome to the quick notebook on using Llama 2"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "title": "KG Construction",
    "section": "Weaviate â€œKnowledge Graphsâ€",
    "text": "Weaviate â€œKnowledge Graphsâ€\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "title": "KG Construction",
    "section": "Weaviate â€œKnowledge Graphsâ€",
    "text": "Weaviate â€œKnowledge Graphsâ€\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#aws-neptune",
    "href": "slides/kg-llamaindex/index.html#aws-neptune",
    "title": "KG Construction",
    "section": "AWS Neptune",
    "text": "AWS Neptune\n\n\nLearn More: Amazon Neptune"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "href": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "title": "KG Construction",
    "section": "Amazon Science ReFinED",
    "text": "Amazon Science ReFinED\n\n\nPaper: ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking\nPaper: Improving Entity Disambiguation by Reasoning over a Knowledge Base\nGitHub: ReFinED is an efficient and accurate entity linking (EL) system."
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "href": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "title": "KG Construction",
    "section": "Amazon Science KGQA",
    "text": "Amazon Science KGQA\n\n\nWebsite: Language models as controlled natural language semantic parsers for knowledge graph question answering GitHub: Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned ML Website",
    "text": "Towards Trustworthy and Aligned ML Website\n\n\nTowards Trustworthy and Aligned ML"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#causal-reasoning",
    "href": "slides/trust-causal/index.html#causal-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Causal Reasoning",
    "text": "Causal Reasoning\n\n\nLearn more: Amazon Book of Why"
  },
  {
    "objectID": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "href": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "title": "Trust and Causal Reasoning",
    "section": "Trustworthy ML Initiative (TrustML)",
    "text": "Trustworthy ML Initiative (TrustML)\n\n\nLearn more: Trustworthy ML Org"
  },
  {
    "objectID": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "href": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "title": "Trust and Causal Reasoning",
    "section": "Gorilla API to Ground â€œTool Useâ€",
    "text": "Gorilla API to Ground â€œTool Useâ€\n\n\nLearn more: Gorilla: Large Language Model Connected with Massive APIs"
  },
  {
    "objectID": "slides/trust-causal/index.html#llama2-accessory",
    "href": "slides/trust-causal/index.html#llama2-accessory",
    "title": "Trust and Causal Reasoning",
    "section": "LLaMA2-Accessory",
    "text": "LLaMA2-Accessory\n\n\nLearn more: LLaMA2-Accessory"
  },
  {
    "objectID": "slides/trust-causal/index.html#multilingual-token-analysis",
    "href": "slides/trust-causal/index.html#multilingual-token-analysis",
    "title": "Trust and Causal Reasoning",
    "section": "MultiLingual Token Analysis",
    "text": "MultiLingual Token Analysis\n\n\nLearn more: Video: LLaMA2 Multilingual Models and Fine Tuning\nGoogle Collab Notebook:"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2",
    "href": "slides/trust-causal/index.html#metaai-dinov2",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2",
    "text": "MetaAI DINOv2\n\n\nLearn more: DINOv2 by Meta AI"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "href": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2 Huggingface Release",
    "text": "MetaAI DINOv2 Huggingface Release\n\n\nLearn more: DINOv2 by Meta AI Huggingface"
  },
  {
    "objectID": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "href": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "title": "Trust and Causal Reasoning",
    "section": "Example notebook for DINOv2 Semantic Segmentation",
    "text": "Example notebook for DINOv2 Semantic Segmentation\n\n\nLearn more: Linear probing of DINOv2 for semantic segmentation"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/nuggets_review/index.html#where-we-started",
    "href": "slides/nuggets_review/index.html#where-we-started",
    "title": "A Summer of Nuggets",
    "section": "Where we startedâ€¦",
    "text": "Where we startedâ€¦"
  },
  {
    "objectID": "slides/nuggets_review/index.html#where-were-going",
    "href": "slides/nuggets_review/index.html#where-were-going",
    "title": "A Summer of Nuggets",
    "section": "Where weâ€™re goingâ€¦",
    "text": "Where weâ€™re goingâ€¦\n\n\n\n\nAI Success Factors: Engineering Trust in Deployments"
  },
  {
    "objectID": "slides/nuggets_review/index.html#this-is-meant-to-provide-something-of-a-roadmap",
    "href": "slides/nuggets_review/index.html#this-is-meant-to-provide-something-of-a-roadmap",
    "title": "A Summer of Nuggets",
    "section": "This is meant to provide something of a â€œRoadmapâ€!",
    "text": "This is meant to provide something of a â€œRoadmapâ€!"
  },
  {
    "objectID": "slides/nuggets_review/index.html#video-link",
    "href": "slides/nuggets_review/index.html#video-link",
    "title": "A Summer of Nuggets",
    "section": "Video Link",
    "text": "Video Link"
  },
  {
    "objectID": "slides/nuggets_review/index.html#old-school-ai-and-the-web",
    "href": "slides/nuggets_review/index.html#old-school-ai-and-the-web",
    "title": "A Summer of Nuggets",
    "section": "â€œOld School AIâ€ and the Webâ€¦",
    "text": "â€œOld School AIâ€ and the Webâ€¦\n\n\nA vision of â€œOntologiesâ€, â€œLinked Dataâ€, and â€œSoftware Agentsâ€â€¦\n\n\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. â€œThe Semantic Web.â€ Scientific American 284, no. 5 (2001): 34â€“43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/nuggets_review/index.html#old-school-cool-ai-and-the-web-2001",
    "href": "slides/nuggets_review/index.html#old-school-cool-ai-and-the-web-2001",
    "title": "A Summer of Nuggets",
    "section": "Old School â€œCoolâ€ AI and the Web (2001)â€¦",
    "text": "Old School â€œCoolâ€ AI and the Web (2001)â€¦\n\n\nThe semantic web had a vision of Agents with Shared Understanding through Ontologies, the ability to Use Tools Like the Web and Consume a Web of Linked Data as Distibuted Knowledge Graphs.\n\n\n\n\n\nTim Berners-Lee, James Hendler, and Ora Lassila. â€œThe Semantic Web.â€ Scientific American 284, no. 5 (2001): 34â€“43. https://lassila.org/publications/2001/SciAm.html"
  },
  {
    "objectID": "slides/nuggets_review/index.html#whats-an-ontology",
    "href": "slides/nuggets_review/index.html#whats-an-ontology",
    "title": "A Summer of Nuggets",
    "section": "Whatâ€™s an Ontology?",
    "text": "Whatâ€™s an Ontology?\n\n\nTom Gruber. â€œOntology.â€ In Encyclopedia of Database Systems, edited by Ling Liu and M. Tamer Ã–zsu, 1â€“3. New York, NY: Springer, 2016. https://doi.org/10.1007/978-1-4899-7993-3_1318-2."
  },
  {
    "objectID": "slides/nuggets_review/index.html#ontology-design-patterns",
    "href": "slides/nuggets_review/index.html#ontology-design-patterns",
    "title": "A Summer of Nuggets",
    "section": "Ontology Design Patterns",
    "text": "Ontology Design Patterns\n\n\n\n\n\n\n\n\nEva Blomqvist, Pascal Hitzler, Krzysztof Janowicz, Adila Krisnadhi, Tom Narock, and Monika Solanki. â€œConsiderations Regarding Ontology Design Patterns.â€ Semantic Web 7, no. 1 (November 10, 2015): 1â€“7. https://doi.org/10.3233/SW-150202."
  },
  {
    "objectID": "slides/nuggets_review/index.html#google-search-and-the-semantic-web",
    "href": "slides/nuggets_review/index.html#google-search-and-the-semantic-web",
    "title": "A Summer of Nuggets",
    "section": "Google Search and the â€œSemantic Webâ€",
    "text": "Google Search and the â€œSemantic Webâ€\n\n\n\n\n\n\n\n\nGoogle. â€œIntroducing the Knowledge Graph: Things, Not Strings,â€ May 16, 2012. https://blog.google/products/search/introducing-knowledge-graph-things-not/.\nGoogle. â€œA Reintroduction to Our Knowledge Graph and Knowledge Panels,â€ May 20, 2020. https://blog.google/products/search/about-knowledge-graph-and-knowledge-panels/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs",
    "href": "slides/nuggets_review/index.html#knowledge-graphs",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs\n\n\n\n\n\n\n\n\nHogan, Aidan, Eva Blomqvist, Michael Cochez, Claudia dâ€™Amato, Gerard de Melo, Claudio GutiÃ©rrez, Sabrina Kirrane, et al.Â Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge 22. Springer, 2021. https://doi.org/10.2200/S01125ED1V01Y202109DSK022."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-1",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-1",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs",
    "text": "Knowledge Graphs\n\n\nWhatâ€™s a Knowledge Graph?\n\n\n\n\n\nHogan, Aidan, Eva Blomqvist, Michael Cochez, Claudia dâ€™Amato, Gerard de Melo, Claudio GutiÃ©rrez, Sabrina Kirrane, et al.Â Knowledge Graphs. Synthesis Lectures on Data, Semantics, and Knowledge 22. Springer, 2021. https://doi.org/10.2200/S01125ED1V01Y202109DSK022."
  },
  {
    "objectID": "slides/nuggets_review/index.html#ai-in-2023..",
    "href": "slides/nuggets_review/index.html#ai-in-2023..",
    "title": "A Summer of Nuggets",
    "section": "AI in 2023..",
    "text": "AI in 2023.."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-ai-social-disruption",
    "href": "slides/nuggets_review/index.html#the-ai-social-disruption",
    "title": "A Summer of Nuggets",
    "section": "The â€œAI Social Disruptionâ€",
    "text": "The â€œAI Social Disruptionâ€\n\n\n\n\nJames Gary, â€œAI â€“ The Social Disruptionâ€, AI Magazine 42, no. 1 (April 12, 2021), Cover."
  },
  {
    "objectID": "slides/nuggets_review/index.html#pretrained-foundation-models",
    "href": "slides/nuggets_review/index.html#pretrained-foundation-models",
    "title": "A Summer of Nuggets",
    "section": "Pretrained Foundation Modelsâ€¦",
    "text": "Pretrained Foundation Modelsâ€¦\n\n\n\n\nZhou, Ce, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, et al.Â â€œA Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.â€ arXiv, May 1, 2023. https://doi.org/10.48550/arXiv.2302.09419."
  },
  {
    "objectID": "slides/nuggets_review/index.html#evolution-of-large-language-models",
    "href": "slides/nuggets_review/index.html#evolution-of-large-language-models",
    "title": "A Summer of Nuggets",
    "section": "Evolution of Large Language Models",
    "text": "Evolution of Large Language Models\n\n\n\n\nYang, Jingfeng, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. â€œHarnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond.â€ arXiv, April 27, 2023. https://doi.org/10.48550/arXiv.2304.13712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformerattention-is-all-you-need",
    "href": "slides/nuggets_review/index.html#transformerattention-is-all-you-need",
    "title": "A Summer of Nuggets",
    "section": "Transformer:â€œAttention is all you needâ€",
    "text": "Transformer:â€œAttention is all you needâ€\n\n\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. â€œAttention Is All You Need.â€ arXiv, August 1, 2023. https://doi.org/10.48550/arXiv.1706.03762."
  },
  {
    "objectID": "slides/nuggets_review/index.html#explain-the-transformer-neural-network-architecture-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "href": "slides/nuggets_review/index.html#explain-the-transformer-neural-network-architecture-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "title": "A Summer of Nuggets",
    "section": "â€œExplain the transformer neural network architecture to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.â€",
    "text": "â€œExplain the transformer neural network architecture to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.â€"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nAlright, letâ€™s get into it! Imagine youâ€™re at a party and youâ€™re trying to catch snippets of multiple conversations. Youâ€™re not just listening to the words, but also noticing whoâ€™s talking to whom, the tone, the context, and youâ€™re making judgments about whatâ€™s important or not. Thatâ€™s kinda what the Transformer architecture does, but for sequences of data like sentences or time-series data.\nAt the core, a Transformer has two main parts: the Encoder and the Decoder. Each has multiple identical layers stacked on top of each other.\n\nEncoder: Takes in the sequence (like a sentence â€œHello, how are you?â€) and processes it as a whole. It outputs a sort of â€œsummaryâ€ or â€œcontextâ€ for each word in the sequence.\n\nSelf-Attention: Each word checks out all the other words and figures out which ones are important to it. The magic formula called attention scores helps in this.\nFeed-forward neural networks: After attention, each word passes through a mini neural network thatâ€™s the same for all words, transforming it yet again."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-1",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-1",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\n\nDecoder: Takes these encodings and starts generating the output sequence (say, a translation of the original sentence into another language).\n\nMasked Self-Attention: Similar to the encoder, but in a way that it canâ€™t cheat and look at future words in the output sequence.\nEncoder-Decoder Attention: The decoder takes a peek at the encoderâ€™s output to better understand the context and produce the correct next word.\nFeed-forward neural networks: Same drill as the encoder, another mini network for transforming words."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-2",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-2",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nSo the magic here is mainly in how words interact with each other through the attention mechanism. Each word looks at all the other words to decide how much focus it should get, like how you tune in to different voices at a party. It does this not once, but multiple times, diving deeper and deeper into the context each time.\nItâ€™s like a super-efficient assembly line for sequences, enabling models like me to generate text or translate languages at scale. And this architecture has been the basis for a lot of breakthroughs in natural language processing. Itâ€™s versatile, parallelizable, and mighty powerful!"
  },
  {
    "objectID": "slides/nuggets_review/index.html#some-llm-neural-networks-use-encoder-decoder-networks.-some-llm-neural-networks-are-encoder-only-and-some-are-decoder-only-like-gpt.-explain-that-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "href": "slides/nuggets_review/index.html#some-llm-neural-networks-use-encoder-decoder-networks.-some-llm-neural-networks-are-encoder-only-and-some-are-decoder-only-like-gpt.-explain-that-to-a-college-junior-computer-science-student.-use-the-style-of-a-good-science-communicator-like-richard-feynman.",
    "title": "A Summer of Nuggets",
    "section": "â€œSome LLM Neural Networks use encoder-decoder networks. Some LLM neural networks are encoder only and some are decoder only like GPT. Explain that to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.â€",
    "text": "â€œSome LLM Neural Networks use encoder-decoder networks. Some LLM neural networks are encoder only and some are decoder only like GPT. Explain that to a College Junior Computer Science student. Use the style of a good science communicator like Richard Feynman.â€"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-3",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-3",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nAh, good question! Think of it like this: youâ€™ve got three types of orchestras. One plays both classical and jazz seamlessly (encoder-decoder), another specializes only in classical (encoder), and the last one is all about that jazz (decoder).\n\nEncoder-Decoder Networks: These are like your all-rounder orchestras. In the machine learning world, these models are often used for tasks like machine translation. The encoder part processes the input language, letâ€™s say, English, and the decoder part spits out the output in another language, maybe Spanish. They work together like a well-conducted orchestra, each contributing to the final masterpiece.\nEncoder-Only Networks: Imagine an orchestra thatâ€™s focused entirely on classical music, where each musician feeds into the other to create a beautiful symphony. In tech, these models are good for tasks like text classification or sentiment analysis. The encoder processes the text and summarizes it in a way that lets you say, â€œAh, this review is positive!â€"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-4",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-4",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\n\nDecoder-Only Networks: Now, these are your jazz specialists, all about improvisation and solos. GPT models, like the one youâ€™re talking to, belong to this category. The decoder starts with a seed (your prompt) and keeps generating one word at a time, predicting the next best word until it forms a coherent reply. It doesnâ€™t need to look back at an original input sentence like in translation; it just jams out text based on what it has learned during its training.\n\nSo, youâ€™ve got different setups for different gigs. If you need a two-way conversation between languages, you go for the encoder-decoder. If you want to understand the essence of a piece of text, youâ€™d lean on the encoder. And if you want to generate text, like writing or even code, the decoder is your go-to musician. Each has its own style, its own instruments, and its own unique approach to making beautiful â€œmusicâ€â€”or in our case, useful computations."
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-do-these-relate-to-the-transformer-architecture",
    "href": "slides/nuggets_review/index.html#how-do-these-relate-to-the-transformer-architecture",
    "title": "A Summer of Nuggets",
    "section": "â€œHow do these relate to the Transformer architectureâ€",
    "text": "â€œHow do these relate to the Transformer architectureâ€"
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-5",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-5",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nGreat follow-up! Alright, think of the Transformer architecture as a fancy new instrumentâ€”a versatile electric guitar, letâ€™s say, that can produce a whole range of sounds from classical to rock to jazz. Now, just like you can use that electric guitar in different types of bands, you can use parts of the Transformer architecture in different types of models.\n\nEncoder-Decoder Networks with Transformers: When people initially talked about Transformers, they were often referring to the full shebangâ€”both encoder and decoder. In a language translation model, the Transformerâ€™s encoder reads an English sentence and compresses its essence. The decoder then takes this essence and generates a Spanish sentence. Both sides are using self-attention, layer normalization, and all those Transformer goodies to do their jobs.\nEncoder-Only Transformers: In some tasks, you donâ€™t need the full band; a guitar solo will do. For instance, BERT (Bidirectional Encoder Representations from Transformers) uses just the encoder part of the Transformer architecture. It processes a sentence and spits out a rich, contextual representation of each word, which can then be used for tasks like text classification or filling in blanks.\nDecoder-Only Transformers: Now, what if we only want to jam and improvise? Thatâ€™s where models like GPT (Generative Pre-trained Transformer) come in. These models use only the decoder part of the Transformer architecture to generate new text. They still use self-attention and feed-forward layers, but they are more about predicting the next noteâ€”or in our case, the next wordâ€”in a sequence."
  },
  {
    "objectID": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-6",
    "href": "slides/nuggets_review/index.html#transformers-explained-by-chatgpt-6",
    "title": "A Summer of Nuggets",
    "section": "Transformers explained by ChatGPT",
    "text": "Transformers explained by ChatGPT\nSo there you go! Just like our versatile electric guitar can be part of a full orchestra, a rock band, or a solo act, different pieces of the Transformer architecture can be used to construct different kinds of neural network models. Each specialized version takes the core principles of the Transformer and applies them in a way thatâ€™s tailored to specific tasks."
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-to-build-a-chatgpt",
    "href": "slides/nuggets_review/index.html#how-to-build-a-chatgpt",
    "title": "A Summer of Nuggets",
    "section": "How to Build a ChatGPT?",
    "text": "How to Build a ChatGPT?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt-you-should-watch-this",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt-you-should-watch-this",
    "title": "A Summer of Nuggets",
    "section": "â€œThe state of GPTâ€ â€“ You should watch this!",
    "text": "â€œThe state of GPTâ€ â€“ You should watch this!\n\n\n\n\nAndrej Karpathy, â€œState of GPTâ€ | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt",
    "title": "A Summer of Nuggets",
    "section": "â€œThe state of GPTâ€",
    "text": "â€œThe state of GPTâ€\n\n\n\n\nAndrej Karpathy, â€œState of GPTâ€ | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-from-a-more-general-view",
    "href": "slides/nuggets_review/index.html#large-language-models-from-a-more-general-view",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models from a more general viewâ€¦",
    "text": "Large Language Models from a more general viewâ€¦\n\n\n\n\nâ€œMaking Large Language Models Work for You.â€ Accessed August 27, 2023. https://simonwillison.net/2023/Aug/27/wordcamp-llms/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#text-to-numbers",
    "href": "slides/nuggets_review/index.html#text-to-numbers",
    "title": "A Summer of Nuggets",
    "section": "Text to numbersâ€¦",
    "text": "Text to numbersâ€¦\n\n\n\n\nâ€œTiktokenizer.â€ Accessed August 27, 2023. https://tiktokenizer.vercel.app/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt",
    "href": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt",
    "title": "A Summer of Nuggets",
    "section": "Base models create general representations through â€œPre-Trainingâ€ (GPT)",
    "text": "Base models create general representations through â€œPre-Trainingâ€ (GPT)\n\n\n\n\nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. â€œImproving Language Understanding by Generative Pre-Training,â€ n.d."
  },
  {
    "objectID": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt-1",
    "href": "slides/nuggets_review/index.html#base-models-create-general-representations-through-pre-training-gpt-1",
    "title": "A Summer of Nuggets",
    "section": "Base models create general representations through â€œPre-Trainingâ€ (GPT)",
    "text": "Base models create general representations through â€œPre-Trainingâ€ (GPT)\n\n\n\n\nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. â€œImproving Language Understanding by Generative Pre-Training,â€ n.d."
  },
  {
    "objectID": "slides/nuggets_review/index.html#pre-training-datasets",
    "href": "slides/nuggets_review/index.html#pre-training-datasets",
    "title": "A Summer of Nuggets",
    "section": "â€œPre-Training Datasets?â€",
    "text": "â€œPre-Training Datasets?â€"
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models",
    "href": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models",
    "title": "A Summer of Nuggets",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, et al.Â â€œLLaMA: Open and Efficient Foundation Language Models.â€ arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models-1",
    "href": "slides/nuggets_review/index.html#llama-open-and-efficient-foundation-language-models-1",
    "title": "A Summer of Nuggets",
    "section": "LLama: Open and Efficient Foundation Language Models",
    "text": "LLama: Open and Efficient Foundation Language Models\n\n\n\n\n\n\n\n\nTouvron, Hugo, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, et al.Â â€œLLaMA: Open and Efficient Foundation Language Models.â€ arXiv, February 27, 2023. https://doi.org/10.48550/arXiv.2302.13971."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gao-et-al.-the-pile",
    "href": "slides/nuggets_review/index.html#gao-et-al.-the-pile",
    "title": "A Summer of Nuggets",
    "section": "Gao et al.Â â€œThe Pileâ€?",
    "text": "Gao et al.Â â€œThe Pileâ€?\n\n\n\n\n \n\n\n\nGao, Leo, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, et al.Â â€œThe Pile: An 800GB Dataset of Diverse Text for Language Modeling.â€ arXiv, December 31, 2020. https://doi.org/10.48550/arXiv.2101.00027."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gao-et-al.-the-pile-1",
    "href": "slides/nuggets_review/index.html#gao-et-al.-the-pile-1",
    "title": "A Summer of Nuggets",
    "section": "Gao et al.Â â€œThe Pileâ€?",
    "text": "Gao et al.Â â€œThe Pileâ€?\n\n\n\n\n \n\n\n\nGao, Leo, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, et al.Â â€œThe Pile: An 800GB Dataset of Diverse Text for Language Modeling.â€ arXiv, December 31, 2020. https://doi.org/10.48550/arXiv.2101.00027."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong-1",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong-1",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\n\n\n\nâ€œSarah Silverman Sues OpenAI and Meta Alleging Copyright Infringement | CNN Business.â€ Accessed August 27, 2023. https://www.cnn.com/2023/07/10/tech/sarah-silverman-openai-meta-lawsuit/index.html."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-could-go-wrong-2",
    "href": "slides/nuggets_review/index.html#what-could-go-wrong-2",
    "title": "A Summer of Nuggets",
    "section": "What could go wrong?",
    "text": "What could go wrong?\n\n\n\n\nâ€œWould I forbid the teaching (if that is the word) of my stories to computers? Not even if I could. I might as well be King Canute, forbidding the tide to come in. Or a Luddite trying to stop industrial progress by hammering a steam loom to pieces.â€ â€“ Stephen King\n\n\n\nReisner, Alex. â€œRevealed: The Authors Whose Pirated Books Are Powering Generative AI.â€ The Atlantic, August 19, 2023. https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/.\nKing, Stephen. â€œStephen King: My Books Were Used to Train AI.â€ The Atlantic, August 23, 2023. https://www.theatlantic.com/books/archive/2023/08/stephen-king-books-ai-writing/675088/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-language-models-are-few-shot-learners-2020",
    "href": "slides/nuggets_review/index.html#gpt-3-language-models-are-few-shot-learners-2020",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Language Models are Few-Shot Learners (2020)",
    "text": "(GPT-3) Language Models are Few-Shot Learners (2020)\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al.Â â€œLanguage Models Are Few-Shot Learners.â€ arXiv, July 22, 2020. https://doi.org/10.48550/arXiv.2005.14165."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-in-context-learning",
    "href": "slides/nuggets_review/index.html#gpt-3-in-context-learning",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) In-Context Learning",
    "text": "(GPT-3) In-Context Learning\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al.Â â€œLanguage Models Are Few-Shot Learners.â€ arXiv, July 22, 2020. https://doi.org/10.48550/arXiv.2005.14165."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "href": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al.Â â€œTraining Language Models to Follow Instructions with Human Feedback.â€ arXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback-1",
    "href": "slides/nuggets_review/index.html#gpt-3-instruct-gpt-reinforcement-learning-from-human-feedback-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback",
    "text": "(GPT-3) Instruct-GPT Reinforcement Learning from Human Feedback\n\n\n\n\nOuyang, Long, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, et al.Â â€œTraining Language Models to Follow Instructions with Human Feedback.â€ arXiv, March 4, 2022. https://doi.org/10.48550/arXiv.2203.02155."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) â€œSparks of AGIâ€?",
    "text": "(GPT-4) â€œSparks of AGIâ€?\n\n\n\n\nBubeck, SÃ©bastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al.Â â€œSparks of Artificial General Intelligence: Early Experiments with GPT-4.â€ arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-1",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) â€œSparks of AGIâ€?",
    "text": "(GPT-4) â€œSparks of AGIâ€?\n\n\n\n\nBubeck, SÃ©bastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al.Â â€œSparks of Artificial General Intelligence: Early Experiments with GPT-4.â€ arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-2",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-2",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) â€œSparks of AGIâ€?",
    "text": "(GPT-4) â€œSparks of AGIâ€?\n\n\n\n\nBubeck, SÃ©bastien, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, et al.Â â€œSparks of Artificial General Intelligence: Early Experiments with GPT-4.â€ arXiv, April 13, 2023. https://doi.org/10.48550/arXiv.2303.12712."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-3",
    "href": "slides/nuggets_review/index.html#gpt-4-sparks-of-agi-3",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) â€œSparks of AGIâ€?",
    "text": "(GPT-4) â€œSparks of AGIâ€?\n\n\n\n\nSparks of AGI: Early Experiments with GPT-4, 2023. https://www.youtube.com/watch?v=qbIk7-JPB2c."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llm-behavior-changes-with-time",
    "href": "slides/nuggets_review/index.html#llm-behavior-changes-with-time",
    "title": "A Summer of Nuggets",
    "section": "LLM Behavior Changes with Time!",
    "text": "LLM Behavior Changes with Time!\n\n\n\n\nChen, Lingjiao, Matei Zaharia, and James Zou. â€œHow Is ChatGPTâ€™s Behavior Changing over Time?â€ arXiv, July 18, 2023. http://arxiv.org/abs/2307.09009."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-towards-truthgpt",
    "href": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-towards-truthgpt",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) OpenAI Reinforcement Learning â€“ â€œTowards TruthGPTâ€",
    "text": "(GPT-4) OpenAI Reinforcement Learning â€“ â€œTowards TruthGPTâ€\n\n\n\n\nJohn Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges, 2023. https://www.youtube.com/watch?v=hhiLw5Q_UFg."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-conceptual-models",
    "href": "slides/nuggets_review/index.html#gpt-4-openai-reinforcement-learning-conceptual-models",
    "title": "A Summer of Nuggets",
    "section": "(GPT-4) OpenAI Reinforcement Learning â€“ â€œConceptual Modelsâ€",
    "text": "(GPT-4) OpenAI Reinforcement Learning â€“ â€œConceptual Modelsâ€\n\n\n\n\nJohn Schulman - Reinforcement Learning from Human Feedback: Progress and Challenges, 2023. https://www.youtube.com/watch?v=hhiLw5Q_UFg."
  },
  {
    "objectID": "slides/nuggets_review/index.html#claude-constitutional-ai",
    "href": "slides/nuggets_review/index.html#claude-constitutional-ai",
    "title": "A Summer of Nuggets",
    "section": "(Claude) â€œConstitutional AIâ€",
    "text": "(Claude) â€œConstitutional AIâ€\n\n\n\n\nAnthropic. â€œClaudeâ€™s Constitution.â€ Accessed August 28, 2023. https://www.anthropic.com/index/claudes-constitution.\nBai, Yuntao, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, et al.Â â€œConstitutional AI: Harmlessness from AI Feedback.â€ arXiv, December 15, 2022. https://doi.org/10.48550/arXiv.2212.08073."
  },
  {
    "objectID": "slides/nuggets_review/index.html#claude-foundation-model-in-aws-bedrock",
    "href": "slides/nuggets_review/index.html#claude-foundation-model-in-aws-bedrock",
    "title": "A Summer of Nuggets",
    "section": "(Claude) â€œFoundation Model in AWS Bedrockâ€",
    "text": "(Claude) â€œFoundation Model in AWS Bedrockâ€\n\n\n\n\n\n\n\n\nAnthropic. â€œClaude 2.â€ Accessed August 28, 2023. https://www.anthropic.com/index/claude-2.\nAnthropic. â€œClaude 2 on Amazon Bedrock.â€ Accessed August 28, 2023. https://www.anthropic.com/index/claude-2-amazon-bedrock."
  },
  {
    "objectID": "slides/nuggets_review/index.html#llama-2open-license-large-language-models",
    "href": "slides/nuggets_review/index.html#llama-2open-license-large-language-models",
    "title": "A Summer of Nuggets",
    "section": "(Llama 2)â€œOpen-Licenseâ€ Large Language Models",
    "text": "(Llama 2)â€œOpen-Licenseâ€ Large Language Models\n\n\n\n\nMeta AI. â€œMeta and Microsoft Introduce the Next Generation of Llama.â€ Accessed August 28, 2023. https://ai.meta.com/blog/llama-2/.\nMeta AI. â€œLlama 2.â€ Accessed August 28, 2023. https://ai.meta.com/llama-project."
  },
  {
    "objectID": "slides/nuggets_review/index.html#the-state-of-gpt-recommendations",
    "href": "slides/nuggets_review/index.html#the-state-of-gpt-recommendations",
    "title": "A Summer of Nuggets",
    "section": "â€œThe state of GPTâ€ Recommendations",
    "text": "â€œThe state of GPTâ€ Recommendations\n\n\n\n\nAndrej Karpathy, â€œState of GPTâ€ | BRK216HFS, Microsoft Build, 2023. https://www.youtube.com/watch?v=bZQun8Y4L2A."
  },
  {
    "objectID": "slides/nuggets_review/index.html#reasoning",
    "href": "slides/nuggets_review/index.html#reasoning",
    "title": "A Summer of Nuggets",
    "section": "Reasoningâ€¦",
    "text": "Reasoningâ€¦"
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "href": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. â€œLarge Language Models Are Zero-Shot Reasoners.â€ arXiv, January 29, 2023. https://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning-1",
    "href": "slides/nuggets_review/index.html#gpt-3-large-language-models-are-zero-shot-reasoners-chain-of-thought-reasoning-1",
    "title": "A Summer of Nuggets",
    "section": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)",
    "text": "(GPT-3) Large Language Models are Zero Shot Reasoners (Chain-of-Thought Reasoning)\n\n\n\n\nKojima, Takeshi, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. â€œLarge Language Models Are Zero-Shot Reasoners.â€ arXiv, January 29, 2023. https://doi.org/10.48550/arXiv.2205.11916."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\nâ€œReAct: Synergizing Reasoning and Acting in Language Models.â€ Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. â€œReAct: Synergizing Reasoning and Acting in Language Models.â€ arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-1",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-1",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\nâ€œReAct: Synergizing Reasoning and Acting in Language Models.â€ Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. â€œReAct: Synergizing Reasoning and Acting in Language Models.â€ arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-2",
    "href": "slides/nuggets_review/index.html#react-synergizing-reasoning-and-acting-in-language-models-2",
    "title": "A Summer of Nuggets",
    "section": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "text": "ReAct: Synergizing Reasoning and Acting in Language Models\n\n\n\n\nâ€œReAct: Synergizing Reasoning and Acting in Language Models.â€ Accessed August 28, 2023. https://react-lm.github.io/.\nYao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. â€œReAct: Synergizing Reasoning and Acting in Language Models.â€ arXiv, March 9, 2023. http://arxiv.org/abs/2210.03629."
  },
  {
    "objectID": "slides/nuggets_review/index.html#prompt-engineering",
    "href": "slides/nuggets_review/index.html#prompt-engineering",
    "title": "A Summer of Nuggets",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\n\n\n\n\nâ€œPrompt Engineering Guide.â€ Accessed August 22, 2023. https://www.promptingguide.ai/."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners",
    "href": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models are Semantic Reasoners",
    "text": "Large Language Models are Semantic Reasoners\n\n\n\n\nTang, Xiaojuan, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. â€œLarge Language Models Are In-Context Semantic Reasoners Rather than Symbolic Reasoners.â€ arXiv, June 8, 2023. http://arxiv.org/abs/2305.14825."
  },
  {
    "objectID": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners-1",
    "href": "slides/nuggets_review/index.html#large-language-models-are-semantic-reasoners-1",
    "title": "A Summer of Nuggets",
    "section": "Large Language Models are Semantic Reasoners",
    "text": "Large Language Models are Semantic Reasoners\n\n\n\n\n\n\n\n\nTang, Xiaojuan, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu, Yitao Liang, and Muhan Zhang. â€œLarge Language Models Are In-Context Semantic Reasoners Rather than Symbolic Reasoners.â€ arXiv, June 8, 2023. http://arxiv.org/abs/2305.14825."
  },
  {
    "objectID": "slides/nuggets_review/index.html#our-research",
    "href": "slides/nuggets_review/index.html#our-research",
    "title": "A Summer of Nuggets",
    "section": "Our Researchâ€¦",
    "text": "Our Researchâ€¦"
  },
  {
    "objectID": "slides/nuggets_review/index.html#retrevial-augmented-generation",
    "href": "slides/nuggets_review/index.html#retrevial-augmented-generation",
    "title": "A Summer of Nuggets",
    "section": "Retrevial Augmented Generation",
    "text": "Retrevial Augmented Generation"
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-and-llms-must-read",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-and-llms-must-read",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs and LLMs â€“ Must Read!",
    "text": "Knowledge Graphs and LLMs â€“ Must Read!\n\n\n\n\nPan, Shirui, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. â€œUnifying Large Language Models and Knowledge Graphs: A Roadmap.â€ arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/nuggets_review/index.html#knowledge-graphs-and-frameworks",
    "href": "slides/nuggets_review/index.html#knowledge-graphs-and-frameworks",
    "title": "A Summer of Nuggets",
    "section": "Knowledge Graphs and Frameworks",
    "text": "Knowledge Graphs and Frameworks\n\n\n\n\nPan, Shirui, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. â€œUnifying Large Language Models and Knowledge Graphs: A Roadmap.â€ arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/nuggets_review/index.html#what-about-trusted-ai",
    "href": "slides/nuggets_review/index.html#what-about-trusted-ai",
    "title": "A Summer of Nuggets",
    "section": "What About Trusted AI?",
    "text": "What About Trusted AI?"
  },
  {
    "objectID": "slides/nuggets_review/index.html#how-to-talk-about-llms-must-read",
    "href": "slides/nuggets_review/index.html#how-to-talk-about-llms-must-read",
    "title": "A Summer of Nuggets",
    "section": "How to talk about LLMs? Must Read!",
    "text": "How to talk about LLMs? Must Read!\n\n\n\n\nShanahan, Murray. â€œTalking About Large Language Models.â€ arXiv, February 16, 2023. https://doi.org/10.48550/arXiv.2212.03551."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dameâ€™s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to â€œtranslational research,â€ a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your â€œAboutâ€ page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "href": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dameâ€™s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to â€œtranslational research,â€ a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your â€œAboutâ€ page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#our-toolset",
    "href": "about.html#our-toolset",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Our Toolset",
    "text": "Our Toolset\nAI Success Factors: Engineering Trust in Deployments is more than just a blog - itâ€™s a demonstration of how modern data science tools can streamline and simplify complex processes.\nOur blogging platform is built using Quarto, an open-source scientific and technical publishing system known for its flexibility and robustness. Quarto has the unique ability to support a wide range of content types, including Jupyter notebooks, R Markdown, and even Python or R scripts. Quartoâ€™s distinctive feature is its ability to include executable code within the documents from various languages such as Python, R, and others. This allows us to create data-driven blog posts where the output - be it a graph, a table, or other data representations - is generated directly from the included code. This adds an interactive element to our posts, giving readers a deeper understanding of the concepts and analyses presented. Quarto supports multiple output formats including HTML, PDF, EPUB, and Word, providing us the versatility to tailor our content to suit different needs. This flexible tool, coupled with its capability to handle larger projects made up of multiple files, allows us to efficiently manage our blog while maintaining consistency and quality across our posts. Quarto presentations are also used to generate revealjs presentations for weekly slide shows. Quarto forms the basis for Fast.aiâ€™s nbdev framework for exploritory programming allowing for software development in Jupyter Notebooks and automated generation of Python modules and documentation from the notebooks.\nDevelopment Containers serve as our primary environment for data science, providing a consistent and replicable framework for running our analyses. These containerized environments allow us to standardize our work and ensure that our research is reproducible and reliable. The dev container uses the Mamba solver to provision the python environment from the specification in the environment.yml.\nWe use Visual Studio Code (VS Code) as our primary code editor, taking advantage of its rich ecosystem of extensions and in-built features. VS Codeâ€™s Jupyter notebook support allows us to interactively develop and visualize our data models directly within the editor, enabling us to produce intuitive, data-driven narratives for our blog posts.\nAll of our content is version controlled and hosted on GitHub. GitHubâ€™s robust versioning system allows us to effectively manage changes, track progress, and ensure that every piece of content we publish is up to date and accurate.\nThe blog is published using GitHub Page, a platform that simplifies the deployment process and seamlessly integrates with our existing GitHub repository. This setup enables us to provide a reliable, accessible resource for our readers, irrespective of where they are or when they choose to access our content.\nFinally, we utilize GitHub Code Spaces to create a fully-featured, cloud-hosted development environment that can be accessed from any device. This not only allows us to work from anywhere but also ensures that our setup can be easily replicated by other researchers and developers who wish to explore our code.\nEach tool in our stack has been chosen for its ability to facilitate efficient, reliable, and transparent data science. By sharing our toolset, we hope to provide insight into our workflows and encourage a culture of open, reproducible research within the AI community."
  },
  {
    "objectID": "about.html#generative-ai-in-content-creation",
    "href": "about.html#generative-ai-in-content-creation",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Generative AI in Content Creation",
    "text": "Generative AI in Content Creation\nIn creating AI Success Factors: Engineering Trust in Deployments, we harness the power of artificial intelligence in conjunction with human expertise. We utilize advanced Generative AI models such as ChatGPT, Bing Chat, and Anthropic Claude in a guided, iterative process that combines the best of AI and human capabilities.\nOur use of Generative AI begins with the drafting stage. These models, trained on extensive datasets, generate human-like text that matches our specified tone and style, providing us with a solid foundation for each blog post. This allows us to focus on the larger narrative without getting mired in the nitty-gritty details from the outset.\nThe AI-generated drafts, while sophisticated, are just the starting point. We employ a methodology that involves guiding the AI to improve its output. This includes providing more detailed prompts, specifying the format we want the output in, or asking the model to think step-by-step before settling on a conclusion.\nOnce we have a draft that weâ€™re satisfied with, itâ€™s time for human intervention. Our team reviews the AI-generated content, refining and editing it to ensure it maintains the standards of accuracy, relevance, and depth that our readers expect. This process leverages critical human skills of creativity, critical thinking, and domain expertise that even the most advanced AI canâ€™t replicate.\nThis approach exemplifies our vision of a symbiotic relationship between AI and humans. By effectively integrating Generative AI into our content creation process, we not only boost our productivity and efficiency but also demonstrate the practical application of AI technologies in real-world scenarios. Thus, the blog becomes a testament to our commitment to translational research and our pursuit of an AI-integrated future."
  }
]
[
  {
    "objectID": "instruction_prompt.html",
    "href": "instruction_prompt.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "ChatGPT, please assist in drafting a blog post for AI Success Factors: Engineering Trust in Deployments. As a generative AI, your input serves as a starting point for discussion and is meticulously reviewed and edited by a team of AI researchers at the Laboratory for Assured AI Applications Development at the University of Notre Dame’s Center for Research Computing.\nThe intended audience includes students, professionals, and enthusiasts interested in the progression of AI, with a focus on the successful deployment of AI technologies. Each post aims to disseminate recent advancements and knowledge in AI, particularly in the fields of AI engineering, trust in AI, and knowledge engineering.\nFor this post, please generate content on the importance of trust in successful AI deployments. Begin with a general introduction to AI deployments, transition into the crucial role of trust, and provide real-world examples where the absence of trust led to issues. Discuss strategies for building trust in AI systems and conclude with insights on future trends in trust within the AI landscape. The tone should be academic yet accessible to our diverse readership."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "href": "slides/tai_testing/index.html#testing-and-cicd-for-trusted-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing and CI/CD for Trusted AI",
    "text": "Testing and CI/CD for Trusted AI\nTesting and CI/CD are software engineering practices that aim to ensure the quality, reliability, and security of software applications. They are especially important for AI applications, which involve complex and dynamic data, models, and algorithms."
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "href": "slides/tai_testing/index.html#what-is-software-1.0-and-software-2.0",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What is Software 1.0 and Software 2.0?",
    "text": "What is Software 1.0 and Software 2.0?\nSoftware 1.0 refers to the traditional way of developing software by writing code that specifies the logic and rules of the application. Software 2.0 refers to the emerging way of developing software by using machine learning (ML) models that learn from data and generate code or behavior."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-and-cicd-for-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why do we need testing and CI/CD for AI?",
    "text": "Why do we need testing and CI/CD for AI?\nAI applications pose unique challenges and risks for testing and CI/CD, such as:\n\nData quality and availability: AI applications depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: AI models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: AI applications may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "href": "slides/tai_testing/index.html#testing-and-cicd-can-help-address-these-challenges-and-risks-by",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing and CI/CD can help address these challenges and risks by:",
    "text": "Testing and CI/CD can help address these challenges and risks by:\n\nAutomating and streamlining the data, model, and code workflows of AI development\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in AI applications\nEnsuring that AI applications meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of AI applications"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "href": "slides/tai_testing/index.html#how-do-we-implement-testing-and-cicd-for-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How do we implement testing and CI/CD for AI?",
    "text": "How do we implement testing and CI/CD for AI?\nTesting and CI/CD for AI involve applying software engineering best practices to the data, model, and code components of AI applications. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing AI models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of AI models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates AI models"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-pipelines",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Real World Machine Learning “Pipelines”",
    "text": "Real World Machine Learning “Pipelines”\n\n\nTwitter: Andrej Karpathy\nLearn More: Autonomous Vehicle Training & Tesla’s Data Engine Explained, TESLA’S DATA ENGINE AND WHAT WE SHOULD LEARN FROM IT CVPR’20 Workshop on Scalability in Autonomous Driving Keynote - Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "href": "slides/tai_testing/index.html#real-world-machine-learning-data-engine",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Real World Machine Learning “Data Engine”",
    "text": "Real World Machine Learning “Data Engine”\n\n\nTwitter: Andrej Karpathy"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "href": "slides/tai_testing/index.html#how-teslas-data-engine-works",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How Tesla’s Data Engine works",
    "text": "How Tesla’s Data Engine works\n\nThe FSD computer in each Tesla car records and sends any inaccuracies or discrepancies between its actions and the human driver’s actions to Tesla’s servers.\nTesla’s servers use these inaccuracies to create unit tests, which are scenarios that the FSD neural network should be able to handle correctly.\nTesla’s servers also use these inaccuracies to search for similar situations in the vast amount of data collected from all the cars in the fleet and create a well-labeled dataset.\nTesla’s servers use this dataset to re-train the FSD neural network using machine learning algorithms and improve its performance and functionality.\nTesla’s servers deploy the updated FSD neural network to the cars’ FSD computers in “shadow mode” to compare its actions with the human driver’s actions."
  },
  {
    "objectID": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "href": "slides/tai_testing/index.html#why-teslas-data-engine-matters",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why Tesla’s Data Engine matters",
    "text": "Why Tesla’s Data Engine matters\n\nTesla’s Data Engine allows them to leverage the power of big data analytics and artificial intelligence in their self-driving cars.\nTesla’s Data Engine enables them to address the long tail problem of autonomous driving, which is the challenge of handling rare or complex situations on the road.\nTesla’s Data Engine ensures that the FSD neural network is constantly improving and not regressing or introducing new errors.\n\n\nLearn More: [Tesla’s Data Engine and what we should learn from it]"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "href": "slides/tai_testing/index.html#what-is-testing-for-ai-vs-traditional-software-testing",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What is “Testing” for AI vs Traditional Software Testing",
    "text": "What is “Testing” for AI vs Traditional Software Testing\n\n\nLearn More: Effective testing for machine learning systems\nYoutube Discussion: MLOps Chat: How Should We Test ML Models? with Data Scientist Jeremy Jordan"
  },
  {
    "objectID": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "href": "slides/tai_testing/index.html#why-do-we-need-testing-for-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Why do we need testing for ML systems?",
    "text": "Why do we need testing for ML systems?\nML systems pose unique challenges and risks for testing, such as:\n\nData quality and availability: ML systems depend on large and diverse datasets that may be noisy, incomplete, biased, or outdated.\nModel performance and robustness: ML models may have high accuracy on average, but low accuracy on edge cases or adversarial inputs. They may also degrade over time or become obsolete due to data drift or concept drift.\nEthical and social implications: ML systems may have unintended or harmful consequences on human values, rights, and well-being, such as privacy, fairness, accountability, transparency, and explainability.\n\nTesting ML systems can help address these challenges and risks by:\n\nDetecting and preventing errors, bugs, vulnerabilities, and anomalies in ML systems\nEnsuring that ML systems meet the functional, non-functional, and ethical requirements of the stakeholders\nEnabling continuous improvement and innovation of ML systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "href": "slides/tai_testing/index.html#how-do-we-test-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "How do we test ML systems?",
    "text": "How do we test ML systems?\nTesting ML systems involves applying software engineering best practices to the data, model, and code components of ML systems. Some examples are:\n\nData testing: Validating the quality, consistency, completeness, relevance, and diversity of the data used for training and testing ML models\nModel testing: Evaluating the accuracy, robustness, efficiency, scalability, interpretability, and fairness of ML models on various metrics and scenarios\nCode testing: Verifying the functionality, usability, security, reliability, maintainability, and portability of the code that implements or integrates ML models"
  },
  {
    "objectID": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "href": "slides/tai_testing/index.html#what-are-some-tools-and-techniques-for-testing-ml-systems",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "What are some tools and techniques for testing ML systems?",
    "text": "What are some tools and techniques for testing ML systems?\nThere are different tools and techniques that can help us test ML systems effectively and efficiently. Some examples are:\n\nData validation tools: Tools that help us check the schema, statistics, anomalies, drifts, and distributions of our data. For example: TensorFlow Data Validation, Great Expectations, Deequ.\nModel validation tools: Tools that help us measure the performance of our models on various metrics and scenarios. For example: TensorFlow Model Analysis, Scikit-Learn, PyTorch.\nCode validation tools: Tools that help us check the syntax, style, coverage, complexity, and security of our code. For example: PyLint, PyTest, Bandit."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "href": "slides/tai_testing/index.html#testing-software-1.0-vs-software-2.0",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing “Software 1.0” vs “Software 2.0”",
    "text": "Testing “Software 1.0” vs “Software 2.0”\n\n\nLearn More: Effective testing for machine learning systems"
  },
  {
    "objectID": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "href": "slides/tai_testing/index.html#beyond-accuracy-behavioral-testing-of-nlp-models-with-checklist",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "“Beyond Accuracy: Behavioral Testing of NLP Models with CheckList”",
    "text": "“Beyond Accuracy: Behavioral Testing of NLP Models with CheckList”\n\n\nLearn More: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList\nGitHub:Beyond Accuracy: Behavioral Testing of NLP Models with CheckList"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Examples of “real world” testing",
    "text": "Examples of “real world” testing\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "href": "slides/tai_testing/index.html#examples-of-real-world-testing-as-a-starting-point",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Examples of “real world” testing as a starting point",
    "text": "Examples of “real world” testing as a starting point\n\n\nLearn More: Microsoft Recommenders GitHub"
  },
  {
    "objectID": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "href": "slides/tai_testing/index.html#test-structure-in-the-microsoft-recommenders",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Test Structure in the Microsoft Recommenders",
    "text": "Test Structure in the Microsoft Recommenders\nThe Microsoft Recommenders repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repository also includes various tests to ensure the quality, reliability, and security of the code and the notebooks."
  },
  {
    "objectID": "slides/tai_testing/index.html#types-of-tests",
    "href": "slides/tai_testing/index.html#types-of-tests",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Types of Tests",
    "text": "Types of Tests\nThere are three types of tests in the Microsoft Recommenders repository:\n\nUnit tests: These are tests that check the functionality and correctness of individual modules, functions, or classes. They are located in the unit folder and use pytest as the testing framework. They are triggered by pull requests to the main or staging branches.\nSmoke tests: These are tests that check if the notebooks can run without errors and produce the expected outputs. They are located in the smoke folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches.\nIntegration tests: These are tests that check if the notebooks can run end-to-end on different environments and platforms, such as CPU, GPU, or Spark. They are located in the integration folder and use papermill and scrapbook as the testing tools. They are run nightly on the main or staging branches."
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-devops",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Azure DevOps",
    "text": "Testing Infrastructure: Azure DevOps\nThe Microsoft Recommenders repository uses Azure DevOps as the testing infrastructure. Azure DevOps is a cloud-based platform that provides various services and tools for software development, such as version control, project management, testing, deployment, and monitoring.\nThere are 19 pipelines for Linux tests and 19 pipelines for Windows tests, each corresponding to a different type of test, branch, and environment. For example:\n\nunit_tests: This pipeline runs unit tests on Linux CPU for pull requests to the main branch.\nunit_tests_staging: This pipeline runs unit tests on Linux CPU for pull requests to the staging branch.\ngpu_unit_tests: This pipeline runs unit tests on Linux GPU for pull requests to the main branch.\ngpu_unit_tests_staging: This pipeline runs unit tests on Linux GPU for pull requests to the staging branch.\nnightly_cpu: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the main branch.\nnightly_staging: This pipeline runs smoke and integration tests on Linux CPU for nightly builds on the staging branch.\nnightly_gpu: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the main branch.\nnightly_gpu_staging: This pipeline runs smoke and integration tests on Linux GPU for nightly builds on the staging branch.\nnightly_spark: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the main branch.\nnightly_spark_staging: This pipeline runs smoke and integration tests on Linux Spark for nightly builds on the staging branch.\n\n\nLearn More: [Test Strategy · microsoft/recommenders Wiki · GitHub]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "href": "slides/tai_testing/index.html#testing-infrastructure-conda-environments",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Conda Environments",
    "text": "Testing Infrastructure: Conda Environments\nThe pipelines use conda environments to manage dependencies and run tests. Conda is an open-source package and environment management system that allows us to create and use different configurations of software packages and libraries.\nA script, generate_conda_file.py, is used to create conda environments for different combinations of CPU, GPU, and Spark. For example:\n\nreco_base: This is the basic CPU environment.\nreco_full: This is the environment that includes CPU, GPU, and Spark.\nreco_gpu: This is the environment that includes CPU and GPU.\nreco_pyspark: This is the environment that includes CPU and Spark.\n\n\nLearn More: [Conda — Conda documentation]"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "href": "slides/tai_testing/index.html#testing-infrastructure-azure-machine-learning",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing Infrastructure: Azure Machine Learning",
    "text": "Testing Infrastructure: Azure Machine Learning\nThe pipelines also use Azure Machine Learning (AML) to run some of the tests on different compute clusters. AML is a cloud-based service that provides various tools and features for ML development, such as data preparation, model training, model deployment, model management, and model monitoring.\nAML provides scalable and flexible compute resources for ML development. For example:\n\nAMLCompute clustername Experiment VM Nodes\nreco-cpu-test2 cpu_unit_tests standard_d3_v2 0..4\nreco-gpu-test gpu_unit_tests standard_nc6_v3 0..4\nreco-spark-test spark_unit_tests standard_d12_v2 0..4\n\n\nLearn More: [What is Azure Machine Learning? - Azure Machine Learning | Microsoft Docs]"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPT’s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "href": "slides/tai_testing/index.html#chatgpt-behavior-drift-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "ChatGPT Behavior Drift?",
    "text": "ChatGPT Behavior Drift?\n\n\nLearn More: How is ChatGPT’s behavior changing over time?"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Tracking LLM “Agent Abilities”",
    "text": "Tracking LLM “Agent Abilities”\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "href": "slides/tai_testing/index.html#tracking-llm-agent-abilities-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Tracking LLM “Agent Abilities”",
    "text": "Tracking LLM “Agent Abilities”\n\n\nLearn More: AgentBench: Evaluating LLMs as Agents"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-cicd",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing in the context of CI/CD",
    "text": "Testing in the context of CI/CD\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "href": "slides/tai_testing/index.html#testing-in-the-context-of-sboms",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Testing in the context of SBoMs",
    "text": "Testing in the context of SBoMs\n\n\nLearn More: Testing stages in continuous integration and continuous delivery"
  },
  {
    "objectID": "slides/tai_testing/index.html#other-updates",
    "href": "slides/tai_testing/index.html#other-updates",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Other Updates",
    "text": "Other Updates"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "href": "slides/tai_testing/index.html#deploying-llama2-to-aws-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Deploying llama2 to AWS",
    "text": "Deploying llama2 to AWS\n\n\nLearn More: Deploy Llama 2 7B/13B/70B on Amazon SageMaker"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai",
    "href": "slides/tai_testing/index.html#juypter-ai",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter\nGitHub: A generative AI extension for JupyterLab"
  },
  {
    "objectID": "slides/tai_testing/index.html#juypter-ai-1",
    "href": "slides/tai_testing/index.html#juypter-ai-1",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Juypter AI",
    "text": "Juypter AI\n\n\nLearn More: Generative AI in Jupyter"
  },
  {
    "objectID": "slides/tai_testing/index.html#kaggle-llm-resource",
    "href": "slides/tai_testing/index.html#kaggle-llm-resource",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Kaggle LLM Resource",
    "text": "Kaggle LLM Resource\n\n\nLearn More: Getting Started With LLMs"
  },
  {
    "objectID": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "href": "slides/tai_testing/index.html#prompt-enginnering-guide",
    "title": "Things that concern Dr. Vardeman: Testing",
    "section": "Prompt Enginnering Guide",
    "text": "Prompt Enginnering Guide\n\n\nLearn More: Prompt Engineering Guide"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "href": "slides/kg-llamaindex/index.html#kg-construction-pipeline",
    "title": "KG Construction",
    "section": "KG Construction Pipeline",
    "text": "KG Construction Pipeline"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-2",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "href": "slides/kg-llamaindex/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-3",
    "title": "KG Construction",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "href": "slides/kg-llamaindex/index.html#llm-kg-construction-frameworks-llamaindex",
    "title": "KG Construction",
    "section": "LLM KG Construction Frameworks Llamaindex",
    "text": "LLM KG Construction Frameworks Llamaindex\n\nLearn more: Llamaindex"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#rebel-large-model",
    "href": "slides/kg-llamaindex/index.html#rebel-large-model",
    "title": "KG Construction",
    "section": "Rebel Large Model",
    "text": "Rebel Large Model\n#| echo: true\nfrom transformers import pipeline\n\ntriplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n# We need to use the tokenizer manually since we need special tokens.\nextracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\nprint(extracted_text[0])\n# Function to parse the generated text and extract the triplets\ndef extract_triplets(text):\n    triplets = []\n    relation, subject, relation, object_ = '', '', '', ''\n    text = text.strip()\n    current = 'x'\n    for token in text.replace(\"&lt;s&gt;\", \"\").replace(\"&lt;pad&gt;\", \"\").replace(\"&lt;/s&gt;\", \"\").split():\n        if token == \"&lt;triplet&gt;\":\n            current = 't'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n                relation = ''\n            subject = ''\n        elif token == \"&lt;subj&gt;\":\n            current = 's'\n            if relation != '':\n                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n            object_ = ''\n        elif token == \"&lt;obj&gt;\":\n            current = 'o'\n            relation = ''\n        else:\n            if current == 't':\n                subject += ' ' + token\n            elif current == 's':\n                object_ += ' ' + token\n            elif current == 'o':\n                relation += ' ' + token\n    if subject != '' and relation != '' and object_ != '':\n        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n    return triplets\nextracted_triplets = extract_triplets(extracted_text[0])\nprint(extracted_triplets)\n\nLearn more: Rebel Large"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel",
    "text": "LlamaIndex with Rebel\n\n\nLearn more: Llamaindex with Rebel Colab Notebook"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "href": "slides/kg-llamaindex/index.html#llamaindex-with-rebel-and-neo4j",
    "title": "KG Construction",
    "section": "LlamaIndex with Rebel and Neo4j",
    "text": "LlamaIndex with Rebel and Neo4j\n\n\nLearn more: Neo4j Graph Store\nGitHub: Tomaz Bratanic"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "href": "slides/kg-llamaindex/index.html#weaviate-with-llama-2-and-llamaindex",
    "title": "KG Construction",
    "section": "Weaviate With Llama 2 and Llamaindex",
    "text": "Weaviate With Llama 2 and Llamaindex\n\n\nLearn more: Welcome to the quick notebook on using Llama 2"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs",
    "title": "KG Construction",
    "section": "Weaviate “Knowledge Graphs”",
    "text": "Weaviate “Knowledge Graphs”\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "href": "slides/kg-llamaindex/index.html#weaviate-knowledge-graphs-1",
    "title": "KG Construction",
    "section": "Weaviate “Knowledge Graphs”",
    "text": "Weaviate “Knowledge Graphs”\n\n\nExample: NASA Graph-Enabled Vector Search"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#aws-neptune",
    "href": "slides/kg-llamaindex/index.html#aws-neptune",
    "title": "KG Construction",
    "section": "AWS Neptune",
    "text": "AWS Neptune\n\n\nLearn More: Amazon Neptune"
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "href": "slides/kg-llamaindex/index.html#amazon-science-refined",
    "title": "KG Construction",
    "section": "Amazon Science ReFinED",
    "text": "Amazon Science ReFinED\n\n\nPaper: ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking\nPaper: Improving Entity Disambiguation by Reasoning over a Knowledge Base\nGitHub: ReFinED is an efficient and accurate entity linking (EL) system."
  },
  {
    "objectID": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "href": "slides/kg-llamaindex/index.html#amazon-science-kgqa",
    "title": "KG Construction",
    "section": "Amazon Science KGQA",
    "text": "Amazon Science KGQA\n\n\nWebsite: Language models as controlled natural language semantic parsers for knowledge graph question answering GitHub: Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "Welcome To AI Success Factors: Engineering Trust in Deployments\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2023\n\n\nCharles F. Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "",
    "text": "At the University of Notre Dame’s Center for Research Computing (CRC), the Laboratory for Assured AI Applications Development (LA3D) represents a critical step in the field of artificial intelligence (AI). As part of CRC’s commitment to leveraging advanced computation for discovery and innovation, LA3D focuses on ensuring the responsible development and application of AI technologies. This initiative aligns with both the technological evolution of AI and the broader goals of CRC and Notre Dame.\nThe mission of LA3D is robust, layered, and rooted in a commitment to research, develop, and deploy AI models and systems that are not just innovative but trustworthy and ethically aligned. With a focus on AI Engineering, Trusted AI, Knowledge Engineering, FAIR (Findable, Accessible, Interoperable, and Reusable) data, and CyberInfrastructure, LA3D presents a multifaceted approach.\nAI’s Transformative Potential: The transformative potential of AI is no longer a distant aspiration but a present-day reality. Whether in healthcare, finance, transportation, or education, AI’s capacity to innovate is unparalleled. LA3D recognizes this potential and strives to harness it, directing AI’s power towards constructive, ethical, and sustainable ends.\nConnection to the Center for Research Computing: LA3D’s home in the CRC is more than a mere geographical placement. It symbolizes a shared vision of advancing science through computational methods, high-performance computing, and now, AI-driven solutions. By integrating into the CRC’s vibrant ecosystem, LA3D amplifies the pursuit of excellence, pushing the boundaries of what’s achievable with AI.\nMission Overview: LA3D’s mission transcends traditional boundaries, aiming to advance fields like AI Engineering, with its critical role in transitioning prototypes to production; Trusted AI, embodying ethical and reliable systems; Knowledge Engineering, embracing the new frontiers of Large Language Models; FAIR data principles; and the rapidly evolving CyberInfrastructure. Each of these elements comes together to create a synergy that fuels LA3D’s ambition to lead AI into an era marked by integrity, ingenuity, and human-centric focus.\nThe launch of LA3D marks a promising beginning in a journey filled with exploration, challenge, and opportunity. It sets the stage for an intellectual adventure that seeks to navigate the complex landscape of AI, unlocking its potentials while remaining anchored to values and ethical principles. Welcome to the Laboratory for Assured AI Applications Development – a place where AI’s promise transforms into tangible progress."
  },
  {
    "objectID": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "href": "posts/welcome/index.html#the-imperative-of-the-disciplines",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "The Imperative of the Disciplines",
    "text": "The Imperative of the Disciplines\n\nAI Engineering: Bridging the Gap from Prototype to Production\nIn the complex, multifaceted realm of AI, the journey from concept to realization is fraught with challenges and intricacies. AI Engineering, a core discipline at the Laboratory for Assured AI Applications Development (LA3D), stands as a beacon guiding this intricate transition from prototypes to production-grade applications.\n\nTransitioning Prototypes to Production: At LA3D, we recognize that the gap between experimental AI prototypes and fully functional production systems is vast. AI Engineering provides the methodologies, tools, and practices needed to navigate this gap. It’s about ensuring that promising concepts don’t just remain on paper but evolve into tangible applications. The recent Gartner research resonates with our approach, identifying that only 53% of AI projects transition from prototypes to production, underscoring the need for an engineering-driven approach.\nCore Pillars: DataOps, ModelOps, DevOps: DataOps focuses on data management and quality, ModelOps on model lifecycle management, and DevOps for seamless integration. These three core pillars together facilitate performance, scalability, interpretability, and reliability of AI models, maximizing the value of AI investments.\nAssurance in AI Models and Mechanistic Interpretability: Assurance in AI Models and Mechanistic Interpretability: Trust and reliability lie at the core of AI Engineering. At LA3D, the utilization of energy-based modeling, specifically Joint Energy-Based Models (JEMs), offers a transparent and statistically grounded approach to AI. By learning joint distributions over observed and latent variables, and associating lower energies with more likely configurations, JEMs help in aligning AI models with ethical guidelines and intended purposes. This mechanistic interpretability, coupled with the robust design inherent in JEMs, ensures predictability and engenders trust. Such alignment is vital for Assured AI, where understanding the underlying patterns and regularities in data becomes a cornerstone for creating reliable and responsible applications.\nScalability, Efficiency, Lifecycle Management, and Data-Centric AI: Ensuring consistent performance across different scales and complexities is crucial. LA3D’s AI Engineering practices enable models to be deployed in various environments without losing integrity or performance. Managing AI models throughout their lifecycle through continuous monitoring, validation, and maintenance ensures adaptability and alignment with evolving objectives. The emphasis on Data-Centric AI reflects LA3D’s commitment to focusing on the quality of data, recognizing that data is the lifeblood of AI systems.\nInterdisciplinary Collaboration and Alignment with Human Values: AI Engineering fosters collaboration among data scientists, engineers, domain experts, and ethical compliance teams. The result is cohesive AI development, where varying perspectives merge to create solutions resonating with diverse needs and values. At LA3D, AI serves human values and societal needs, ensuring that technology is not only technically sound but also socially responsible.\nEmbracing CyberSecurity: Coupled with a growing interest in CyberSecurity, LA3D extends the scope of AI Engineering to safeguard information and assure security in AI applications.\n\nAI Engineering is not merely a process at LA3D; it’s a philosophy and an imperative discipline. It’s the bedrock that ensures AI models are not just innovative but also responsible, practical, and aligned with the human experience. Bridging the gap from prototype to production, AI Engineering paves the way for a future where AI is not just a tool but a reliable partner for progress. Join us on this journey as we delve deeper into AI Engineering, exploring its challenges, triumphs, and nuances.\n\n\nTrusted AI: A Cornerstone of Ethical and Reliable Systems\nTrusted AI is not just a concept; it’s a commitment to integrity, ethics, and societal alignment that LA3D wholeheartedly embraces. Trust in AI is an essential component in our technological landscape, and it embodies various facets that work in synergy to create ethical and reliable systems.\n\nAssurance in AI Models: At LA3D, assurance goes beyond mere compliance; it’s about creating AI models that can be understood, scrutinized, and validated. Building AI models that can explain their reasoning and provide clarity in their decisions is integral to creating trust.\nTransparency and Accountability: The quest for Trusted AI demands complete transparency in both process and outcomes. LA3D adheres to an open and comprehensible approach that allows all stakeholders to understand how decisions are made and who is accountable for them. Ensuring this level of transparency fosters an environment where AI models can be thoroughly evaluated and critiqued, reinforcing trust in their use.\nResponsible AI: While Trusted AI focuses on reliability and ethics, Responsible AI broadens the spectrum to include considerations such as fairness, inclusivity, privacy, and societal impact. At LA3D, we recognize that AI systems must not only operate within ethical guidelines but also actively contribute to the well-being of society. This commitment to social responsibility aligns with our holistic approach to developing technology that enriches lives.\nCyberSecurity in AI: As AI systems become more intertwined with our daily lives, the need to secure them becomes paramount. LA3D is committed to incorporating CyberSecurity measures within the AI development process, safeguarding data and protecting the integrity of AI systems. We understand that trust in AI also depends on the security of the systems, and we dedicate our resources to ensure that our AI applications are robust against threats.\n\nTrusted AI is a cornerstone at LA3D, reflecting our relentless pursuit of aligning technology with human values and ethical principles. It’s about creating AI that people can rely on, understand, and feel safe using. The interplay between transparency, accountability, Responsible AI, and CyberSecurity forms a unified approach to build AI systems that not only perform exceptionally but also resonate with the broader societal goals.\nJoin us as we explore further the nuances of Trusted AI, a field where technology and ethics merge to pave the way for a future where AI is a dependable ally. Our commitment to this discipline underscores the depth of our understanding of the complexities involved in crafting AI that is truly trusted.\nThis section outlines the key areas of Trusted AI that LA3D focuses on, emphasizing the importance of trust, transparency, responsibility, and security within the AI domain. It underscores the laboratory’s dedication to ethical and reliable AI systems, aligning with societal needs and values.\n\n\nKnowledge Engineering and Prompt Engineering: The New Frontiers\nIn the rapidly evolving landscape of artificial intelligence, Knowledge Engineering and Prompt Engineering emerge as exciting new frontiers that promise to reshape the way we conceptualize, create, and leverage AI systems. At the Laboratory for Assured AI Applications Development (LA3D), we recognize the vital role of these disciplines in shaping the next generation of AI applications.\n\nKnowledge Graphs: Knowledge graphs represent a transformative approach to organizing and connecting information. By modeling relationships between entities in a structured and semantically rich format, knowledge graphs enable more intelligent querying and reasoning. LA3D actively leverages knowledge graphs to power more insightful and context-aware AI solutions.\nOntology Design Patterns: A specialized aspect of Knowledge Engineering, ontology design patterns allow for the formal representation of concepts and their relationships within a specific domain. By utilizing these patterns, LA3D ensures that AI systems have a solid conceptual foundation, enabling more precise interpretation and decision-making.\nLLM Techniques: Large Language Models (LLMs) are revolutionizing natural language processing. By employing techniques like Prompt Engineering, LA3D refines the interaction with LLMs, enhancing their responsiveness and adaptability. This method allows for more effective communication with AI systems, aligning them closer to human-like understanding.\nAI Models as Surrogates: At LA3D, we explore the exciting potential of AI models as surrogates for complex mathematical or physical models. These AI surrogates can provide faster and more accessible simulations, accelerating research and opening new avenues for exploration in science and engineering.\nAI Co-Pilots for Various Tasks: Beyond acting as mere tools, AI models are now being developed as intelligent co-pilots, assisting human experts in a variety of tasks. Whether aiding in data analysis, guiding complex problem-solving, or enhancing creative processes, AI co-pilots represent a new paradigm of collaboration between human and machine intelligence.\n\nKnowledge Engineering and Prompt Engineering are not mere additions to the AI toolkit; they are pivotal advancements that herald a new era in AI application design and interaction. By embracing these new frontiers, LA3D reinforces its commitment to innovation, excellence, and the relentless pursuit of AI that is not just cutting-edge but profoundly attuned to human needs and aspirations. Join us as we explore these new horizons, uncovering the immense potential and profound implications they hold for the future of AI.\n\n\nThe Evolution of CyberInfrastructure and AI-Driven Science AI-Driven Science\nThe seamless integration of CyberInfrastructure with AI-driven science marks a transformative phase in research and innovation. As part of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing (CRC), we are at the forefront of this exciting convergence, pioneering approaches that harness the power of advanced computing technologies to accelerate scientific discovery.\n\nAI-Driven Science: The infusion of AI into scientific research has ushered in a new era of data-driven exploration and insight. At LA3D, we employ AI models to analyze complex data sets, predict outcomes, and even guide experimental design. From enhancing medical diagnostics to predicting climate patterns, AI-driven science is unlocking unprecedented opportunities for understanding and innovation.\nRelevance to CRC: The Center for Research Computing at Notre Dame is committed to providing cutting-edge computational resources and expertise. The collaboration with LA3D amplifies this commitment by aligning AI research with state-of-the-art CyberInfrastructure. Together, we’re pushing the boundaries of what’s possible in computational science.\nAI Surrogates for Mathematical Models: Building on the AI surrogates concept, we utilize AI models to replicate complex mathematical or physical systems within CRC. These surrogates enable faster simulations and insights, thus accelerating research and expanding our ability to tackle previously intractable problems.\nAI Co-Pilots for Scientific Exploration: The development of AI co-pilots has extended into the realm of scientific exploration at CRC. These intelligent systems act as collaborators, assisting researchers in hypothesis formulation, data analysis, and problem-solving. It’s a revolutionary approach that augments human intelligence with AI, fostering a new level of creativity and rigor in scientific inquiry.\nIntegration of CyberInfrastructure: A robust CyberInfrastructure is foundational to AI-driven science at CRC. By weaving together high-performance computing, cloud technologies, and specialized software, we’re creating a dynamic environment where AI and computational science flourish. It’s a synergy that optimizes research processes, enhances collaboration, and catalyzes breakthroughs.\n\nThe evolution of CyberInfrastructure and AI-driven science at CRC represents more than technological advancement; it’s a paradigm shift in how we approach research and discovery. Through strategic collaboration and relentless innovation, we’re crafting a future where technology and human intellect unite to illuminate the unknown. Join us on this path, as we explore the incredible potential and promise of this convergence, continually striving to redefine the boundaries of what is possible in science and beyond."
  },
  {
    "objectID": "posts/welcome/index.html#blogs-objective-and-overview",
    "href": "posts/welcome/index.html#blogs-objective-and-overview",
    "title": "Welcome To AI Success Factors: Engineering Trust in Deployments",
    "section": "Blog’s Objective and Overview",
    "text": "Blog’s Objective and Overview\nIn alignment with the University of Notre Dame’s mission to seek knowledge that addresses humanity’s pressing challenges, and the Center for Research Computing’s (CRC) commitment to driving innovation, the Laboratory for Assured AI Applications Development (LA3D) is pleased to unveil this blog as an essential platform.\n\nWeekly Updates: Engage with regular insights into the ongoing research, technological advancements, and creative pursuits within LA3D. From AI Engineering to Trusted AI, we’ll keep our community abreast of the exciting developments shaping our field.\nInsights into Trusted AI, CI-Compass, and More: Delve into the core projects and collaborations within LA3D, including specialized explorations into the worlds of Trusted AI, CI-Compass, CyberSecurity in AI, and the nuances of Responsible AI.\nAI Workforce Development: Recognizing the need for a skilled and knowledgeable AI workforce, this blog will feature initiatives, programs, and strategies dedicated to cultivating the next generation of AI professionals. Together with CRC, we strive to foster education, mentorship, and career development in AI.\nResearch Publications and Highlights: Discover the rich tapestry of research being woven at LA3D. We’ll highlight key publications, conference achievements, and innovative studies that reflect our commitment to excellence and alignment with Notre Dame’s values.\nCommunity Engagement and Collaboration: Building on Notre Dame’s emphasis on community and service, this blog invites you to participate, share, and learn. Join a lively dialogue that celebrates diversity of thought and collaboration in pursuit of a greater understanding of Assured AI.\nSpotlight on CyberSecurity in AI and Emerging Topics: As part of our comprehensive view of modern AI, we will dedicate specific sections to explore critical areas like CyberSecurity and the delicate balance between Responsible and Trusted AI.\nConnection to Notre Dame’s and CRC’s Mission: This blog embodies the spirit of Notre Dame and CRC’s shared mission to advance knowledge, foster innovation, and contribute to society. We strive to make the pursuit of AI not only a scientific endeavor but also a means to enrich lives and address societal needs.\n\nIn the introduction, we’ve outlined the essential areas of focus at the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. From AI Engineering’s crucial role in transitioning prototypes to production, to the ethical imperatives in Trusted AI, Knowledge Engineering, CyberSecurity in AI, and the blog’s alignment with the missions of CRC and Notre Dame, we’ve set the stage for a comprehensive exploration.\nOur blog serves as a platform to dive into these topics, including AI workforce development and the ways in which AI intersects with societal needs and technological advancements. As we move forward, we’ll examine these subjects in detail, shedding light on the challenges, successes, and ongoing efforts in these fields.\nStay tuned as we delve into the complexities of AI, with insights and updates that reflect LA3D’s commitment to innovation, responsibility, and real-world applicability. Join us in this exploration, as we strive to make AI not just a tool, but a reliable partner for progress."
  },
  {
    "objectID": "slideindex.html",
    "href": "slideindex.html",
    "title": "Weekly Nugget Presentations",
    "section": "",
    "text": "TAI Knowledge Engineering: A Frameworks Perspective\n\n\n\n\n\n\n\nKG Construction\n\n\ntrustedAI\n\n\nTesting\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nThings that concern Dr. Vardeman: Testing\n\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\nTesting\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nKG Construction\n\n\n\n\n\n\n\nKnowledge Engineering\n\n\nKG Construction\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\n  \n\n\n\n\nTrust and Causal Reasoning\n\n\n\n\n\n\n\nframeworks\n\n\ntrustedAI\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\nCharles F Vardeman II\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#how-it-started",
    "href": "slides/kg_pipeline/index.html#how-it-started",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "How it started…",
    "text": "How it started…"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#how-its-going",
    "href": "slides/kg_pipeline/index.html#how-its-going",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "How its going…",
    "text": "How its going…\n\n\nShirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, and Xindong Wu. “Unifying Large Language Models and Knowledge Graphs: A Roadmap.” arXiv, June 14, 2023. http://arxiv.org/abs/2306.08302."
  },
  {
    "objectID": "slides/kg_pipeline/index.html#the-semantic-web",
    "href": "slides/kg_pipeline/index.html#the-semantic-web",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "“The Semantic Web…”",
    "text": "“The Semantic Web…”\n\nTim Berners-Lee, James Hendler, and Ora Lassila. “The Semantic Web.” Scientific American 284, no. 5 (2001): 34–43."
  },
  {
    "objectID": "slides/kg_pipeline/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "href": "slides/kg_pipeline/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nRManLuo/Awesome-LLM-KG: Awesome papers about unifying LLMs and KGs (https://github.com/RManLuo/Awesome-LLM-KG)"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#ontology-based-etl",
    "href": "slides/kg_pipeline/index.html#ontology-based-etl",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Ontology based ETL",
    "text": "Ontology based ETL"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#automated-vocabulary-extraction",
    "href": "slides/kg_pipeline/index.html#automated-vocabulary-extraction",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Automated Vocabulary Extraction",
    "text": "Automated Vocabulary Extraction"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#llm-assisted-odps-using-pattern-templates",
    "href": "slides/kg_pipeline/index.html#llm-assisted-odps-using-pattern-templates",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "LLM assisted ODPs using Pattern Templates",
    "text": "LLM assisted ODPs using Pattern Templates"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#ontology-engineering-in-a-age-of-llms",
    "href": "slides/kg_pipeline/index.html#ontology-engineering-in-a-age-of-llms",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Ontology Engineering in a Age of LLMs",
    "text": "Ontology Engineering in a Age of LLMs"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#applying-software-engineering-to-ontologies",
    "href": "slides/kg_pipeline/index.html#applying-software-engineering-to-ontologies",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Applying Software Engineering to Ontologies",
    "text": "Applying Software Engineering to Ontologies\n\n\nBlomqvist, Eva, Karl Hammar, and Valentina Presutti. “Engineering Ontologies with Patterns – The EXtreme Design Methodology.” In Ontology Engineering with Ontology Design Patterns, 23–50. IOS Press, 2016. https://doi.org/10.3233/978-1-61499-676-7-23."
  },
  {
    "objectID": "slides/kg_pipeline/index.html#applying-software-engineering-to-ontologies-1",
    "href": "slides/kg_pipeline/index.html#applying-software-engineering-to-ontologies-1",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Applying Software Engineering to Ontologies",
    "text": "Applying Software Engineering to Ontologies\n\n\nCogan Shimizu, Karl Hammar, and Pascal Hitzler. “Modular Ontology Modeling.” Edited by Sabrina Kirrane, Axel-Cyrille Ngonga Ngomo, Sabrina Kirrane, and Axel-Cyrille Ngonga Ngomo. Semantic Web 14, no. 3 (April 5, 2023): 459–89. https://doi.org/10.3233/SW-222886."
  },
  {
    "objectID": "slides/kg_pipeline/index.html#fair-ontologies-and-vocabularies",
    "href": "slides/kg_pipeline/index.html#fair-ontologies-and-vocabularies",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "FAIR Ontologies and Vocabularies",
    "text": "FAIR Ontologies and Vocabularies\n\n\nGarijo, Daniel, and María Poveda-Villalón. “Best Practices for Implementing FAIR Vocabularies and Ontologies on the Web.” arXiv, March 29, 2020. http://arxiv.org/abs/2003.13084."
  },
  {
    "objectID": "slides/kg_pipeline/index.html#visual-ontology-developmentz",
    "href": "slides/kg_pipeline/index.html#visual-ontology-developmentz",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Visual Ontology Developmentz",
    "text": "Visual Ontology Developmentz\n\n\nGarijo, Daniel, and María Poveda-Villalón. “Best Practices for Implementing FAIR Vocabularies and Ontologies on the Web.” arXiv, March 29, 2020. http://arxiv.org/abs/2003.13084."
  },
  {
    "objectID": "slides/kg_pipeline/index.html#self-documenting-ontologies",
    "href": "slides/kg_pipeline/index.html#self-documenting-ontologies",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Self Documenting Ontologies",
    "text": "Self Documenting Ontologies\n\n\nGarijo, Daniel. “WIDOCO: A Wizard for Documenting Ontologies.” In International Semantic Web Conference, 94–102. Springer, Cham, 2017. https://doi.org/10.1007/978-3-319-68204-4_9.http://dgarijo.com/papers/widoco-iswc2017.pdf Garijo, Daniel. “WIDOCO: A Wizard for Documenting Ontologies.” Java, 2017. https://doi.org/10.1007/978-3-319-68204-4_9.https://github.com/dgarijo/Widoco"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#resources-to-learn-more",
    "href": "slides/kg_pipeline/index.html#resources-to-learn-more",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Resources to Learn More…",
    "text": "Resources to Learn More…"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#kgc-master-class-on-json-ld-pipeline",
    "href": "slides/kg_pipeline/index.html#kgc-master-class-on-json-ld-pipeline",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "KGC Master Class on JSON-LD Pipeline",
    "text": "KGC Master Class on JSON-LD Pipeline\n\n\nLearn More: Converting Legacy Enterprise Data into Knowledge Graphs with AI and JSON LD"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "href": "slides/kg_pipeline/index.html#unifying-large-language-models-and-knowledge-graphs-a-roadmap-1",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
    "text": "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n\n\nLearn More: [RManLuo/Awesome-LLM-KG: Awesome papers about unifying LLMs and KGs (github.com)"
  },
  {
    "objectID": "slides/kg_pipeline/index.html#chatgpt-experiment",
    "href": "slides/kg_pipeline/index.html#chatgpt-experiment",
    "title": "TAI Knowledge Engineering: A Frameworks Perspective",
    "section": "ChatGPT Experiment",
    "text": "ChatGPT Experiment\n\n\nLearn More: ChatGPT Code Interpreter"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-ml-website",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned ML Website",
    "text": "Towards Trustworthy and Aligned ML Website\n\n\nTowards Trustworthy and Aligned ML"
  },
  {
    "objectID": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "href": "slides/trust-causal/index.html#towards-trustworthy-and-aligned-machine-learning-a-data-centric-survey-with-causality-perspectives-1",
    "title": "Trust and Causal Reasoning",
    "section": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives",
    "text": "Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives\n\n\nLearn more: ArXiv Paper"
  },
  {
    "objectID": "slides/trust-causal/index.html#causal-reasoning",
    "href": "slides/trust-causal/index.html#causal-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Causal Reasoning",
    "text": "Causal Reasoning\n\n\nLearn more: Amazon Book of Why"
  },
  {
    "objectID": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "href": "slides/trust-causal/index.html#trustworthy-ml-initiative-trustml",
    "title": "Trust and Causal Reasoning",
    "section": "Trustworthy ML Initiative (TrustML)",
    "text": "Trustworthy ML Initiative (TrustML)\n\n\nLearn more: Trustworthy ML Org"
  },
  {
    "objectID": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "href": "slides/trust-causal/index.html#gorilla-api-to-ground-tool-use",
    "title": "Trust and Causal Reasoning",
    "section": "Gorilla API to Ground “Tool Use”",
    "text": "Gorilla API to Ground “Tool Use”\n\n\nLearn more: Gorilla: Large Language Model Connected with Massive APIs"
  },
  {
    "objectID": "slides/trust-causal/index.html#llama2-accessory",
    "href": "slides/trust-causal/index.html#llama2-accessory",
    "title": "Trust and Causal Reasoning",
    "section": "LLaMA2-Accessory",
    "text": "LLaMA2-Accessory\n\n\nLearn more: LLaMA2-Accessory"
  },
  {
    "objectID": "slides/trust-causal/index.html#multilingual-token-analysis",
    "href": "slides/trust-causal/index.html#multilingual-token-analysis",
    "title": "Trust and Causal Reasoning",
    "section": "MultiLingual Token Analysis",
    "text": "MultiLingual Token Analysis\n\n\nLearn more: Video: LLaMA2 Multilingual Models and Fine Tuning\nGoogle Collab Notebook:"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2",
    "href": "slides/trust-causal/index.html#metaai-dinov2",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2",
    "text": "MetaAI DINOv2\n\n\nLearn more: DINOv2 by Meta AI"
  },
  {
    "objectID": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "href": "slides/trust-causal/index.html#metaai-dinov2-huggingface-release",
    "title": "Trust and Causal Reasoning",
    "section": "MetaAI DINOv2 Huggingface Release",
    "text": "MetaAI DINOv2 Huggingface Release\n\n\nLearn more: DINOv2 by Meta AI Huggingface"
  },
  {
    "objectID": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "href": "slides/trust-causal/index.html#example-notebook-for-dinov2-semantic-segmentation",
    "title": "Trust and Causal Reasoning",
    "section": "Example notebook for DINOv2 Semantic Segmentation",
    "text": "Example notebook for DINOv2 Semantic Segmentation\n\n\nLearn more: Linear probing of DINOv2 for semantic segmentation"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "href": "slides/trust-causal/index.html#linear-regression-model-for-reasoning-1",
    "title": "Trust and Causal Reasoning",
    "section": "Linear Regression Model for Reasoning",
    "text": "Linear Regression Model for Reasoning\n\n\nLearn more: TART: A plug-and-play Transformer module for task-agnostic reasoning"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to “translational research,” a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your “About” page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "href": "about.html#about-ai-success-factors-engineering-trust-in-deployments",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "",
    "text": "AI Success Factors: Engineering Trust in Deployments is an initiative of the Laboratory for Assured AI Applications Development (LA3D) at the University of Notre Dame’s Center for Research Computing. This blog delves into the intricate dynamics of artificial intelligence (AI) research and development, with a strong emphasis on AI engineering, trust, and knowledge engineering.\nAs the pace of AI evolution accelerates, understanding the key factors for successful deployment becomes critical. This blog focuses on the intersection of trust and engineering, two pivotal components that determine the efficacy and acceptability of AI applications in various societal contexts.\nThe Laboratory for Assured AI Applications Development operates with a commitment to “translational research,” a methodology that drives us to convert theoretical advancements in AI into practical applications. This commitment extends to the creation of an efficient and secure AI cyberinfrastructure, designed to support the deployment of trustworthy and effective AI applications.\nAI Success Factors serves as a communication medium, helping to disseminate the work conducted by our lab and facilitating knowledge exchange within the AI community. We invite active engagement and encourage thoughtful discussions, aiming to foster a collaborative atmosphere that enriches our collective understanding of AI.\nOur vision for AI Success Factors is to contribute to an AI future marked by trusted and efficient applications, where AI engineering is comprehensible, accessible, and actionable. The blog aims to provide insights and perspectives that enable readers to grasp the nuances of AI deployment, assisting them in navigating the ever-evolving landscape of AI research and development.\nWhether you are a student, a professional, or an enthusiast interested in the progression of AI, AI Success Factors offers a wealth of knowledge and insights into the key aspects that shape the success of AI deployments. Through this platform, we hope to further the understanding and acceptance of AI and its many transformative possibilities.\nCertainly, here is a possible addition to your “About” page that discusses the tools used to create and manage the blog:"
  },
  {
    "objectID": "about.html#our-toolset",
    "href": "about.html#our-toolset",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Our Toolset",
    "text": "Our Toolset\nAI Success Factors: Engineering Trust in Deployments is more than just a blog - it’s a demonstration of how modern data science tools can streamline and simplify complex processes.\nOur blogging platform is built using Quarto, an open-source scientific and technical publishing system known for its flexibility and robustness. Quarto has the unique ability to support a wide range of content types, including Jupyter notebooks, R Markdown, and even Python or R scripts. Quarto’s distinctive feature is its ability to include executable code within the documents from various languages such as Python, R, and others. This allows us to create data-driven blog posts where the output - be it a graph, a table, or other data representations - is generated directly from the included code. This adds an interactive element to our posts, giving readers a deeper understanding of the concepts and analyses presented. Quarto supports multiple output formats including HTML, PDF, EPUB, and Word, providing us the versatility to tailor our content to suit different needs. This flexible tool, coupled with its capability to handle larger projects made up of multiple files, allows us to efficiently manage our blog while maintaining consistency and quality across our posts. Quarto presentations are also used to generate revealjs presentations for weekly slide shows. Quarto forms the basis for Fast.ai’s nbdev framework for exploritory programming allowing for software development in Jupyter Notebooks and automated generation of Python modules and documentation from the notebooks.\nDevelopment Containers serve as our primary environment for data science, providing a consistent and replicable framework for running our analyses. These containerized environments allow us to standardize our work and ensure that our research is reproducible and reliable. The dev container uses the Mamba solver to provision the python environment from the specification in the environment.yml.\nWe use Visual Studio Code (VS Code) as our primary code editor, taking advantage of its rich ecosystem of extensions and in-built features. VS Code’s Jupyter notebook support allows us to interactively develop and visualize our data models directly within the editor, enabling us to produce intuitive, data-driven narratives for our blog posts.\nAll of our content is version controlled and hosted on GitHub. GitHub’s robust versioning system allows us to effectively manage changes, track progress, and ensure that every piece of content we publish is up to date and accurate.\nThe blog is published using GitHub Page, a platform that simplifies the deployment process and seamlessly integrates with our existing GitHub repository. This setup enables us to provide a reliable, accessible resource for our readers, irrespective of where they are or when they choose to access our content.\nFinally, we utilize GitHub Code Spaces to create a fully-featured, cloud-hosted development environment that can be accessed from any device. This not only allows us to work from anywhere but also ensures that our setup can be easily replicated by other researchers and developers who wish to explore our code.\nEach tool in our stack has been chosen for its ability to facilitate efficient, reliable, and transparent data science. By sharing our toolset, we hope to provide insight into our workflows and encourage a culture of open, reproducible research within the AI community."
  },
  {
    "objectID": "about.html#generative-ai-in-content-creation",
    "href": "about.html#generative-ai-in-content-creation",
    "title": "About: Laboratory for Assured AI Applications Development (LA3D)",
    "section": "Generative AI in Content Creation",
    "text": "Generative AI in Content Creation\nIn creating AI Success Factors: Engineering Trust in Deployments, we harness the power of artificial intelligence in conjunction with human expertise. We utilize advanced Generative AI models such as ChatGPT, Bing Chat, and Anthropic Claude in a guided, iterative process that combines the best of AI and human capabilities.\nOur use of Generative AI begins with the drafting stage. These models, trained on extensive datasets, generate human-like text that matches our specified tone and style, providing us with a solid foundation for each blog post. This allows us to focus on the larger narrative without getting mired in the nitty-gritty details from the outset.\nThe AI-generated drafts, while sophisticated, are just the starting point. We employ a methodology that involves guiding the AI to improve its output. This includes providing more detailed prompts, specifying the format we want the output in, or asking the model to think step-by-step before settling on a conclusion.\nOnce we have a draft that we’re satisfied with, it’s time for human intervention. Our team reviews the AI-generated content, refining and editing it to ensure it maintains the standards of accuracy, relevance, and depth that our readers expect. This process leverages critical human skills of creativity, critical thinking, and domain expertise that even the most advanced AI can’t replicate.\nThis approach exemplifies our vision of a symbiotic relationship between AI and humans. By effectively integrating Generative AI into our content creation process, we not only boost our productivity and efficiency but also demonstrate the practical application of AI technologies in real-world scenarios. Thus, the blog becomes a testament to our commitment to translational research and our pursuit of an AI-integrated future."
  }
]